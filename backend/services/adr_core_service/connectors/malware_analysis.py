"""
Malware Analysis Connector - Integrates with Malware Analysis Service
"""

import httpx
import logging
from typing import Dict, Any, Optional
from datetime import datetime

from .base import BaseConnector

logger = logging.getLogger(__name__)


class MalwareAnalysisConnector(BaseConnector):
    """
    Connector for Malware Analysis Service

    Provides:
    - File hash analysis
    - Malware family identification
    - YARA rule matching
    - Behavioral analysis results
    - Sandbox execution results
    """

    def __init__(self, base_url: str = "http://localhost:8006"):
        config = {
            'endpoint': base_url,
            'timeout': 30.0,
            'enabled': True
        }
        super().__init__(config)
        self.cache = {}

    async def health_check(self) -> bool:
        """Check if Malware Analysis Service is reachable"""
        try:
            response = await self.client.get(f"{self.endpoint}/health")
            return response.status_code == 200
        except Exception as e:
            logger.error(f"Health check failed: {e}")
            return False

    async def analyze_hash(self, file_hash: str) -> Optional[Dict[str, Any]]:
        """
        Analyze file hash using malware analysis service

        Args:
            file_hash: MD5, SHA1, or SHA256 hash

        Returns:
            Malware analysis results or None
        """
        if file_hash in self.cache:
            logger.debug(f"Cache hit for hash: {file_hash}")
            return self.cache[file_hash]

        try:
            response = await self._make_request(
                'POST',
                '/api/malware/analyze',
                data={'hash': file_hash}
            )

            if response:
                enriched = {
                    'hash': file_hash,
                    'is_malware': response.get('is_malware', False),
                    'confidence': response.get('confidence', 0),
                    'malware_family': response.get('malware_family'),
                    'threat_name': response.get('threat_name'),

                    # Detection results
                    'yara_matches': response.get('yara_matches', []),
                    'av_detections': response.get('av_detections', {}),

                    # Behavioral analysis
                    'behaviors': response.get('behaviors', []),
                    'file_type': response.get('file_type'),
                    'file_size': response.get('file_size'),

                    # Threat scoring
                    'threat_score': response.get('threat_score', 0),
                    'severity': response.get('severity', 'unknown'),

                    # Metadata
                    'analyzed_at': datetime.utcnow().isoformat(),
                    'enriched_by': 'malware_analysis_service'
                }

                self.cache[file_hash] = enriched

                logger.info(
                    f"ðŸ¦  Malware analysis for {file_hash}: "
                    f"Malware={enriched['is_malware']}, "
                    f"Family={enriched['malware_family']}"
                )

                return enriched

            return None

        except Exception as e:
            logger.error(f"Error analyzing hash {file_hash}: {e}")
            return None

    async def scan_file(self, file_path: str) -> Optional[Dict[str, Any]]:
        """
        Scan file using malware analysis service

        Args:
            file_path: Path to file to scan

        Returns:
            Scan results or None
        """
        try:
            with open(file_path, 'rb') as f:
                files = {'file': f}
                response = await self.client.post(
                    f"{self.endpoint}/api/malware/scan",
                    files=files
                )

            if response.status_code == 200:
                return response.json()

            return None

        except Exception as e:
            logger.error(f"Error scanning file {file_path}: {e}")
            return None

    async def enrich(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Enrich detection data with malware analysis

        Args:
            data: Detection data containing file hashes

        Returns:
            Enriched data with malware analysis results
        """
        # Extract hashes from detection
        hashes_to_analyze = []

        # Direct hash field
        if 'file_hash' in data:
            hashes_to_analyze.append(data['file_hash'])

        # Hash in indicators
        for indicator in data.get('indicators', []):
            if isinstance(indicator, dict) and indicator.get('type') == 'hash':
                hashes_to_analyze.append(indicator.get('value'))
            elif isinstance(indicator, str) and len(indicator) in [32, 40, 64]:
                # Potential hash by length
                hashes_to_analyze.append(indicator)

        # Analyze each hash
        malware_results = {}
        for hash_val in set(hashes_to_analyze):
            result = await self.analyze_hash(hash_val)
            if result:
                malware_results[hash_val] = result

        # Add to enriched context
        data['enriched_context'] = data.get('enriched_context', {})
        data['enriched_context']['malware_analysis'] = malware_results

        # Adjust threat score based on malware analysis
        if malware_results:
            malware_scores = [
                result['threat_score']
                for result in malware_results.values()
                if result.get('is_malware')
            ]

            if malware_scores:
                max_malware_score = max(malware_scores)
                original_score = data.get('threat_score', 0)

                # If malware detected, heavily weight the malware score
                adjusted_score = int(max_malware_score * 0.8 + original_score * 0.2)

                data['threat_score_original'] = original_score
                data['threat_score'] = adjusted_score
                data['threat_score_adjusted_by'] = 'malware_analysis'

                # Update severity
                if adjusted_score >= 80:
                    data['severity'] = 'critical'
                elif adjusted_score >= 60:
                    data['severity'] = 'high'

                logger.info(
                    f"ðŸ¦  Threat score adjusted: {original_score} â†’ {adjusted_score} "
                    f"based on malware analysis"
                )

                # Add malware families to threat description
                families = [
                    result['malware_family']
                    for result in malware_results.values()
                    if result.get('malware_family')
                ]

                if families:
                    data['malware_families'] = families

        return data

    async def get_yara_rules(self) -> Optional[list]:
        """Get available YARA rules from malware service"""
        try:
            response = await self._make_request('GET', '/api/yara/rules')
            return response.get('rules', []) if response else None
        except Exception as e:
            logger.error(f"Error getting YARA rules: {e}")
            return None

    async def submit_sample(self, file_data: bytes, filename: str) -> Optional[str]:
        """
        Submit malware sample for analysis

        Args:
            file_data: File binary data
            filename: Original filename

        Returns:
            Analysis job ID or None
        """
        try:
            files = {'file': (filename, file_data)}
            response = await self.client.post(
                f"{self.endpoint}/api/malware/submit",
                files=files
            )

            if response.status_code == 200:
                result = response.json()
                return result.get('job_id')

            return None

        except Exception as e:
            logger.error(f"Error submitting sample {filename}: {e}")
            return None
