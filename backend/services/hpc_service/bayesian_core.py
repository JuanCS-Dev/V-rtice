"""hPC Service - Hierarchical Predictive Coding Network (Bayesian Core).

This module implements the core Bayesian inference engine for the hPC service,
which is inspired by the theory of predictive coding in the brain. It uses
Bayesian methods to continuously update its beliefs about the state of the
world (i.e., the network environment) based on incoming sensory data.

Key Concepts:
- **Predictive Coding**: The brain constantly generates top-down predictions about
  sensory input. Bottom-up sensory signals are compared to these predictions,
  and only the differences (prediction errors) are propagated up the hierarchy.
- **Bayesian Inference**: Beliefs are updated according to Bayes' theorem:
  `posterior ∝ likelihood × prior`.
- **Free Energy Principle**: The system acts to minimize prediction error, which
  is equivalent to minimizing a quantity called "free energy" or "surprise."
"""

import logging
import time
import numpy as np
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, field
from enum import Enum
from scipy.stats import entropy

logger = logging.getLogger(__name__)


class ThreatLevel(str, Enum):
    """Enumeration for the assessed threat severity levels."""
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    BENIGN = "benign"


@dataclass
class Observation:
    """Represents a single, bottom-up sensory observation.

    Attributes:
        timestamp (float): The time of the observation.
        features (np.ndarray): The feature vector of the observation.
        source_id (str): The source of the observation (e.g., a specific sensor).
    """
    timestamp: float
    features: np.ndarray
    source_id: str
    metadata: Dict = field(default_factory=dict)


@dataclass
class Prediction:
    """Represents a top-down prediction generated by the model.

    Attributes:
        mean (np.ndarray): The expected feature vector.
        variance (np.ndarray): The uncertainty (variance) around the mean.
        threat_level (ThreatLevel): The predicted threat level.
    """
    mean: np.ndarray
    variance: np.ndarray
    confidence: float
    threat_level: ThreatLevel
    reasoning: str


@dataclass
class PredictionError:
    """Represents the difference between an observation and a prediction."""
    error: np.ndarray
    magnitude: float
    surprise: float


@dataclass
class BeliefState:
    """Represents the model's current beliefs (posterior distribution).

    Attributes:
        threat_probability (Dict[ThreatLevel, float]): The probability distribution
            over possible threat levels.
        entropy (float): The Shannon entropy of the belief state, representing
            the model's overall uncertainty.
    """
    threat_probability: Dict[ThreatLevel, float]
    feature_distribution: Dict[str, Tuple[float, float]]
    entropy: float


class BayesianCore:
    """The core Bayesian inference engine for hierarchical predictive coding.

    This class manages the belief state of the system, generates predictions,
    computes prediction errors, and updates its beliefs based on new observations.
    """

    def __init__(self, num_features: int, learning_rate: float = 0.1):
        """Initializes the BayesianCore.

        Args:
            num_features (int): The number of features in an observation vector.
            learning_rate (float): The rate at which the model updates its prior beliefs.
        """
        self.num_features = num_features
        self.learning_rate = learning_rate
        self.prior_mean = np.zeros(num_features)
        self.prior_variance = np.ones(num_features)
        self.belief_state: Optional[BeliefState] = None

    def learn_prior(self, observations: List[Observation]):
        """Learns the prior distribution from a set of normal (benign) observations."""
        features = np.array([obs.features for obs in observations])
        self.prior_mean = np.mean(features, axis=0)
        self.prior_variance = np.var(features, axis=0) + 1e-6
        # Initialize belief state with the learned prior
        self.belief_state = BeliefState(
            threat_probability={level: 1.0/len(ThreatLevel) for level in ThreatLevel},
            feature_distribution={f'f{i}': (self.prior_mean[i], np.sqrt(self.prior_variance[i])) for i in range(self.num_features)},
            entropy=entropy(list(self.belief_state.threat_probability.values())) if self.belief_state else 0
        )

    def predict(self) -> Prediction:
        """Generates a top-down prediction based on the current prior beliefs."""
        # For simplicity, the prediction is the current prior.
        return Prediction(
            mean=self.prior_mean,
            variance=self.prior_variance,
            confidence=1.0 / (1.0 + np.mean(self.prior_variance)),
            threat_level=ThreatLevel.BENIGN, # Default prediction
            reasoning="Based on prior distribution of normal traffic."
        )

    def compute_prediction_error(self, obs: Observation, pred: Prediction) -> PredictionError:
        """Computes the prediction error between an observation and a prediction."""
        error = obs.features - pred.mean
        # Mahalanobis distance for magnitude
        magnitude = np.sqrt(np.sum((error**2) / pred.variance))
        # Simplified surprise metric
        surprise = np.log(1 + magnitude)
        return PredictionError(error=error, magnitude=float(magnitude), surprise=float(surprise))

    def update_beliefs(self, obs: Observation, error: PredictionError) -> BeliefState:
        """Updates the model's beliefs based on the prediction error."""
        # Update prior (online learning)
        self.prior_mean += self.learning_rate * error.error
        # Update threat probability based on error magnitude
        new_threat_prob = self._update_threat_probability(error.magnitude)
        self.belief_state.threat_probability = new_threat_prob
        self.belief_state.entropy = entropy(list(new_threat_prob.values()))
        return self.belief_state

    def _update_threat_probability(self, error_magnitude: float) -> Dict[ThreatLevel, float]:
        """Updates the threat probability distribution based on error magnitude."""
        # Simplified logic: higher error -> higher threat probability
        threat_score = 1 / (1 + np.exp(-0.5 * (error_magnitude - 5)))
        probs = {level: 0.1 for level in ThreatLevel} # base prob
        if threat_score > 0.9: probs[ThreatLevel.CRITICAL] = 0.6
        elif threat_score > 0.7: probs[ThreatLevel.HIGH] = 0.6
        elif threat_score > 0.5: probs[ThreatLevel.MEDIUM] = 0.6
        else: probs[ThreatLevel.BENIGN] = 0.6
        # Normalize
        total = sum(probs.values())
        return {k: v/total for k, v in probs.items()}