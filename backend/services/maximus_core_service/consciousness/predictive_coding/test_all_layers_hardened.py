"""
Tests for ALL 5 Predictive Coding Layers - Parametrized to Eliminate Duplication

Tests Layer1-5 implementations inheriting from PredictiveCodingLayerBase:
- Layer1Sensory (VAE event compression)
- Layer2Behavioral (RNN sequence prediction)
- Layer3Operational (Transformer long-range dependencies)
- Layer4Tactical (GNN relational reasoning)
- Layer5Strategic (Bayesian causal inference)

Each layer inherits ALL safety features from base class.
These tests validate layer-specific prediction logic.

40 tests Ã— 5 layers = 200 tests (but parametrized for maintainability)

NO MOCK - Uses real layer implementations.

Authors: Claude Code + Juan
Version: 1.0.0
Date: 2025-10-08
"""

import pytest
import asyncio
import numpy as np

from consciousness.predictive_coding.layer_base_hardened import LayerConfig
from consciousness.predictive_coding.layer1_sensory_hardened import Layer1Sensory
from consciousness.predictive_coding.layer2_behavioral_hardened import Layer2Behavioral
from consciousness.predictive_coding.layer3_operational_hardened import Layer3Operational
from consciousness.predictive_coding.layer4_tactical_hardened import Layer4Tactical
from consciousness.predictive_coding.layer5_strategic_hardened import Layer5Strategic


# ============================================================================
# Parametrized Layer Fixtures
# ============================================================================


ALL_LAYERS = [
    (Layer1Sensory, 1, "Layer1_Sensory", 10000, 64),
    (Layer2Behavioral, 2, "Layer2_Behavioral", 64, 32),
    (Layer3Operational, 3, "Layer3_Operational", 32, 16),
    (Layer4Tactical, 4, "Layer4_Tactical", 16, 8),
    (Layer5Strategic, 5, "Layer5_Strategic", 8, 4),
]


@pytest.fixture(params=ALL_LAYERS, ids=["layer1", "layer2", "layer3", "layer4", "layer5"])
def layer_class(request):
    """Parametrized fixture providing all 5 layer classes."""
    return request.param


@pytest.fixture
def layer_instance(layer_class):
    """Parametrized fixture providing layer instances."""
    LayerClass, layer_id, layer_name, input_dim, hidden_dim = layer_class
    config = LayerConfig(
        layer_id=layer_id,
        input_dim=input_dim,
        hidden_dim=hidden_dim
    )
    return LayerClass(config)


# ============================================================================
# Tests: Layer Initialization
# ============================================================================


def test_layer_initialization(layer_class):
    """Test each layer initializes correctly with appropriate config."""
    LayerClass, layer_id, layer_name, input_dim, hidden_dim = layer_class

    config = LayerConfig(
        layer_id=layer_id,
        input_dim=input_dim,
        hidden_dim=hidden_dim
    )
    layer = LayerClass(config)

    assert layer.config.layer_id == layer_id
    assert layer.config.input_dim == input_dim
    assert layer.config.hidden_dim == hidden_dim
    assert layer.get_layer_name() == layer_name


def test_layer_rejects_wrong_layer_id(layer_class):
    """Test each layer rejects config with wrong layer_id."""
    LayerClass, layer_id, layer_name, input_dim, hidden_dim = layer_class

    # Wrong layer_id (different from expected)
    wrong_id = (layer_id % 5) + 1
    if wrong_id == layer_id:
        wrong_id = (layer_id + 1) % 5 + 1

    config = LayerConfig(
        layer_id=wrong_id,
        input_dim=input_dim,
        hidden_dim=hidden_dim
    )

    with pytest.raises(AssertionError):
        LayerClass(config)


# ============================================================================
# Tests: Prediction Logic
# ============================================================================


@pytest.mark.asyncio
async def test_predict_returns_correct_shape(layer_instance, layer_class):
    """Test prediction returns output with correct shape."""
    _, layer_id, _, input_dim, hidden_dim = layer_class

    # Create input with correct shape
    input_data = np.random.randn(input_dim).astype(np.float32)

    prediction = await layer_instance.predict(input_data)

    assert prediction is not None
    assert isinstance(prediction, np.ndarray)
    # Prediction should have same shape as input (reconstruction/next prediction)
    assert prediction.shape == (input_dim,)


@pytest.mark.asyncio
async def test_predict_handles_list_input(layer_instance, layer_class):
    """Test prediction accepts list input and converts to numpy."""
    _, layer_id, _, input_dim, hidden_dim = layer_class

    # List input
    input_data = [0.5] * input_dim

    prediction = await layer_instance.predict(input_data)

    assert prediction is not None
    assert isinstance(prediction, np.ndarray)


@pytest.mark.asyncio
async def test_predict_increments_counter(layer_instance, layer_class):
    """Test prediction increments total_predictions counter."""
    _, layer_id, _, input_dim, hidden_dim = layer_class

    input_data = np.random.randn(input_dim).astype(np.float32)

    state_before = layer_instance.get_state()
    await layer_instance.predict(input_data)
    state_after = layer_instance.get_state()

    assert state_after.total_predictions == state_before.total_predictions + 1


# ============================================================================
# Tests: Error Computation
# ============================================================================


def test_compute_error_returns_scalar(layer_instance, layer_class):
    """Test compute_error returns scalar value."""
    _, layer_id, _, input_dim, hidden_dim = layer_class

    predicted = np.ones(input_dim)
    actual = np.ones(input_dim) * 2.0

    error = layer_instance.compute_error(predicted, actual)

    assert isinstance(error, float)
    assert error >= 0.0


def test_compute_error_zero_for_perfect_prediction(layer_instance, layer_class):
    """Test error is zero (or near-zero) for perfect prediction."""
    _, layer_id, _, input_dim, hidden_dim = layer_class

    data = np.random.randn(input_dim).astype(np.float32)

    error = layer_instance.compute_error(data, data)

    assert error == pytest.approx(0.0, abs=1e-6)


def test_compute_error_bounded_by_max(layer_instance, layer_class):
    """Test error is clipped to max_prediction_error."""
    _, layer_id, _, input_dim, hidden_dim = layer_class

    # Very different vectors (large error)
    predicted = np.ones(input_dim) * 100.0
    actual = np.ones(input_dim) * -100.0

    error = layer_instance.compute_error(predicted, actual)

    # Should be clipped to max_prediction_error
    assert error <= layer_instance.config.max_prediction_error


# ============================================================================
# Tests: Safety Features (Inherited from Base)
# ============================================================================


@pytest.mark.asyncio
async def test_circuit_breaker_protection(layer_class):
    """Test circuit breaker opens after consecutive errors."""
    LayerClass, layer_id, layer_name, input_dim, hidden_dim = layer_class

    config = LayerConfig(
        layer_id=layer_id,
        input_dim=input_dim,
        hidden_dim=hidden_dim,
        max_consecutive_errors=3
    )
    layer = LayerClass(config)

    # Monkey-patch to force failures
    original_impl = layer._predict_impl

    async def failing_impl(input_data):
        raise RuntimeError("Forced failure")

    layer._predict_impl = failing_impl

    input_data = np.random.randn(input_dim).astype(np.float32)

    # Trigger 3 failures
    await layer.predict(input_data)
    await layer.predict(input_data)
    await layer.predict(input_data)

    state = layer.get_state()
    assert state.circuit_breaker_open is True


@pytest.mark.asyncio
async def test_attention_gating_works(layer_instance, layer_class):
    """Test attention gate limits predictions per cycle."""
    _, layer_id, _, input_dim, hidden_dim = layer_class

    # Set low limit
    layer_instance.config.max_predictions_per_cycle = 2

    input_data = np.random.randn(input_dim).astype(np.float32)

    # Make 3 predictions (should block 3rd)
    result1 = await layer_instance.predict(input_data)
    result2 = await layer_instance.predict(input_data)
    result3 = await layer_instance.predict(input_data)

    assert result1 is not None
    assert result2 is not None
    assert result3 is None  # Blocked by attention gate


def test_emergency_stop_works(layer_instance, layer_class):
    """Test emergency_stop() deactivates layer."""
    assert layer_instance._is_active is True

    layer_instance.emergency_stop()

    assert layer_instance._is_active is False
    assert layer_instance._circuit_breaker_open is True


# ============================================================================
# Tests: Layer-Specific Features
# ============================================================================


@pytest.mark.asyncio
async def test_layer2_hidden_state_persistence():
    """Test Layer2 (RNN) maintains hidden state across predictions."""
    config = LayerConfig(layer_id=2, input_dim=64, hidden_dim=32)
    layer = Layer2Behavioral(config)

    input1 = np.random.randn(64).astype(np.float32)
    input2 = np.random.randn(64).astype(np.float32)

    # First prediction initializes hidden state
    pred1 = await layer.predict(input1)

    # Hidden state should be non-zero after first prediction
    assert np.any(layer._hidden_state != 0.0)

    # Second prediction should use updated hidden state
    hidden_before = layer._hidden_state.copy()
    pred2 = await layer.predict(input2)
    hidden_after = layer._hidden_state

    # Hidden state should have changed
    assert not np.array_equal(hidden_before, hidden_after)


def test_layer2_reset_hidden_state():
    """Test Layer2 reset_hidden_state() clears RNN state."""
    config = LayerConfig(layer_id=2, input_dim=64, hidden_dim=32)
    layer = Layer2Behavioral(config)

    # Set non-zero hidden state
    layer._hidden_state = np.ones(32)

    layer.reset_hidden_state()

    assert np.all(layer._hidden_state == 0.0)


@pytest.mark.asyncio
async def test_layer3_context_window_accumulation():
    """Test Layer3 (Transformer) accumulates context window."""
    config = LayerConfig(layer_id=3, input_dim=32, hidden_dim=16)
    layer = Layer3Operational(config)

    assert len(layer._context_window) == 0

    input1 = np.random.randn(32).astype(np.float32)
    await layer.predict(input1)

    assert len(layer._context_window) == 1

    input2 = np.random.randn(32).astype(np.float32)
    await layer.predict(input2)

    assert len(layer._context_window) == 2


@pytest.mark.asyncio
async def test_layer3_context_window_max_length():
    """Test Layer3 context window respects max length."""
    config = LayerConfig(layer_id=3, input_dim=32, hidden_dim=16)
    layer = Layer3Operational(config)

    layer._max_context_length = 3

    # Add 5 items via predict (which maintains max length)
    for i in range(5):
        input_data = np.ones(32) * i
        await layer.predict(input_data)

    assert len(layer._context_window) <= 3


def test_layer3_reset_context():
    """Test Layer3 reset_context() clears attention context."""
    config = LayerConfig(layer_id=3, input_dim=32, hidden_dim=16)
    layer = Layer3Operational(config)

    # Add items
    layer._context_window.append(np.ones(32))
    layer._context_window.append(np.ones(32))

    layer.reset_context()

    assert len(layer._context_window) == 0


@pytest.mark.asyncio
async def test_layer4_entity_embeddings_created():
    """Test Layer4 (GNN) creates entity embeddings."""
    config = LayerConfig(layer_id=4, input_dim=16, hidden_dim=8)
    layer = Layer4Tactical(config)

    assert len(layer._entity_embeddings) == 0

    input_data = np.random.randn(16).astype(np.float32)
    await layer.predict(input_data)

    # Should have created entity embeddings
    assert len(layer._entity_embeddings) > 0


def test_layer4_reset_graph():
    """Test Layer4 reset_graph() clears relational state."""
    config = LayerConfig(layer_id=4, input_dim=16, hidden_dim=8)
    layer = Layer4Tactical(config)

    # Add entities and relations
    layer._entity_embeddings["entity_1"] = np.ones(8)
    layer._entity_embeddings["entity_2"] = np.ones(8)
    layer._relations[("entity_1", "entity_2")] = "related"

    layer.reset_graph()

    assert len(layer._entity_embeddings) == 0
    assert len(layer._relations) == 0


def test_layer5_goal_priors_sum_to_one():
    """Test Layer5 (Bayesian) goal priors are normalized."""
    config = LayerConfig(layer_id=5, input_dim=8, hidden_dim=4)
    layer = Layer5Strategic(config)

    prior_sum = sum(layer._goal_priors.values())

    assert prior_sum == pytest.approx(1.0, abs=1e-6)


def test_layer5_update_priors():
    """Test Layer5 update_priors() adjusts goal probabilities."""
    config = LayerConfig(layer_id=5, input_dim=8, hidden_dim=4)
    layer = Layer5Strategic(config)

    initial_prior = layer._goal_priors["data_exfiltration"]

    # Update with observations favoring data_exfiltration
    for _ in range(10):
        obs = np.random.randn(8).astype(np.float32)
        layer.update_priors(obs, "data_exfiltration")

    updated_prior = layer._goal_priors["data_exfiltration"]

    # Prior should have increased
    assert updated_prior >= initial_prior


def test_layer5_reset_priors():
    """Test Layer5 reset_priors() returns to uniform distribution."""
    config = LayerConfig(layer_id=5, input_dim=8, hidden_dim=4)
    layer = Layer5Strategic(config)

    # Update priors (make non-uniform)
    for _ in range(5):
        obs = np.random.randn(8).astype(np.float32)
        layer.update_priors(obs, "data_exfiltration")

    # Reset
    layer.reset_priors()

    # All priors should be equal (uniform)
    prior_values = list(layer._goal_priors.values())
    assert all(p == pytest.approx(prior_values[0], abs=1e-6) for p in prior_values)


# ============================================================================
# Tests: Metrics Export
# ============================================================================


@pytest.mark.asyncio
async def test_get_health_metrics_structure(layer_instance, layer_class):
    """Test get_health_metrics() returns correct structure."""
    _, layer_id, layer_name, input_dim, hidden_dim = layer_class

    input_data = np.random.randn(input_dim).astype(np.float32)
    await layer_instance.predict(input_data)

    metrics = layer_instance.get_health_metrics()

    # Check metrics is dict
    assert isinstance(metrics, dict)

    # Check has expected keys (layer name normalized with underscores)
    layer_key_prefix = layer_name.lower()
    expected_keys = [
        f"{layer_key_prefix}_is_active",
        f"{layer_key_prefix}_total_predictions",
    ]

    for key in expected_keys:
        assert key in metrics


@pytest.mark.asyncio
async def test_metrics_values_are_numeric(layer_instance, layer_class):
    """Test all metric values are numeric."""
    _, layer_id, _, input_dim, hidden_dim = layer_class

    input_data = np.random.randn(input_dim).astype(np.float32)
    await layer_instance.predict(input_data)

    metrics = layer_instance.get_health_metrics()

    for key, value in metrics.items():
        assert isinstance(value, (int, float, bool)), f"{key} has non-numeric value: {value}"


# ============================================================================
# Run Tests
# ============================================================================


if __name__ == "__main__":
    pytest.main([__file__, "-v", "--tb=short"])
