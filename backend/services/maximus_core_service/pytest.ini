[pytest]
# Test discovery
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Output and reporting
addopts =
    --verbose
    --tb=short
    --cov=.
    --cov-report=html:htmlcov
    --cov-report=term-missing
    --cov-report=xml
    --cov-fail-under=70
    -ra
    --color=yes
    --ignore=tests/archived_broken

# Coverage configuration
[coverage:run]
source = .
omit =
    */tests/*
    */test_*.py
    */__pycache__/*
    */venv/*
    */env/*
    setup.py
    tests/archived_broken/*

[coverage:report]
precision = 2
show_missing = True
skip_covered = False

[coverage:html]
directory = htmlcov

# Markers for test categorization
markers =
    unit: Unit tests (fast, isolated)
    integration: Integration tests (medium speed, component interaction)
    e2e: End-to-end tests (slow, full workflow)
    slow: Slow tests (skip with -m 'not slow')
    benchmark: Performance benchmarks (biological plausibility validation)
    requires_torch: Tests requiring PyTorch
    requires_gpu: Tests requiring GPU
    requires_onnx: Tests requiring ONNX runtime
    requires_cuda: Tests requiring CUDA

# Console output styling
console_output_style = progress

# Timeout (10 minutes for slow tests)
timeout = 600

# Warnings
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning

# Logging
log_cli = false
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

# Pytest-xdist for parallel testing (if installed)
# Run with: pytest -n auto
# numprocesses = auto
