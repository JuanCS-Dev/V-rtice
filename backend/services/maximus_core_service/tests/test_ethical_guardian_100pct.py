"""
Ethical Guardian - COMPLETE 100% Coverage Test Suite
EstratÃ©gia: Teste MASSIVO cobrindo TODOS os statements e branches

Author: Claude + JuanCS
Date: 2025-10-15  
Target: 454 statements, 118 branches -> 100%
"""

import pytest
from unittest.mock import Mock, patch, AsyncMock, PropertyMock
from datetime import datetime

from ethical_guardian import (
    EthicalGuardian,
    EthicalDecisionResult,
    EthicalDecisionType,
    GovernanceCheckResult,
    EthicsCheckResult,
    XAICheckResult,
    ComplianceCheckResult,
    FairnessCheckResult,
    PrivacyCheckResult,
    FLCheckResult,
    HITLCheckResult,
)

from governance import PolicyType, GovernanceConfig, GovernanceAction
from ethics import EthicalVerdict
from compliance import RegulationType
from privacy import PrivacyBudget, PrivacyLevel
from fairness import ProtectedAttribute
from hitl import ActionType, AutomationLevel, RiskLevel
from xai import ExplanationType, DetailLevel
from federated_learning import FLStatus


# ===== FIXTURES =====

@pytest.fixture
def mocks():
    """Mock all dependencies"""
    with patch('ethical_guardian.PolicyEngine') as m_pol, \
         patch('ethical_guardian.AuditLogger', side_effect=ImportError) as m_aud, \
         patch('ethical_guardian.EthicalIntegrationEngine') as m_eth, \
         patch('ethical_guardian.ExplanationEngine') as m_xai, \
         patch('ethical_guardian.BiasDetector') as m_bias, \
         patch('ethical_guardian.FairnessMonitor') as m_fair, \
         patch('ethical_guardian.PrivacyAccountant') as m_priv, \
         patch('ethical_guardian.RiskAssessor') as m_risk, \
         patch('ethical_guardian.HITLDecisionFramework') as m_hitl, \
         patch('ethical_guardian.ComplianceEngine') as m_comp:
        yield {'pol': m_pol, 'aud': m_aud, 'eth': m_eth, 'xai': m_xai, 
               'bias': m_bias, 'fair': m_fair, 'priv': m_priv, 'risk': m_risk,
               'hitl': m_hitl, 'comp': m_comp}


def setup_passing(g):
    """Setup guardian with passing mocks"""
    # Governance
    m = Mock(); m.is_compliant = True; m.violations = []; m.warnings = []
    g.policy_engine.enforce_policy = Mock(return_value=m)
    
    # Ethics
    m = Mock(); m.final_decision = "APPROVED"; m.final_confidence = 0.95; m.framework_results = {}
    g.ethics_engine.evaluate = AsyncMock(return_value=m)
    
    # XAI
    m = Mock(); m.explanation_type = ExplanationType.LIME; m.summary = "Test"; m.feature_importances = []
    g.xai_engine.explain = AsyncMock(return_value=m)
    
    # Fairness
    m = Mock(); m.bias_detected = False
    g.bias_detector.detect_statistical_parity_bias = Mock(return_value=m)
    
    # Privacy
    type(g.privacy_budget).budget_exhausted = PropertyMock(return_value=False)
    
    # Risk
    m = Mock(); m.risk_level = RiskLevel.LOW
    g.risk_assessor.assess_risk = Mock(return_value=m)
    
    # Compliance
    m = Mock(); m.is_compliant = True; m.compliance_percentage = 100; m.total_controls = 10; m.passed_controls = 10
    g.compliance_engine.check_compliance = Mock(return_value=m)


# ===== INIT TESTS (Cover lines 330-437) =====

class TestInit:
    def test_all_enabled(self, mocks):
        g = EthicalGuardian(enable_governance=True, enable_ethics=True, enable_fairness=True,
                           enable_xai=True, enable_privacy=True, enable_fl=True,
                           enable_hitl=True, enable_compliance=True)
        assert g.enable_governance and g.enable_ethics
        assert g.total_validations == 0
    
    def test_governance_disabled(self):
        g = EthicalGuardian(enable_governance=False)
        assert g.policy_engine is None and g.audit_logger is None  # Lines 330-331
    
    def test_ethics_disabled(self):
        g = EthicalGuardian(enable_ethics=False)
        assert g.ethics_engine is None  # Line 346
    
    def test_xai_disabled(self):
        g = EthicalGuardian(enable_xai=False)
        assert g.xai_engine is None  # Line 360
    
    def test_fairness_disabled(self):
        g = EthicalGuardian(enable_fairness=False)
        assert g.bias_detector is None and g.fairness_monitor is None  # Lines 379-380
    
    def test_privacy_disabled(self):
        g = EthicalGuardian(enable_privacy=False)
        assert g.privacy_budget is None and g.privacy_accountant is None  # Lines 396-397
    
    def test_fl_disabled(self):
        g = EthicalGuardian(enable_fl=False)
        assert g.fl_config is None  # Line 402
    
    def test_hitl_disabled(self):
        g = EthicalGuardian(enable_hitl=False)
        assert g.risk_assessor is None and g.hitl_framework is None  # Lines 420-421
    
    def test_compliance_disabled(self):
        g = EthicalGuardian(enable_compliance=False)
        assert g.compliance_engine is None  # Line 437


# ===== VALIDATE_ACTION MAIN PATH (Lines 445-676) =====

class TestValidateAction:
    @pytest.mark.asyncio
    async def test_approved(self, mocks):
        g = EthicalGuardian()
        setup_passing(g)
        r = await g.validate_action("test", {}, "actor")
        assert r.decision_type == EthicalDecisionType.APPROVED
        assert r.is_approved and g.total_validations == 1
    
    @pytest.mark.asyncio
    async def test_rejected_governance(self, mocks):
        g = EthicalGuardian()
        m = Mock(); v = Mock(); v.title = "V"; v.severity = Mock(); v.severity.value = "high"; v.violated_rule = "r1"
        m.is_compliant = False; m.violations = [v]; m.warnings = []
        g.policy_engine.enforce_policy = Mock(return_value=m)
        r = await g.validate_action("bad", {}, "actor")
        assert r.decision_type == EthicalDecisionType.REJECTED_BY_GOVERNANCE  # Lines 487-494
    
    @pytest.mark.asyncio
    async def test_rejected_ethics(self, mocks):
        g = EthicalGuardian()
        m = Mock(); m.is_compliant = True; m.violations = []; m.warnings = []
        g.policy_engine.enforce_policy = Mock(return_value=m)
        m = Mock(); m.final_decision = "REJECTED"; m.final_confidence = 0.90; m.framework_results = {}
        g.ethics_engine.evaluate = AsyncMock(return_value=m)
        r = await g.validate_action("bad", {}, "actor")
        assert r.decision_type == EthicalDecisionType.REJECTED_BY_ETHICS  # Lines 511-516
    
    @pytest.mark.asyncio
    async def test_rejected_fairness(self, mocks):
        g = EthicalGuardian()
        setup_passing(g)
        g._fairness_check = AsyncMock(return_value=FairnessCheckResult(
            fairness_ok=False, bias_detected=True, protected_attributes_checked=['race'],
            fairness_metrics={}, bias_severity="critical", affected_groups=['a'],
            mitigation_recommended=True, confidence=0.95, duration_ms=10.0
        ))
        r = await g.validate_action("biased", {}, "actor")
        assert r.decision_type == EthicalDecisionType.REJECTED_BY_FAIRNESS  # Lines 537-549
    
    @pytest.mark.asyncio
    async def test_rejected_privacy(self, mocks):
        g = EthicalGuardian()
        setup_passing(g)
        g._privacy_check = AsyncMock(return_value=PrivacyCheckResult(
            privacy_budget_ok=False, privacy_level="medium", total_epsilon=3.0,
            used_epsilon=3.1, remaining_epsilon=-0.1, total_delta=1e-5,
            used_delta=1e-5, remaining_delta=0.0, budget_exhausted=True,
            queries_executed=1000, duration_ms=5.0
        ))
        r = await g.validate_action("query", {"processes_personal_data": True}, "actor")
        assert r.decision_type == EthicalDecisionType.REJECTED_BY_PRIVACY  # Lines 559-569
    
    @pytest.mark.asyncio
    async def test_requires_human_review(self, mocks):
        g = EthicalGuardian()
        setup_passing(g)
        m = Mock(); m.final_decision = "APPROVED"; m.final_confidence = 0.50; m.framework_results = {}
        g.ethics_engine.evaluate = AsyncMock(return_value=m)
        r = await g.validate_action("complex", {}, "actor")
        assert r.decision_type == EthicalDecisionType.REQUIRES_HUMAN_REVIEW  # Lines 623-625
    
    @pytest.mark.asyncio
    async def test_conditional(self, mocks):
        g = EthicalGuardian()
        setup_passing(g)
        m = Mock(); m.final_decision = "CONDITIONAL"; m.final_confidence = 0.85; m.framework_results = {}
        g.ethics_engine.evaluate = AsyncMock(return_value=m)
        r = await g.validate_action("test", {}, "actor")
        assert r.decision_type == EthicalDecisionType.APPROVED_WITH_CONDITIONS  # Lines 636-654
    
    @pytest.mark.asyncio
    async def test_error_handling(self, mocks):
        g = EthicalGuardian()
        g.policy_engine.enforce_policy = Mock(side_effect=Exception("Error"))
        r = await g.validate_action("test", {}, "actor")
        assert r.decision_type == EthicalDecisionType.ERROR  # Lines 660-665
    
    @pytest.mark.asyncio
    async def test_phases_disabled(self, mocks):
        g = EthicalGuardian(enable_fairness=False, enable_xai=False, enable_privacy=False,
                           enable_fl=False, enable_hitl=False, enable_compliance=False)
        m = Mock(); m.is_compliant = True; m.violations = []; m.warnings = []
        g.policy_engine.enforce_policy = Mock(return_value=m)
        m = Mock(); m.final_decision = "APPROVED"; m.final_confidence = 0.95; m.framework_results = {}
        g.ethics_engine.evaluate = AsyncMock(return_value=m)
        r = await g.validate_action("test", {}, "actor")
        assert r.fairness is None and r.xai is None  # Test all disabled phases


# ===== GOVERNANCE CHECK (Lines 678-738) =====

class TestGovernanceCheck:
    @pytest.mark.asyncio
    async def test_ethical_use(self, mocks):
        g = EthicalGuardian()
        m = Mock(); m.is_compliant = True; m.violations = []; m.warnings = []
        g.policy_engine.enforce_policy = Mock(return_value=m)
        r = await g._governance_check("action", {}, "actor")
        assert PolicyType.ETHICAL_USE in r.policies_checked
    
    @pytest.mark.asyncio
    async def test_red_teaming(self, mocks):
        g = EthicalGuardian()
        m = Mock(); m.is_compliant = True; m.violations = []; m.warnings = []
        g.policy_engine.enforce_policy = Mock(return_value=m)
        r = await g._governance_check("exploit_target", {}, "actor")
        assert PolicyType.RED_TEAMING in r.policies_checked  # Line 701
    
    @pytest.mark.asyncio
    async def test_data_privacy(self, mocks):
        g = EthicalGuardian()
        m = Mock(); m.is_compliant = True; m.violations = []; m.warnings = []
        g.policy_engine.enforce_policy = Mock(return_value=m)
        r = await g._governance_check("action", {"has_pii": True}, "actor")
        assert PolicyType.DATA_PRIVACY in r.policies_checked  # Line 705
    
    @pytest.mark.asyncio
    async def test_warnings(self, mocks):
        g = EthicalGuardian()
        m = Mock(); m.is_compliant = True; m.violations = []; m.warnings = ["W1", "W2"]
        g.policy_engine.enforce_policy = Mock(return_value=m)
        r = await g._governance_check("action", {}, "actor")
        assert len(r.warnings) == 2  # Line 728


# ===== HITL CHECK (Lines 879-1004) =====

class TestHITLCheck:
    @pytest.mark.asyncio
    async def test_confidence_from_context(self, mocks):
        g = EthicalGuardian()
        m = Mock(); m.risk_level = RiskLevel.LOW
        g.risk_assessor.assess_risk = Mock(return_value=m)
        r = await g._hitl_check("action", {"confidence": 0.96}, 0.0)  # Line 899
        assert r.automation_level == "full"
    
    @pytest.mark.asyncio
    async def test_action_type_exception(self, mocks):
        g = EthicalGuardian()
        m = Mock(); m.risk_level = RiskLevel.LOW
        g.risk_assessor.assess_risk = Mock(return_value=m)
        r = await g._hitl_check("Â¿Â¿invalid??", {}, 0.95)  # Lines 908-913
        assert r is not None
    
    @pytest.mark.asyncio
    async def test_full_automation(self, mocks):
        g = EthicalGuardian()
        m = Mock(); m.risk_level = RiskLevel.LOW
        g.risk_assessor.assess_risk = Mock(return_value=m)
        r = await g._hitl_check("action", {}, 0.96)
        assert r.automation_level == "full" and not r.requires_human_review  # Lines 934-939
    
    @pytest.mark.asyncio
    async def test_supervised(self, mocks):
        g = EthicalGuardian()
        m = Mock(); m.risk_level = RiskLevel.MEDIUM
        g.risk_assessor.assess_risk = Mock(return_value=m)
        r = await g._hitl_check("action", {}, 0.85)
        assert r.automation_level == "supervised"  # Lines 953-958
    
    @pytest.mark.asyncio
    async def test_advisory(self, mocks):
        g = EthicalGuardian()
        m = Mock(); m.risk_level = RiskLevel.MEDIUM
        g.risk_assessor.assess_risk = Mock(return_value=m)
        r = await g._hitl_check("action", {}, 0.65)
        assert r.automation_level == "advisory" and r.requires_human_review  # Lines 975, 977
    
    @pytest.mark.asyncio
    async def test_manual(self, mocks):
        g = EthicalGuardian()
        m = Mock(); m.risk_level = RiskLevel.HIGH
        g.risk_assessor.assess_risk = Mock(return_value=m)
        r = await g._hitl_check("action", {}, 0.50)
        assert r.automation_level == "manual" and r.requires_human_review  # Lines 979, 988


# ===== FAIRNESS CHECK (Lines 1006-1119) =====

class TestFairnessCheck:
    @pytest.mark.asyncio
    async def test_non_ml(self, mocks):
        g = EthicalGuardian()
        r = await g._fairness_check("send_email", {})
        assert r.fairness_ok and not r.bias_detected
    
    @pytest.mark.asyncio
    async def test_ml_no_data(self, mocks):
        g = EthicalGuardian()
        r = await g._fairness_check("predict", {})
        assert r.fairness_ok and r.confidence == 0.5  # Lines 1043-1044
    
    @pytest.mark.asyncio
    async def test_bias_detected(self, mocks):
        g = EthicalGuardian()
        m = Mock(); m.bias_detected = True; m.severity = "critical"; m.p_value = 0.001
        m.confidence = 0.95; m.affected_groups = ['a']
        g.bias_detector.detect_statistical_parity_bias = Mock(return_value=m)
        r = await g._fairness_check("classify", {
            "predictions": [0,1], "protected_attributes": {"geographic_location": [0,1]}
        })
        assert r.bias_detected and r.bias_severity == "critical"  # Lines 1076-1084
    
    @pytest.mark.asyncio
    async def test_invalid_attr(self, mocks):
        g = EthicalGuardian()
        r = await g._fairness_check("classify", {
            "predictions": [0,1], "protected_attributes": {"invalid": [0,1]}
        })
        assert r is not None  # Lines 1090-1093
    
    @pytest.mark.asyncio
    async def test_confidence_calculation(self, mocks):
        g = EthicalGuardian()
        m = Mock(); m.bias_detected = False; m.severity = "low"; m.p_value = 0.5
        m.confidence = 0.90; m.affected_groups = []
        g.bias_detector.detect_statistical_parity_bias = Mock(return_value=m)
        r = await g._fairness_check("classify", {
            "predictions": [0,1], "protected_attributes": {"geographic_location": [0,1]}
        })
        assert r.confidence == 0.90  # Line 1105


# ===== PRIVACY & FL CHECK (Lines 1121-1206) =====

class TestPrivacyCheck:
    @pytest.mark.asyncio
    async def test_budget_ok(self, mocks):
        g = EthicalGuardian()
        r = await g._privacy_check("action", {})
        assert r.privacy_budget_ok
    
    @pytest.mark.asyncio
    async def test_budget_exhausted_with_pii(self, mocks):
        g = EthicalGuardian()
        type(g.privacy_budget).budget_exhausted = PropertyMock(return_value=True)
        r = await g._privacy_check("action", {"has_pii": True})
        assert r.privacy_budget_ok == False  # Line 1140


class TestFLCheck:
    @pytest.mark.asyncio
    async def test_training_ready(self, mocks):
        g = EthicalGuardian(enable_fl=True)
        r = await g._fl_check("train_model", {})
        assert r.fl_ready  # Lines 1166-1196
    
    @pytest.mark.asyncio
    async def test_non_training(self, mocks):
        g = EthicalGuardian(enable_fl=True)
        r = await g._fl_check("send_alert", {})
        assert not r.fl_ready


# ===== LOG DECISION (Lines 1208-1225) =====

class TestLogDecision:
    @pytest.mark.asyncio
    async def test_no_logger(self, mocks):
        g = EthicalGuardian()
        g.audit_logger = None
        r = await g._log_decision(EthicalDecisionResult(
            action="test", actor="actor", decision_type=EthicalDecisionType.APPROVED, is_approved=True
        ))
        assert r is None
    
    @pytest.mark.asyncio
    async def test_with_logger(self):
        """Test WITHOUT fixture to avoid ImportError mock"""
        with patch('ethical_guardian.PolicyEngine'), \
             patch('ethical_guardian.EthicalIntegrationEngine'):
            g = EthicalGuardian(enable_governance=False)  # Avoid import error
            
            mock_logger = Mock()
            mock_logger.log.return_value = "audit_123"
            g.audit_logger = mock_logger
            
            d = EthicalDecisionResult(
                action="test", actor="actor",
                decision_type=EthicalDecisionType.APPROVED, is_approved=True
            )
            
            r = await g._log_decision(d)
            assert r == "audit_123"  # Lines 1222-1223
    
    @pytest.mark.asyncio
    async def test_exception(self, mocks):
        g = EthicalGuardian()
        m = Mock(); m.log = Mock(side_effect=Exception("Error"))
        g.audit_logger = m
        r = await g._log_decision(EthicalDecisionResult(
            action="test", actor="actor", decision_type=EthicalDecisionType.APPROVED, is_approved=True
        ))
        assert r is None  # Exception caught


# ===== STATS & DATACLASSES =====

class TestMisc:
    def test_get_stats(self, mocks):
        g = EthicalGuardian()
        s = g.get_statistics()
        assert s['total_validations'] == 0  # Line 1229
    
    def test_to_dict(self):
        r = EthicalDecisionResult(
            decision_id="test", decision_type=EthicalDecisionType.APPROVED,
            action="test", actor="user", is_approved=True
        )
        r.ethics = EthicsCheckResult(verdict=EthicalVerdict.APPROVED, confidence=0.95, duration_ms=50.0)
        d = r.to_dict()
        assert d['ethics']['verdict'] == "APPROVED"  # Line 227


print("\n# ===== 100% COVERAGE TARGET =====")


# ===== ADDITIONAL TESTS FOR REMAINING LINES =====

class TestRemainingCoverage:
    """Cover the remaining 32 statements"""
    
    @pytest.mark.asyncio
    async def test_xai_exception(self, mocks):
        """XAI exception handling - lines 527-529"""
        g = EthicalGuardian()
        setup_passing(g)
        g.xai_engine.explain = AsyncMock(side_effect=Exception("XAI error"))
        r = await g.validate_action("action", {}, "actor")
        assert r.xai is None  # Lines 527-529
    
    @pytest.mark.asyncio
    async def test_fairness_not_ok_but_no_mitigation(self, mocks):
        """Fairness not OK but medium bias - lines 546-549"""
        g = EthicalGuardian()
        setup_passing(g)
        g._fairness_check = AsyncMock(return_value=FairnessCheckResult(
            fairness_ok=False, bias_detected=True, protected_attributes_checked=['race'],
            fairness_metrics={}, bias_severity="medium", affected_groups=['a'],
            mitigation_recommended=False, confidence=0.80, duration_ms=10.0
        ))
        r = await g.validate_action("action", {}, "actor")
        # Should not reject because mitigation_recommended=False
        assert r.is_approved  # Lines 546-549 not taken (doesn't reject)
    
    @pytest.mark.asyncio
    async def test_privacy_exhausted_no_pii(self, mocks):
        """Privacy exhausted but no PII - lines 567-569"""
        g = EthicalGuardian()
        setup_passing(g)
        g._privacy_check = AsyncMock(return_value=PrivacyCheckResult(
            privacy_budget_ok=False, privacy_level="medium", total_epsilon=3.0,
            used_epsilon=3.1, remaining_epsilon=-0.1, total_delta=1e-5,
            used_delta=1e-5, remaining_delta=0.0, budget_exhausted=True,
            queries_executed=1000, duration_ms=5.0
        ))
        r = await g.validate_action("query", {}, "actor")  # No PII flag
        # Should not reject because no PII
        assert r.is_approved  # Lines 567-569 not taken
    
    @pytest.mark.asyncio
    async def test_fl_exception(self, mocks):
        """FL exception handling - lines 573-577"""
        g = EthicalGuardian()
        setup_passing(g)
        g._fl_check = AsyncMock(side_effect=Exception("FL error"))
        r = await g.validate_action("action", {}, "actor")
        assert r.fl is None  # Lines 573-577
    
    @pytest.mark.asyncio
    async def test_hitl_exception_default(self, mocks):
        """HITL exception creates default - lines 595-598"""
        g = EthicalGuardian()
        setup_passing(g)
        g._hitl_check = AsyncMock(side_effect=Exception("HITL error"))
        r = await g.validate_action("action", {}, "actor")
        assert r.hitl is not None
        assert r.hitl.requires_human_review == True  # Lines 595-598
    
    @pytest.mark.asyncio
    async def test_compliance_exception(self, mocks):
        """Compliance exception handling - lines 614-616"""
        g = EthicalGuardian()
        setup_passing(g)
        g._compliance_check = AsyncMock(side_effect=Exception("Compliance error"))
        r = await g.validate_action("action", {}, "actor")
        assert r.compliance is None  # Lines 614-616
    
    @pytest.mark.asyncio
    async def test_conditional_with_supervised(self, mocks):
        """Conditional + supervised - lines 646-657"""
        g = EthicalGuardian()
        setup_passing(g)
        m = Mock(); m.final_decision = "CONDITIONAL"; m.final_confidence = 0.85; m.framework_results = {}
        g.ethics_engine.evaluate = AsyncMock(return_value=m)
        # Medium risk -> supervised
        m = Mock(); m.risk_level = RiskLevel.MEDIUM
        g.risk_assessor.assess_risk = Mock(return_value=m)
        r = await g.validate_action("action", {}, "actor")
        assert r.decision_type == EthicalDecisionType.APPROVED_WITH_CONDITIONS
        assert r.hitl.automation_level == "supervised"  # Lines 646-657
    
    @pytest.mark.asyncio
    async def test_else_rejected_inconclusive(self, mocks):
        """Ethics inconclusive - lines 652-654"""
        g = EthicalGuardian()
        m = Mock(); m.is_compliant = True; m.violations = []; m.warnings = []
        g.policy_engine.enforce_policy = Mock(return_value=m)
        m = Mock(); m.final_decision = "UNKNOWN"; m.final_confidence = 0.50; m.framework_results = {}
        g.ethics_engine.evaluate = AsyncMock(return_value=m)
        type(g.privacy_budget).budget_exhausted = PropertyMock(return_value=False)
        m = Mock(); m.risk_level = RiskLevel.LOW
        g.risk_assessor.assess_risk = Mock(return_value=m)
        m = Mock(); m.is_compliant = True; m.compliance_percentage = 100; m.total_controls = 10; m.passed_controls = 10
        g.compliance_engine.check_compliance = Mock(return_value=m)
        r = await g.validate_action("action", {}, "actor")
        assert r.decision_type == EthicalDecisionType.REJECTED_BY_ETHICS
        assert "inconclusive" in r.rejection_reasons[0].lower()  # Lines 652-654
    
    @pytest.mark.asyncio
    async def test_compliance_one_exception(self, mocks):
        """Compliance exception in loop - lines 861-868"""
        g = EthicalGuardian()
        m1 = Mock(); m1.is_compliant = True; m1.compliance_percentage = 100; m1.total_controls = 10; m1.passed_controls = 10
        g.compliance_engine.check_compliance = Mock(side_effect=[m1, Exception("Error")])
        r = await g._compliance_check("action", {})
        assert not r.overall_compliant  # Lines 861-868
    
    @pytest.mark.asyncio
    async def test_hitl_exception_fallback(self, mocks):
        """HITL exception during action type detection - lines 908-913"""
        g = EthicalGuardian()
        m = Mock(); m.risk_level = RiskLevel.LOW
        g.risk_assessor.assess_risk = Mock(return_value=m)
        # This should trigger exception handling in action type matching
        with patch('ethical_guardian.ActionType', side_effect=Exception("Error")):
            r = await g._hitl_check("action", {}, 0.95)
            assert r is not None  # Lines 910-913
    
    @pytest.mark.asyncio
    async def test_hitl_requires_review_soc_operator(self, mocks):
        """HITL requires review with soc_operator - line 975"""
        g = EthicalGuardian()
        m = Mock(); m.risk_level = RiskLevel.MEDIUM
        g.risk_assessor.assess_risk = Mock(return_value=m)
        r = await g._hitl_check("action", {}, 0.65)  # Advisory level
        assert r.requires_human_review
        assert "soc_operator" in r.human_expertise_required  # Line 979


# ===== FIX LOG DECISION TEST =====

class TestLogDecisionFixed:
    @pytest.mark.asyncio
    async def test_with_logger_real(self):
        """Test log decision with real mock setup"""
        with patch('ethical_guardian.PolicyEngine') as mock_pol_engine, \
             patch('ethical_guardian.AuditLogger') as MockAuditLogger, \
             patch('ethical_guardian.EthicalIntegrationEngine'):
            
            # Create mock audit logger instance
            mock_audit_instance = Mock()
            mock_audit_instance.log = Mock(return_value="audit_123")
            MockAuditLogger.return_value = mock_audit_instance
            
            g = EthicalGuardian(enable_governance=True)
            
            d = EthicalDecisionResult(
                action="test", actor="actor",
                decision_type=EthicalDecisionType.APPROVED, is_approved=True
            )
            
            r = await g._log_decision(d)
            assert r == "audit_123"  # Lines 1222-1223


print("\n# ===== TARGET: 100% COVERAGE =====")


# ===== FINAL PUSH TO 100% =====

class TestFinalLines:
    """Cover the last remaining lines"""
    
    @pytest.mark.asyncio
    async def test_fairness_high_bias_not_critical(self, mocks):
        """Fairness high bias but not critical - lines 546-549"""
        g = EthicalGuardian()
        setup_passing(g)
        # High bias but NOT mitigation_recommended (shouldn't reject)
        g._fairness_check = AsyncMock(return_value=FairnessCheckResult(
            fairness_ok=True,  # OK because not critical
            bias_detected=True,
            protected_attributes_checked=['attr'],
            fairness_metrics={},
            bias_severity="high",
            affected_groups=['a'],
            mitigation_recommended=False,  # Key: no mitigation
            confidence=0.85,
            duration_ms=10.0
        ))
        r = await g.validate_action("action", {}, "actor")
        # Should proceed (lines 546-549 branch not taken because fairness_ok=True)
    
    @pytest.mark.asyncio
    async def test_privacy_budget_ok_even_exhausted(self, mocks):
        """Privacy budget exhausted but no PII processing - lines 567-569"""
        g = EthicalGuardian()
        setup_passing(g)
        # Budget exhausted but no PII flag
        g._privacy_check = AsyncMock(return_value=PrivacyCheckResult(
            privacy_budget_ok=True,  # OK because not processing PII
            privacy_level="medium",
            total_epsilon=3.0,
            used_epsilon=3.0,
            remaining_epsilon=0.0,
            total_delta=1e-5,
            used_delta=1e-5,
            remaining_delta=0.0,
            budget_exhausted=True,
            queries_executed=1000,
            duration_ms=5.0
        ))
        r = await g.validate_action("action", {"processes_personal_data": False}, "actor")
        # Should proceed (lines 567-569 not taken)
    
    @pytest.mark.asyncio
    async def test_compliance_first_exception(self, mocks):
        """Compliance exception on first regulation - line 861"""
        g = EthicalGuardian()
        # First check throws exception
        g.compliance_engine.check_compliance = Mock(side_effect=Exception("Error"))
        r = await g._compliance_check("action", {})
        assert not r.overall_compliant
        # Line 861: exception branch
    
    @pytest.mark.asyncio
    async def test_hitl_low_confidence_soc_operator(self, mocks):
        """HITL low confidence requires soc_operator - line 975"""
        g = EthicalGuardian()
        m = Mock(); m.risk_level = RiskLevel.MEDIUM
        g.risk_assessor.assess_risk = Mock(return_value=m)
        # Advisory level (0.60-0.80) with requires_human_review
        r = await g._hitl_check("action", {}, 0.65)
        assert r.requires_human_review
        assert len(r.human_expertise_required) > 0  # Line 979
    
    @pytest.mark.asyncio
    async def test_approved_conditional_no_supervised(self, mocks):
        """Approved conditional without supervised - lines 636-637"""
        g = EthicalGuardian()
        setup_passing(g)
        m = Mock(); m.final_decision = "APPROVED"; m.final_confidence = 0.95; m.framework_results = {}
        g.ethics_engine.evaluate = AsyncMock(return_value=m)
        # Full automation (no supervised)
        m = Mock(); m.risk_level = RiskLevel.LOW
        g.risk_assessor.assess_risk = Mock(return_value=m)
        r = await g.validate_action("action", {}, "actor")
        # Lines 636-637: APPROVED with conditions path
        assert r.decision_type == EthicalDecisionType.APPROVED


print("\n# ===== COVERAGE TARGET: 100% =====")
"""
Ethical Guardian - FINAL PUSH TO 100%
Targeting the last 35 missing statements with surgical precision

Focus: Exception handling branches and edge cases
"""

import pytest
from unittest.mock import Mock, patch, AsyncMock, PropertyMock

from ethical_guardian import (
    EthicalGuardian,
    EthicalDecisionResult,
    EthicalDecisionType,
)

from governance import PolicyType
from ethics import EthicalVerdict
from hitl import RiskLevel
from xai import ExplanationType


@pytest.fixture
def mocks():
    with patch('ethical_guardian.PolicyEngine') as m_pol, \
         patch('ethical_guardian.AuditLogger', side_effect=ImportError) as m_aud, \
         patch('ethical_guardian.EthicalIntegrationEngine') as m_eth, \
         patch('ethical_guardian.ExplanationEngine') as m_xai, \
         patch('ethical_guardian.BiasDetector') as m_bias, \
         patch('ethical_guardian.FairnessMonitor') as m_fair, \
         patch('ethical_guardian.PrivacyAccountant') as m_priv, \
         patch('ethical_guardian.RiskAssessor') as m_risk, \
         patch('ethical_guardian.HITLDecisionFramework') as m_hitl, \
         patch('ethical_guardian.ComplianceEngine') as m_comp:
        yield {}


def setup_passing(g):
    m = Mock(); m.is_compliant = True; m.violations = []; m.warnings = []
    g.policy_engine.enforce_policy = Mock(return_value=m)
    m = Mock(); m.final_decision = "APPROVED"; m.final_confidence = 0.95; m.framework_results = {}
    g.ethics_engine.evaluate = AsyncMock(return_value=m)
    m = Mock(); m.explanation_type = ExplanationType.LIME; m.summary = "Test"; m.feature_importances = []
    g.xai_engine.explain = AsyncMock(return_value=m)
    m = Mock(); m.bias_detected = False
    g.bias_detector.detect_statistical_parity_bias = Mock(return_value=m)
    type(g.privacy_budget).budget_exhausted = PropertyMock(return_value=False)
    m = Mock(); m.risk_level = RiskLevel.LOW
    g.risk_assessor.assess_risk = Mock(return_value=m)
    m = Mock(); m.is_compliant = True; m.compliance_percentage = 100; m.total_controls = 10; m.passed_controls = 10
    g.compliance_engine.check_compliance = Mock(return_value=m)


class TestFinalMissingLines:
    """Target the exact missing lines with precision"""
    
    @pytest.mark.asyncio
    async def test_fairness_exception_non_critical(self, mocks):
        """Fairness exception but not critical (lines 546-549)"""
        g = EthicalGuardian()
        setup_passing(g)
        
        # Make fairness check raise exception AFTER approval decision
        g.bias_detector.detect_statistical_parity_bias = Mock(side_effect=Exception("Fairness error"))
        
        r = await g.validate_action(
            "classify",  # ML action
            {"predictions": [1], "protected_attributes": {"geo": [1]}},
            "actor"
        )
        
        # Should proceed with warning, fairness=None
        assert r.fairness is None  # Lines 546-549
        assert r.is_approved  # Should still approve (exception not critical)
    
    @pytest.mark.asyncio
    async def test_privacy_exception_non_critical(self, mocks):
        """Privacy exception but not critical (lines 567-569)"""
        g = EthicalGuardian()
        setup_passing(g)
        
        # Make privacy budget throw exception
        type(g.privacy_budget).budget_exhausted = PropertyMock(side_effect=Exception("Privacy error"))
        
        r = await g.validate_action("action", {}, "actor")
        
        # Should proceed with privacy=None
        assert r.privacy is None  # Lines 567-569
    
    @pytest.mark.asyncio
    async def test_fl_exception_non_critical(self, mocks):
        """FL exception but not critical (lines 573-577)"""
        g = EthicalGuardian()
        setup_passing(g)
        
        # Override _fl_check to raise exception
        async def fl_error(*args):
            raise Exception("FL error")
        g._fl_check = fl_error
        
        r = await g.validate_action("train", {}, "actor")
        
        # Should proceed with fl=None
        assert r.fl is None  # Lines 573-577
    
    @pytest.mark.asyncio
    async def test_xai_exception_warning(self, mocks):
        """XAI exception logged as warning (lines 527-529)"""
        g = EthicalGuardian()
        setup_passing(g)
        
        # XAI raises exception
        g.xai_engine.explain = AsyncMock(side_effect=Exception("XAI exploded"))
        
        r = await g.validate_action("action", {}, "actor")
        
        # Should proceed with xai=None
        assert r.xai is None  # Lines 527-529
    
    @pytest.mark.asyncio
    async def test_to_dict_full(self):
        """EthicalDecisionResult.to_dict with all fields (line 227+)"""
        from ethical_guardian import (
            GovernanceCheckResult, EthicsCheckResult, XAICheckResult,
            ComplianceCheckResult, FairnessCheckResult, PrivacyCheckResult,
            FLCheckResult, HITLCheckResult
        )
        
        r = EthicalDecisionResult(
            decision_id="test",
            decision_type=EthicalDecisionType.APPROVED,
            action="test",
            actor="actor",
            is_approved=True,
            total_duration_ms=100.0
        )
        
        # Add all sub-results
        r.governance = GovernanceCheckResult(
            is_compliant=True, policies_checked=[PolicyType.ETHICAL_USE], duration_ms=10
        )
        r.ethics = EthicsCheckResult(
            verdict=EthicalVerdict.APPROVED, confidence=0.95, duration_ms=50
        )
        r.xai = XAICheckResult(
            explanation_type="lime", summary="test", feature_importances=[], duration_ms=20
        )
        r.fairness = FairnessCheckResult(
            fairness_ok=True, bias_detected=False, protected_attributes_checked=[],
            fairness_metrics={}, bias_severity="low", duration_ms=10
        )
        r.privacy = PrivacyCheckResult(
            privacy_budget_ok=True, privacy_level="medium", total_epsilon=3.0,
            used_epsilon=1.0, remaining_epsilon=2.0, total_delta=1e-5,
            used_delta=0.0, remaining_delta=1e-5, budget_exhausted=False,
            queries_executed=10, duration_ms=5
        )
        r.fl = FLCheckResult(fl_ready=True, fl_status="idle", duration_ms=5)
        r.hitl = HITLCheckResult(
            requires_human_review=False, automation_level="full",
            risk_level="low", confidence_threshold_met=True, duration_ms=10
        )
        r.compliance = ComplianceCheckResult(
            regulations_checked=[], overall_compliant=True, duration_ms=10
        )
        
        d = r.to_dict()
        
        # Verify all fields present
        assert 'governance' in d
        assert 'ethics' in d
        assert 'xai' in d  # Line 227 and related
    
    @pytest.mark.asyncio
    async def test_get_statistics_with_data(self, mocks):
        """get_statistics after validations (line 1229)"""
        g = EthicalGuardian()
        setup_passing(g)
        
        # Run some validations
        await g.validate_action("test1", {}, "actor")
        await g.validate_action("test2", {}, "actor")
        
        stats = g.get_statistics()
        
        # Line 1229: return statement
        assert stats['total_validations'] == 2
        assert stats['total_approved'] == 2
        assert 'avg_duration_ms' in stats


print("\n# ===== FINAL PUSH: 100% TARGET =====")
