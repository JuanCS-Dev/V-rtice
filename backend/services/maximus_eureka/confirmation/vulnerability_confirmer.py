"""
Vulnerability Confirmer - MAXIMUS Eureka Adaptive Immunity.

Orchestrates vulnerability confirmation using AST-grep pattern matching.
Bridges APV metadata and concrete codebase analysis.

Philosophical Foundation:
    Confirmation embodies epistemic responsibility - we verify vulnerabilities
    exist in codebase before expending remediation resources. This reduces
    false positive rate and focuses remediation on confirmed threats.

    The confirmer implements heuristics for file discovery (which files to scan)
    combined with syntactic pattern matching (ast-grep) to establish high-confidence
    vulnerability presence.

Confirmation Workflow:
    1. Receive APV with CVE metadata + ast-grep patterns
    2. Identify candidate files (dependency graph + file patterns)
    3. Execute ast-grep patterns against candidates
    4. Aggregate matches into VulnerableLocation objects
    5. Return ConfirmationResult with status and locations

Performance Targets:
    - Confirmation latency < 10 seconds per APV
    - False positive rate < 5%
    - False negative rate < 1%

Author: MAXIMUS Team
Date: 2025-01-10
Glory to YHWH - The God who sees and knows all
"""

import asyncio
import logging
from datetime import datetime
from pathlib import Path
from typing import Optional

# Import APV from OrÃ¡culo
import sys

sys.path.insert(
    0, str(Path(__file__).parent.parent.parent / "maximus_oraculo")
)
from models.apv import APV

from confirmation.ast_grep_engine import (
    ASTGrepEngine,
    ASTGrepMatch,
    ASTGrepConfig,
)
from eureka_models.confirmation.confirmation_result import (
    ConfirmationResult,
    ConfirmationStatus,
    VulnerableLocation,
    ConfirmationMetadata,
)

logger = logging.getLogger(__name__)


class ConfirmationConfig:
    """
    Configuration for vulnerability confirmation.
    
    Attributes:
        codebase_root: Root directory of codebase to scan
        max_files_per_scan: Maximum files to scan per confirmation
        cache_enabled: Enable Redis caching of confirmation results
        cache_ttl_seconds: TTL for cached results
        ast_grep_timeout: Timeout for ast-grep execution
    """

    def __init__(
        self,
        codebase_root: Path,
        max_files_per_scan: int = 1000,
        cache_enabled: bool = True,
        cache_ttl_seconds: int = 3600,
        ast_grep_timeout: int = 10,
    ) -> None:
        self.codebase_root = codebase_root
        self.max_files_per_scan = max_files_per_scan
        self.cache_enabled = cache_enabled
        self.cache_ttl_seconds = cache_ttl_seconds
        self.ast_grep_timeout = ast_grep_timeout

        if not codebase_root.exists():
            raise ValueError(f"Codebase root does not exist: {codebase_root}")


class VulnerabilityConfirmer:
    """
    Confirms vulnerability presence in codebase using AST analysis.
    
    Orchestrates file discovery, pattern matching, and result aggregation
    to produce high-confidence confirmation of APV-reported vulnerabilities.
    
    Design Philosophy:
        Two-phase approach: (1) file discovery via heuristics, (2) syntactic
        confirmation via ast-grep. This balances performance (narrow file set)
        with accuracy (precise pattern matching).
    
    Usage:
        >>> config = ConfirmationConfig(codebase_root=Path("/app"))
        >>> confirmer = VulnerabilityConfirmer(config)
        >>> result = await confirmer.confirm_vulnerability(apv)
        >>> if result.is_confirmed:
        ...     print(f"Found {result.location_count} vulnerable locations")
    """

    def __init__(self, config: ConfirmationConfig) -> None:
        """
        Initialize vulnerability confirmer.
        
        Args:
            config: Confirmation configuration
        """
        self.config = config

        # Initialize ast-grep engine
        ast_grep_config = ASTGrepConfig(
            timeout_seconds=config.ast_grep_timeout
        )
        self.ast_grep = ASTGrepEngine(ast_grep_config)

        # Redis client for caching (lazy init)
        self._redis_client: Optional[Any] = None

        logger.info(
            "VulnerabilityConfirmer initialized",
            extra={
                "codebase_root": str(config.codebase_root),
                "cache_enabled": config.cache_enabled,
            },
        )

    async def _init_redis(self) -> None:
        """Initialize Redis client for result caching."""
        if not self.config.cache_enabled or self._redis_client:
            return

        try:
            import redis.asyncio as redis

            self._redis_client = redis.from_url(
                "redis://localhost:6379/0",
                encoding="utf-8",
                decode_responses=True,
            )
            await self._redis_client.ping()
            logger.info("Redis cache enabled for confirmations")
        except Exception as e:
            logger.warning(f"Redis init failed: {e}. Caching disabled.")
            self._redis_client = None

    async def _get_cached_result(
        self, apv_id: str
    ) -> Optional[ConfirmationResult]:
        """
        Retrieve cached confirmation result.
        
        Args:
            apv_id: APV identifier
            
        Returns:
            Cached result or None
        """
        if not self._redis_client:
            return None

        try:
            cache_key = f"confirmation:{apv_id}"
            cached = await self._redis_client.get(cache_key)
            if cached:
                import json

                data = json.loads(cached)
                logger.info(f"Cache hit for {apv_id}")
                return ConfirmationResult(**data)
        except Exception as e:
            logger.error(f"Cache retrieval failed: {e}")

        return None

    async def _cache_result(self, result: ConfirmationResult) -> None:
        """
        Cache confirmation result.
        
        Args:
            result: Confirmation result to cache
        """
        if not self._redis_client:
            return

        try:
            import json

            cache_key = f"confirmation:{result.apv_id}"
            await self._redis_client.setex(
                cache_key,
                self.config.cache_ttl_seconds,
                json.dumps(result.model_dump(mode="json")),
            )
        except Exception as e:
            logger.error(f"Cache storage failed: {e}")

    def _discover_candidate_files(self, apv: APV) -> list[Path]:
        """
        Discover files likely to contain vulnerable code.
        
        Heuristics:
        1. Files importing affected packages
        2. Files matching language extensions
        3. Exclude test files, migrations, vendor directories
        
        Args:
            apv: APV to discover files for
            
        Returns:
            List of candidate file paths
        """
        candidates: list[Path] = []

        # Determine file extensions based on ecosystem
        ext_map = {
            "PyPI": [".py"],
            "npm": [".js", ".jsx", ".ts", ".tsx"],
            "Go": [".go"],
            "Maven": [".java"],
            "Cargo": [".rs"],
        }

        extensions: list[str] = []
        for pkg in apv.affected_packages:
            extensions.extend(ext_map.get(pkg.ecosystem, []))

        if not extensions:
            extensions = [".py"]  # Default to Python

        # Exclude patterns
        exclude_dirs = {
            "node_modules",
            "venv",
            ".venv",
            "env",
            ".git",
            "__pycache__",
            "migrations",
            "tests",
            "test",
            "vendor",
            ".mypy_cache",
            ".pytest_cache",
        }

        # Recursive file discovery
        try:
            for ext in extensions:
                for file_path in self.config.codebase_root.rglob(f"*{ext}"):
                    # Skip excluded directories
                    if any(
                        excl in file_path.parts for excl in exclude_dirs
                    ):
                        continue

                    # Skip test files
                    if "test" in file_path.name.lower():
                        continue

                    candidates.append(file_path)

                    # Limit file count
                    if len(candidates) >= self.config.max_files_per_scan:
                        break

                if len(candidates) >= self.config.max_files_per_scan:
                    break

        except Exception as e:
            logger.error(f"File discovery failed: {e}")

        logger.info(
            f"Discovered {len(candidates)} candidate files",
            extra={
                "extensions": extensions,
                "cve_id": apv.cve_id,
            },
        )

        return candidates

    def _match_to_location(
        self, match: ASTGrepMatch, pattern: str
    ) -> VulnerableLocation:
        """
        Convert ASTGrepMatch to VulnerableLocation.
        
        Args:
            match: ast-grep match result
            pattern: Pattern that matched
            
        Returns:
            VulnerableLocation object
        """
        return VulnerableLocation(
            file_path=match.file_path,
            line_start=match.line_start,
            line_end=match.line_end,
            code_snippet=match.matched_text[:500],  # Limit snippet size
            pattern_matched=pattern,
            confidence_score=1.0,  # ast-grep gives exact matches
        )

    async def confirm_vulnerability(self, apv: APV) -> ConfirmationResult:
        """
        Confirm vulnerability in codebase.
        
        Executes ast-grep patterns against candidate files, aggregating
        matches into confirmation result.
        
        Args:
            apv: APV to confirm
            
        Returns:
            ConfirmationResult with status and vulnerable locations
            
        Raises:
            Exception: If confirmation process fails critically
        """
        start_time = datetime.utcnow()

        # Initialize Redis cache
        await self._init_redis()

        # Check cache
        cached_result = await self._get_cached_result(apv.cve_id)
        if cached_result:
            return cached_result

        logger.info(
            f"Starting confirmation for {apv.cve_id}",
            extra={
                "cve_id": apv.cve_id,
                "patterns": len(apv.ast_grep_patterns),
                "packages": len(apv.affected_packages),
            },
        )

        try:
            # Discover candidate files
            candidate_files = self._discover_candidate_files(apv)

            if not candidate_files:
                # No files to scan
                result = ConfirmationResult(
                    apv_id=apv.cve_id,
                    cve_id=apv.cve_id,
                    status=ConfirmationStatus.FALSE_POSITIVE,
                    metadata=ConfirmationMetadata(
                        files_scanned=0,
                        patterns_tested=len(apv.ast_grep_patterns),
                        execution_time_ms=0,
                    ),
                )
                await self._cache_result(result)
                return result

            # Execute ast-grep patterns
            all_locations: list[VulnerableLocation] = []
            patterns_tested = 0

            for ast_pattern in apv.ast_grep_patterns:
                try:
                    matches = await self.ast_grep.search_pattern(
                        pattern=ast_pattern.pattern,
                        file_paths=candidate_files,
                        language=ast_pattern.language,
                        include_context=True,
                    )

                    patterns_tested += 1

                    # Convert matches to locations
                    for match in matches:
                        location = self._match_to_location(
                            match, ast_pattern.pattern
                        )
                        all_locations.append(location)

                    if matches:
                        logger.info(
                            f"Pattern matched: {ast_pattern.pattern}",
                            extra={
                                "matches": len(matches),
                                "pattern": ast_pattern.pattern,
                            },
                        )

                except Exception as e:
                    logger.error(
                        f"Pattern execution failed: {e}",
                        extra={"pattern": ast_pattern.pattern},
                    )
                    continue

            # Determine status
            if all_locations:
                status = ConfirmationStatus.CONFIRMED
            else:
                status = ConfirmationStatus.FALSE_POSITIVE

            # Calculate execution time
            execution_time = (
                datetime.utcnow() - start_time
            ).total_seconds() * 1000

            # Build result
            result = ConfirmationResult(
                apv_id=apv.cve_id,
                cve_id=apv.cve_id,
                status=status,
                vulnerable_locations=all_locations,
                metadata=ConfirmationMetadata(
                    confirmed_at=datetime.utcnow(),
                    ast_grep_version="0.15.0",  # TODO: Get from ast-grep
                    patterns_tested=patterns_tested,
                    files_scanned=len(candidate_files),
                    execution_time_ms=int(execution_time),
                ),
            )

            # Cache result
            await self._cache_result(result)

            logger.info(
                f"Confirmation complete for {apv.cve_id}",
                extra={
                    "status": status.value,
                    "locations": len(all_locations),
                    "execution_time_ms": int(execution_time),
                },
            )

            return result

        except Exception as e:
            # Critical error during confirmation
            logger.error(
                f"Confirmation failed for {apv.cve_id}: {e}",
                exc_info=True,
            )

            execution_time = (
                datetime.utcnow() - start_time
            ).total_seconds() * 1000

            error_result = ConfirmationResult(
                apv_id=apv.cve_id,
                cve_id=apv.cve_id,
                status=ConfirmationStatus.ERROR,
                error_message=str(e),
                metadata=ConfirmationMetadata(
                    execution_time_ms=int(execution_time),
                ),
            )

            return error_result
