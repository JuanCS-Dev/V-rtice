# MAXIMUS Or√°culo Service - Environment Variables Configuration
# Copy this file to .env and configure your values

# ============================================================================
# Feature Flags
# ============================================================================

# Enable LLM-powered code generation (requires OPENAI_API_KEY)
ENABLE_LLM_CODEGEN=true

# Enable Kafka integration for WebSocket streaming
ENABLE_KAFKA=false

# Enable WebSocket endpoints  
ENABLE_WEBSOCKET=true

# ============================================================================
# OpenAI Configuration (for LLM code generation)
# ============================================================================

# OpenAI API Key (required if ENABLE_LLM_CODEGEN=true)
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-your-api-key-here

# OpenAI Model Selection
OPENAI_MODEL=gpt-4-turbo-preview

# Maximum tokens to generate per request
OPENAI_MAX_TOKENS=4096
