"""Sophia Engine - Motor de Sabedoria (Artigo I).

Implementa o Princ√≠pio da Sabedoria: julgar se uma interven√ß√£o √© necess√°ria
antes de acionar o ciclo MAPE-K completo.

Fundamento B√≠blico: Prov√©rbios 9:10
"O temor do SENHOR √© o princ√≠pio da sabedoria."

Author: V√©rtice Platform Team
License: Proprietary
"""

import asyncio
from datetime import datetime, timedelta
import json
import logging
from pathlib import Path
import re
import subprocess
from typing import Any

import yaml

from models import Anomaly, InterventionDecision, InterventionLevel, Severity

logger = logging.getLogger(__name__)


class SophiaEngine:
    """
    Motor de Sabedoria: Julga se uma interven√ß√£o √© necess√°ria.

    Implementa tr√™s perguntas essenciais:
    1. √â uma falha transit√≥ria que se autocorrige?
    2. A interven√ß√£o pode causar mais dano que a falha?
    3. H√° precedentes hist√≥ricos que informam a decis√£o?
    """

    def __init__(self, wisdom_base, observability_client):
        """
        Inicializa Sophia Engine.

        Args:
            wisdom_base: Cliente para Wisdom Base (precedentes hist√≥ricos)
            observability_client: Cliente para Prometheus/Loki
        """
        self.wisdom_base = wisdom_base
        self.observability_client = observability_client

        # Configura√ß√µes de sabedoria
        self.transient_failure_threshold_minutes = 5
        self.min_precedent_confidence = 0.85
        self.risk_tolerance = 0.3  # M√°ximo 30% de risco aceit√°vel

    async def should_intervene(self, anomaly: Anomaly) -> dict[str, Any]:
        """
        Decis√£o principal: devemos intervir nesta anomalia?

        Args:
            anomaly: Anomalia detectada

        Returns:
            Dict com decis√£o e reasoning
        """
        logger.info(
            f"[Sophia] Evaluating intervention for anomaly {anomaly.anomaly_id}"
        )

        # Pergunta 1: √â transit√≥ria?
        if await self._is_self_healing_naturally(anomaly):
            return {
                "decision": InterventionDecision.OBSERVE_AND_WAIT,
                "reasoning": "Anomalia tem padr√£o transit√≥rio conhecido. Hist√≥rico mostra auto-corre√ß√£o em 94% dos casos.",
                "wait_time_minutes": self.transient_failure_threshold_minutes,
                "sophia_wisdom": "H√° tempo certo para cada a√ß√£o (Eclesiastes 3:1). Este n√£o √© o momento de agir.",
            }

        # Pergunta 2: Risco de interven√ß√£o > benef√≠cio?
        risk_assessment = await self._assess_intervention_risk(anomaly)
        current_impact = self._calculate_current_impact(anomaly)

        if risk_assessment["risk_score"] > current_impact:
            return {
                "decision": InterventionDecision.HUMAN_CONSULTATION_REQUIRED,
                "reasoning": f"Risco de interven√ß√£o ({risk_assessment['risk_score']:.2f}) > impacto atual ({current_impact:.2f})",
                "risk_details": risk_assessment,
                "sophia_wisdom": "A prud√™ncia √© a marca da sabedoria. Quando em d√∫vida, consultar aqueles com mais experi√™ncia.",
            }

        # Pergunta 3: H√° precedentes hist√≥ricos?
        precedent = await self._query_wisdom_base(anomaly)

        if precedent:
            return {
                "decision": InterventionDecision.INTERVENE,
                "reasoning": f"Precedente encontrado (similaridade: {precedent['similarity']:.1%}). Interven√ß√£o anterior foi {precedent['outcome']}.",
                "intervention_level": self._recommend_intervention_level(
                    anomaly, precedent
                ),
                "precedent": precedent,
                "sophia_wisdom": "H√° sabedoria em aprender com o passado. Precedentes nos guiam.",
            }

        # Sem precedentes: avaliar se devemos arriscar interven√ß√£o
        if anomaly.severity in [Severity.P0_CRITICAL, Severity.P1_HIGH]:
            return {
                "decision": InterventionDecision.INTERVENE,
                "reasoning": f"Severidade {anomaly.severity.value} requer a√ß√£o. Sem precedentes, mas impacto justifica risco.",
                "intervention_level": InterventionLevel.PATCH_SURGICAL,  # Come√ßar conservador
                "sophia_wisdom": "Em momentos cr√≠ticos, sabedoria tamb√©m √© agir com coragem temperada.",
            }
        else:
            return {
                "decision": InterventionDecision.OBSERVE_AND_WAIT,
                "reasoning": "Sem precedentes e severidade n√£o cr√≠tica. Observar para aprender antes de agir.",
                "wait_time_minutes": 10,
                "sophia_wisdom": "Melhor observar e aprender que agir precipitadamente sem conhecimento.",
            }

    async def _is_self_healing_naturally(self, anomaly: Anomaly) -> bool:
        """
        Verifica se anomalia tem padr√£o de auto-corre√ß√£o.

        Args:
            anomaly: Anomalia a verificar

        Returns:
            True se hist√≥rico mostra auto-corre√ß√£o frequente
        """
        # Buscar ocorr√™ncias similares nas √∫ltimas 4 semanas
        time_window = datetime.now() - timedelta(weeks=4)

        similar_anomalies = await self.observability_client.query_similar_anomalies(
            anomaly_type=anomaly.anomaly_type,
            service=anomaly.service,
            since=time_window,
        )

        if len(similar_anomalies) < 5:
            return False  # Insuficiente hist√≥rico

        # Calcular taxa de auto-corre√ß√£o
        auto_corrected = sum(
            1 for a in similar_anomalies if a["resolved_without_intervention"]
        )

        auto_correction_rate = auto_corrected / len(similar_anomalies)

        # Se > 90% se auto-corrigiram, considerar transit√≥rio
        is_transient = auto_correction_rate > 0.90

        if is_transient:
            logger.info(
                f"[Sophia] Anomaly {anomaly.anomaly_id} identified as transient "
                f"({auto_correction_rate:.1%} auto-correction rate)"
            )

        return is_transient

    async def _assess_intervention_risk(self, anomaly: Anomaly) -> dict[str, Any]:
        """
        Avalia risco de interven√ß√£o.

        Args:
            anomaly: Anomalia a avaliar

        Returns:
            Dict com risk_score e detalhes
        """
        risk_factors = []
        risk_score = 0.0

        # Fator 1: Complexidade do servi√ßo afetado
        service_complexity = await self._get_service_complexity(anomaly.service)
        if service_complexity > 0.7:
            risk_factors.append("Servi√ßo de alta complexidade")
            risk_score += 0.3

        # Fator 2: N√∫mero de depend√™ncias
        dependencies = await self._get_service_dependencies(anomaly.service)
        if len(dependencies) > 10:
            risk_factors.append(f"Muitas depend√™ncias ({len(dependencies)})")
            risk_score += 0.2

        # Fator 3: Mudan√ßas recentes no servi√ßo
        recent_changes = await self._get_recent_changes(anomaly.service, hours=24)
        if recent_changes > 3:
            risk_factors.append(f"M√∫ltiplas mudan√ßas recentes ({recent_changes})")
            risk_score += 0.25

        # Fator 4: Falta de testes
        test_coverage = await self._get_test_coverage(anomaly.service)
        if test_coverage < 0.90:
            risk_factors.append(f"Coverage baixo ({test_coverage:.1%})")
            risk_score += 0.25

        return {
            "risk_score": min(risk_score, 1.0),
            "risk_factors": risk_factors,
            "service_complexity": service_complexity,
            "dependencies_count": len(dependencies),
            "recent_changes": recent_changes,
            "test_coverage": test_coverage,
        }

    def _calculate_current_impact(self, anomaly: Anomaly) -> float:
        """
        Calcula impacto atual da anomalia.

        Args:
            anomaly: Anomalia a avaliar

        Returns:
            Impact score (0.0 - 1.0)
        """
        impact = 0.0

        # Severity base
        severity_scores = {
            Severity.P0_CRITICAL: 1.0,
            Severity.P1_HIGH: 0.7,
            Severity.P2_MEDIUM: 0.4,
            Severity.P3_LOW: 0.2,
        }
        impact += severity_scores.get(anomaly.severity, 0.5)

        # M√©tricas espec√≠ficas
        if "error_rate" in anomaly.metrics:
            impact += anomaly.metrics["error_rate"] * 0.3

        if "affected_users" in anomaly.metrics:
            users_affected = anomaly.metrics["affected_users"]
            if users_affected > 1000:
                impact += 0.3
            elif users_affected > 100:
                impact += 0.15

        return min(impact, 1.0)

    async def _query_wisdom_base(self, anomaly: Anomaly) -> dict[str, Any] | None:
        """
        Busca precedentes hist√≥ricos na Wisdom Base.

        Args:
            anomaly: Anomalia a buscar

        Returns:
            Precedente mais similar ou None
        """
        precedents = await self.wisdom_base.query_precedents(
            anomaly_type=anomaly.anomaly_type,
            service=anomaly.service,
            similarity_threshold=self.min_precedent_confidence,
        )

        if not precedents:
            return None

        # Retornar precedente mais similar com outcome positivo
        successful_precedents = [p for p in precedents if p["outcome"] == "success"]

        if successful_precedents:
            return max(successful_precedents, key=lambda p: p["similarity"])

        # Se n√£o h√° sucessos, retornar mais similar (para aprender com falha)
        return max(precedents, key=lambda p: p["similarity"])

    def _recommend_intervention_level(
        self, anomaly: Anomaly, precedent: dict[str, Any]
    ) -> InterventionLevel:
        """
        Recomenda n√≠vel de interven√ß√£o baseado em precedente.

        Args:
            anomaly: Anomalia atual
            precedent: Precedente hist√≥rico

        Returns:
            N√≠vel de interven√ß√£o recomendado
        """
        # Se precedente foi sucesso e similar > 90%, usar mesmo n√≠vel
        if precedent["outcome"] == "success" and precedent["similarity"] > 0.90:
            return precedent.get("intervention_level", InterventionLevel.PATCH_SURGICAL)

        # Se precedente falhou, ser mais conservador
        if precedent["outcome"] == "failure":
            return InterventionLevel.OBSERVE

        # Padr√£o: come√ßar com interven√ß√£o cir√∫rgica
        return InterventionLevel.PATCH_SURGICAL

    async def _get_service_complexity(self, service: str) -> float:
        """
        Calcula complexidade real do servi√ßo usando radon.

        Usa cyclomatic complexity como m√©trica principal.
        Normaliza para escala 0.0-1.0 (complexidade >15 = muito alta).

        Args:
            service: Nome do servi√ßo (e.g., "penelope_service")

        Returns:
            Score de complexidade (0.0 - 1.0)
        """
        try:
            service_path = f"backend/services/{service}"

            # Run radon cc (cyclomatic complexity)
            result = subprocess.run(
                ["radon", "cc", "-a", "-j", service_path],
                capture_output=True,
                text=True,
                timeout=30,
                cwd="/home/juan/vertice-dev",
            )

            if result.returncode != 0:
                logger.warning(
                    f"Radon failed for {service}: {result.stderr}. Using default complexity."
                )
                return 0.5

            # Parse JSON output
            data = json.loads(result.stdout)

            # Calculate weighted complexity
            total_complexity = 0
            total_functions = 0

            for file_data in data.values():
                for item in file_data:
                    total_complexity += item.get("complexity", 0)
                    total_functions += 1

            if total_functions == 0:
                logger.info(
                    f"No functions found in {service}, using default complexity"
                )
                return 0.5

            avg_complexity = total_complexity / total_functions

            # Normalize to 0-1 scale (complexity >15 is very high)
            normalized = min(avg_complexity / 15.0, 1.0)

            logger.info(
                f"Service {service} complexity: {normalized:.2f} "
                f"(avg cyclomatic: {avg_complexity:.1f}, functions: {total_functions})"
            )
            return normalized

        except subprocess.TimeoutExpired:
            logger.error(f"Radon timeout for {service}")
            return 0.5
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse radon output for {service}: {e}")
            return 0.5
        except Exception as e:
            logger.error(f"Failed to calculate complexity for {service}: {e}")
            return 0.5  # Conservative fallback

    async def _get_service_dependencies(self, service: str) -> list[str]:
        """
        Obt√©m depend√™ncias reais do servi√ßo analisando imports e docker-compose.

        Analisa:
        1. Imports Python (from X_service import ...)
        2. docker-compose.yml (depends_on)
        3. Service Registry (runtime dependencies)

        Args:
            service: Nome do servi√ßo (e.g., "penelope_service")

        Returns:
            Lista de servi√ßos dependentes (unique)
        """
        try:
            dependencies = set()
            service_path = Path(f"/home/juan/vertice-dev/backend/services/{service}")

            if not service_path.exists():
                logger.warning(f"Service path not found: {service_path}")
                return []

            # 1. Parse Python imports
            for py_file in service_path.rglob("*.py"):
                try:
                    content = py_file.read_text()

                    # Find internal service imports
                    # Pattern: from X_service import ... or import X_service
                    import_pattern = (
                        r"from\s+(\w+_service)\s+import|import\s+(\w+_service)"
                    )
                    matches = re.findall(import_pattern, content)

                    for match in matches:
                        dep = match[0] or match[1]
                        if dep and dep != service:
                            dependencies.add(dep)
                except Exception as e:
                    logger.debug(f"Failed to parse {py_file}: {e}")
                    continue

            # 2. Parse docker-compose.yml
            compose_file = service_path / "docker-compose.yml"
            if compose_file.exists():
                try:
                    compose_data = yaml.safe_load(compose_file.read_text())

                    for svc_name, svc_config in compose_data.get(
                        "services", {}
                    ).items():
                        depends_on = svc_config.get("depends_on", [])

                        # depends_on can be list or dict
                        if isinstance(depends_on, list):
                            dependencies.update(depends_on)
                        elif isinstance(depends_on, dict):
                            dependencies.update(depends_on.keys())
                except Exception as e:
                    logger.debug(f"Failed to parse docker-compose.yml: {e}")

            # 3. Query Service Registry (if available)
            # TODO: Implement when Service Registry client is available
            # registry_deps = await self._query_registry_dependencies(service)
            # dependencies.update(registry_deps)

            result = sorted(list(dependencies))
            logger.info(f"Service {service} has {len(result)} dependencies: {result}")
            return result

        except Exception as e:
            logger.error(f"Failed to get dependencies for {service}: {e}")
            return []

    async def _get_recent_changes(self, service: str, hours: int = 24) -> int:
        """
        Obt√©m n√∫mero real de commits recentes usando git log.

        Conta commits no diret√≥rio do servi√ßo nas √∫ltimas N horas.

        Args:
            service: Nome do servi√ßo (e.g., "penelope_service")
            hours: Janela de tempo em horas (padr√£o: 24)

        Returns:
            N√∫mero de commits recentes
        """
        try:
            service_path = f"backend/services/{service}"
            since_time = f"{hours} hours ago"

            result = subprocess.run(
                [
                    "git",
                    "log",
                    "--oneline",
                    f"--since={since_time}",
                    "--",
                    service_path,
                ],
                capture_output=True,
                text=True,
                timeout=10,
                cwd="/home/juan/vertice-dev",
            )

            if result.returncode != 0:
                logger.warning(f"Git log failed for {service}: {result.stderr}")
                return 0

            # Count non-empty lines
            commit_count = len(
                [line for line in result.stdout.split("\n") if line.strip()]
            )

            logger.info(
                f"Service {service} had {commit_count} commits in last {hours}h"
            )
            return commit_count

        except subprocess.TimeoutExpired:
            logger.error(f"Git log timeout for {service}")
            return 0
        except Exception as e:
            logger.error(f"Failed to get recent changes for {service}: {e}")
            return 0

    async def _get_test_coverage(self, service: str) -> float:
        """
        Obt√©m coverage real de testes usando pytest-cov.

        Executa pytest com coverage no diret√≥rio do servi√ßo e extrai
        o percentual de cobertura do coverage.json gerado.

        Args:
            service: Nome do servi√ßo (e.g., "penelope_service")

        Returns:
            Coverage (0.0 - 1.0)
        """
        try:
            service_path = Path(f"/home/juan/vertice-dev/backend/services/{service}")

            if not service_path.exists():
                logger.warning(f"Service path not found: {service_path}")
                return 0.0

            # Run pytest with coverage
            result = subprocess.run(
                ["pytest", "--cov=.", "--cov-report=json", "-q", "--tb=no"],
                capture_output=True,
                text=True,
                timeout=120,  # 2 minutes timeout
                cwd=str(service_path),
            )

            # Check if coverage.json was generated
            coverage_file = service_path / "coverage.json"
            if not coverage_file.exists():
                logger.warning(
                    f"No coverage.json for {service}. "
                    f"Tests may have failed or no tests exist."
                )
                return 0.0

            # Read coverage.json
            coverage_data = json.loads(coverage_file.read_text())
            coverage_pct = coverage_data["totals"]["percent_covered"] / 100.0

            logger.info(
                f"Service {service} coverage: {coverage_pct:.1%} "
                f"({coverage_data['totals']['covered_lines']}/{coverage_data['totals']['num_statements']} statements)"
            )
            return coverage_pct

        except subprocess.TimeoutExpired:
            logger.error(f"Pytest timeout for {service} (>120s)")
            return 0.0
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse coverage.json for {service}: {e}")
            return 0.0
        except KeyError as e:
            logger.error(f"Invalid coverage.json format for {service}: {e}")
            return 0.0
        except Exception as e:
            logger.error(f"Failed to get test coverage for {service}: {e}")
            return 0.0

    async def validate_patch_in_twin(self, service: str, patch: str) -> dict[str, Any]:
        """
        Validate patch using digital twin before production.

        Creates isolated Docker container, applies patch, runs tests,
        monitors metrics. Only approves if all checks pass.

        Args:
            service: Service name (e.g., "penelope_service")
            patch: Git-style patch content

        Returns:
            validation_result: Dict with success, test_results, metrics
        """
        from core.digital_twin import DigitalTwinEnvironment

        twin_env = DigitalTwinEnvironment()
        twin_id = None

        try:
            # Step 1: Create digital twin
            logger.info(f"Creating digital twin for {service}...")
            twin_id = await twin_env.create_twin(service)

            # Step 2: Apply patch
            logger.info(f"Applying patch to twin {twin_id}...")
            patch_applied = await twin_env.apply_patch(twin_id, patch)

            if not patch_applied:
                return {
                    "success": False,
                    "reason": "Patch failed to apply cleanly",
                    "twin_id": twin_id,
                }

            # Step 3: Run tests
            logger.info(f"Running tests in twin {twin_id}...")
            test_results = await twin_env.run_tests(twin_id)

            if test_results["tests_failed"] > 0:
                return {
                    "success": False,
                    "reason": f"{test_results['tests_failed']} tests failed",
                    "test_results": test_results,
                    "twin_id": twin_id,
                }

            # Step 4: Check coverage didn't drop significantly
            original_coverage = await self._get_test_coverage(service)
            new_coverage = test_results["coverage"]

            if new_coverage < original_coverage - 5.0:  # Allow 5% drop
                return {
                    "success": False,
                    "reason": f"Coverage dropped from {original_coverage:.1f}% to {new_coverage:.1f}%",
                    "test_results": test_results,
                    "twin_id": twin_id,
                }

            # Step 5: Monitor for regressions
            logger.info(f"Monitoring twin {twin_id} for regressions (120s)...")
            metrics = await twin_env.monitor_metrics(twin_id, duration_seconds=120)

            if metrics["cpu_avg"] > 80.0:
                return {
                    "success": False,
                    "reason": f"High CPU usage: {metrics['cpu_avg']:.1f}%",
                    "metrics": metrics,
                    "test_results": test_results,
                    "twin_id": twin_id,
                }

            # All checks passed!
            logger.info(f"‚úÖ Patch validation successful for {service}")
            return {
                "success": True,
                "test_results": test_results,
                "metrics": metrics,
                "twin_id": twin_id,
                "validation_summary": {
                    "tests_passed": test_results["tests_passed"],
                    "tests_failed": test_results["tests_failed"],
                    "coverage": new_coverage,
                    "cpu_avg": metrics["cpu_avg"],
                    "memory_avg": metrics["memory_avg"],
                },
            }

        except Exception as e:
            logger.error(f"Digital twin validation failed: {e}")
            return {
                "success": False,
                "reason": f"Validation error: {str(e)}",
                "error": str(e),
                "twin_id": twin_id,
            }

        finally:
            # Always clean up twin
            if twin_id:
                try:
                    logger.info(f"Destroying twin {twin_id}...")
                    await twin_env.destroy_twin(twin_id)
                except Exception as e:
                    logger.error(f"Failed to destroy twin {twin_id}: {e}")

    async def apply_patch_with_rollback(
        self, service: str, patch: str, anomaly_id: str
    ) -> dict[str, Any]:
        """Apply patch with automatic rollback on failure.

        Applies patch to production service, monitors for regressions,
        and automatically rolls back if problems detected.

        Workflow:
        1. Save patch to history
        2. Get baseline metrics
        3. Apply patch to production
        4. Restart service
        5. Monitor for 5 minutes
        6. Auto-rollback if errors spike or service crashes

        Args:
            service: Service name (e.g., "penelope_service")
            patch: Git-style patch content
            anomaly_id: Anomaly identifier for tracking

        Returns:
            result: Dict with success, patch_id, metrics
        """
        from core.patch_history import PatchHistory

        patch_history = PatchHistory()
        patch_id = None

        try:
            # Step 1: Save to history
            logger.info(f"Saving patch to history for {service}...")
            patch_id = await patch_history.save_patch(
                service,
                patch,
                anomaly_id,
                metadata={
                    "applied_at": datetime.utcnow().isoformat(),
                    "applied_by": "penelope",
                    "anomaly_id": anomaly_id,
                },
            )

            # Step 2: Get baseline metrics
            logger.info(f"Getting baseline metrics for {service}...")
            baseline = await self._get_service_metrics(service)

            # Step 3: Apply patch to production
            logger.info(f"Applying patch {patch_id[:8]} to production {service}...")
            service_path = Path(f"/home/juan/vertice-dev/backend/services/{service}")

            result = subprocess.run(
                ["patch", "-p1"],
                input=patch.encode(),
                cwd=str(service_path),
                capture_output=True,
            )

            if result.returncode != 0:
                error_msg = result.stderr.decode(errors="ignore")
                logger.error(f"Patch application failed: {error_msg}")
                return {
                    "success": False,
                    "patch_id": patch_id,
                    "error": f"Patch failed to apply: {error_msg}",
                    "rolled_back": False,
                }

            # Step 4: Restart service (if applicable)
            logger.info(f"Patch applied, restarting {service}...")
            await self._restart_service(service)

            # Step 5: Monitor for 5 minutes
            logger.info(f"Monitoring {service} for regressions (5 min)...")
            monitoring_duration = 300  # 5 minutes
            check_interval = 10  # Check every 10 seconds
            checks = monitoring_duration // check_interval

            for i in range(checks):
                await asyncio.sleep(check_interval)

                current_metrics = await self._get_service_metrics(service)

                # Check for regressions
                if (
                    current_metrics.get("error_rate", 0)
                    > baseline.get("error_rate", 0) * 2.0
                ):
                    error_rate_baseline = baseline.get("error_rate", 0)
                    error_rate_current = current_metrics.get("error_rate", 0)

                    logger.error(
                        f"üö® Error rate doubled: {error_rate_baseline:.2f} ‚Üí {error_rate_current:.2f}"
                    )

                    # Auto-rollback
                    logger.warning(
                        f"Initiating automatic rollback for patch {patch_id[:8]}"
                    )
                    rollback_success = await patch_history.rollback_patch(
                        service, patch_id
                    )

                    if rollback_success:
                        await self._restart_service(service)
                        return {
                            "success": False,
                            "patch_id": patch_id,
                            "error": f"Error rate doubled: {error_rate_baseline:.2f} ‚Üí {error_rate_current:.2f}",
                            "rolled_back": True,
                            "baseline_metrics": baseline,
                            "final_metrics": current_metrics,
                        }
                    else:
                        # Rollback failed - CRITICAL
                        await self._alert_human(
                            service=service,
                            severity="CRITICAL",
                            message=f"Patch {patch_id[:8]} caused errors AND rollback failed",
                            patch_id=patch_id,
                            error="Auto-rollback failure",
                        )
                        return {
                            "success": False,
                            "patch_id": patch_id,
                            "error": "Error rate doubled and rollback failed",
                            "rolled_back": False,
                            "alert_sent": True,
                        }

                if not current_metrics.get("healthy", True):
                    logger.error(f"üö® Service {service} became unhealthy")

                    # Auto-rollback
                    logger.warning(
                        f"Initiating automatic rollback for patch {patch_id[:8]}"
                    )
                    rollback_success = await patch_history.rollback_patch(
                        service, patch_id
                    )

                    if rollback_success:
                        await self._restart_service(service)
                        return {
                            "success": False,
                            "patch_id": patch_id,
                            "error": "Service became unhealthy",
                            "rolled_back": True,
                        }

                logger.debug(
                    f"Health check {i+1}/{checks}: "
                    f"error_rate={current_metrics.get('error_rate', 0):.3f}, "
                    f"healthy={current_metrics.get('healthy', True)}"
                )

            # All checks passed!
            final_metrics = await self._get_service_metrics(service)
            logger.info(f"‚úÖ Patch {patch_id[:8]} stable after {monitoring_duration}s")

            return {
                "success": True,
                "patch_id": patch_id,
                "monitoring_duration_seconds": monitoring_duration,
                "baseline_metrics": baseline,
                "final_metrics": final_metrics,
                "rolled_back": False,
            }

        except Exception as e:
            logger.error(f"Patch application failed with exception: {e}")

            # Attempt rollback
            if patch_id:
                logger.warning(f"Attempting rollback due to exception")
                rollback_success = await patch_history.rollback_patch(service, patch_id)

                if rollback_success:
                    await self._restart_service(service)
                    return {
                        "success": False,
                        "patch_id": patch_id,
                        "error": str(e),
                        "rolled_back": True,
                    }

            return {
                "success": False,
                "patch_id": patch_id,
                "error": str(e),
                "rolled_back": False,
            }

    async def _get_service_metrics(self, service: str) -> dict[str, Any]:
        """Get current service metrics.

        Stub implementation - should query Prometheus/observability.

        Args:
            service: Service name

        Returns:
            metrics: Dict with error_rate, healthy, etc.
        """
        # TODO: Implement real Prometheus query
        # For now, return conservative defaults
        return {
            "error_rate": 0.01,  # 1% error rate
            "healthy": True,
            "cpu_usage": 0.5,
            "memory_usage": 0.6,
        }

    async def _restart_service(self, service: str) -> bool:
        """Restart a service.

        Stub implementation - should use docker-compose or k8s.

        Args:
            service: Service name

        Returns:
            success: True if restart succeeded
        """
        # TODO: Implement real service restart
        # docker-compose restart {service} or kubectl rollout restart
        logger.info(f"Would restart service: {service}")
        return True

    async def _alert_human(
        self, service: str, severity: str, message: str, **kwargs
    ) -> bool:
        """Alert human operator.

        Stub implementation - should send to Slack/PagerDuty.

        Args:
            service: Service name
            severity: Alert severity (CRITICAL, WARNING, etc.)
            message: Alert message
            **kwargs: Additional context

        Returns:
            success: True if alert sent
        """
        # TODO: Implement real alerting (Slack, PagerDuty, etc.)
        logger.critical(
            f"üö® HUMAN ALERT [{severity}] for {service}: {message} | Context: {kwargs}"
        )
        return True
