"""Integration Analyzer - Analyzes communication patterns between services.

Identifies:
- Kafka topics and pub/sub patterns
- Redis communication (pub/sub, streams)
- HTTP/REST dependencies
- Single Points of Failure (SPOFs)
- Latency bottlenecks

Production-ready, zero mocks.
"""

import logging
from typing import Any, Dict, List, Set

logger = logging.getLogger(__name__)


class IntegrationAnalyzer:
    """Analyzes service integration patterns."""

    # Known Kafka topics in VÃ‰RTICE
    KNOWN_KAFKA_TOPICS = [
        "system.telemetry.raw",
        "system.predictions",
        "system.homeostatic",
        "immune.cytokines",
        "threat.cascades",
        "agent.communications",
        "reactive.fabric.events"
    ]

    # Known Redis patterns
    REDIS_PATTERNS = [
        "rate_limit:*",
        "session:*",
        "prediction_cache:*",
        "hitl_queue"
    ]

    def __init__(self, scanner):
        """Initialize with architecture scanner."""
        self.scanner = scanner

    async def analyze(self) -> Dict[str, Any]:
        """
        Analyze integration patterns across VÃ‰RTICE platform.

        Returns:
            Integration analysis with SPOFs and bottlenecks
        """
        logger.info("ðŸ”— Analyzing integration patterns...")

        architecture = await self.scanner.scan()
        services = architecture["services"]

        # Analyze Kafka integrations
        kafka_analysis = self._analyze_kafka(services)

        # Analyze Redis integrations
        redis_analysis = self._analyze_redis(services)

        # Analyze HTTP dependencies
        http_analysis = self._analyze_http_dependencies(services)

        # Identify SPOFs
        spofs = self._identify_spofs(architecture)

        # Identify bottlenecks
        bottlenecks = self._identify_bottlenecks(architecture)

        result = {
            "kafka": kafka_analysis,
            "redis": redis_analysis,
            "http": http_analysis,
            "spofs": spofs,
            "bottlenecks": bottlenecks,
            "total_integration_points": (
                kafka_analysis["total_topics"] +
                redis_analysis["total_patterns"] +
                http_analysis["total_dependencies"]
            )
        }

        logger.info("âœ… Integration analysis complete")
        return result

    def _analyze_kafka(self, services: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        """Analyze Kafka integration patterns."""
        kafka_services = [
            name for name, data in services.items()
            if "kafka" in name.lower() or "hcl" in name.lower()
        ]

        producers = []
        consumers = []

        for service_name in services:
            # Heuristic: services with "_service" likely produce/consume
            if any(pattern in service_name for pattern in ["immunis_", "hcl_", "maximus_"]):
                producers.append(service_name)
                consumers.append(service_name)

        return {
            "kafka_brokers": kafka_services,
            "total_topics": len(self.KNOWN_KAFKA_TOPICS),
            "topics": self.KNOWN_KAFKA_TOPICS,
            "estimated_producers": len(set(producers)),
            "estimated_consumers": len(set(consumers))
        }

    def _analyze_redis(self, services: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
        """Analyze Redis integration patterns."""
        redis_services = [
            name for name in services if "redis" in name.lower()
        ]

        return {
            "redis_instances": redis_services,
            "total_patterns": len(self.REDIS_PATTERNS),
            "patterns": self.REDIS_PATTERNS,
            "use_cases": [
                "Rate limiting",
                "Session storage",
                "Prediction cache",
                "HITL queue",
                "Pub/sub messaging"
            ]
        }

    def _analyze_http_dependencies(
        self,
        services: Dict[str, Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Analyze HTTP/REST dependencies."""
        total_deps = sum(
            len(s.get("depends_on", []))
            for s in services.values()
        )

        # Services with many dependencies (potential bottlenecks)
        high_dependency_services = [
            (name, len(data.get("depends_on", [])))
            for name, data in services.items()
            if len(data.get("depends_on", [])) > 3
        ]

        return {
            "total_dependencies": total_deps,
            "high_dependency_services": high_dependency_services,
            "api_gateway": "api_gateway" in services
        }

    def _identify_spofs(self, architecture: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Identify Single Points of Failure."""
        spofs = []

        # Check for single Kafka broker
        kafka_count = sum(1 for s in architecture["services"] if "kafka" in s.lower())
        if kafka_count == 1:
            spofs.append({
                "type": "kafka_broker",
                "severity": "HIGH",
                "description": "Single Kafka broker - no replication",
                "recommendation": "Deploy Kafka cluster with replication_factor > 1"
            })

        # Check for single Redis instance
        redis_count = sum(1 for s in architecture["services"] if "redis" in s.lower() and "aurora" not in s.lower())
        if redis_count == 1:
            spofs.append({
                "type": "redis_cache",
                "severity": "MEDIUM",
                "description": "Single Redis instance",
                "recommendation": "Deploy Redis Sentinel or Cluster"
            })

        # Check for single API gateway
        gateway_count = sum(1 for s in architecture["services"] if "gateway" in s.lower())
        if gateway_count == 1:
            spofs.append({
                "type": "api_gateway",
                "severity": "HIGH",
                "description": "Single API Gateway instance",
                "recommendation": "Deploy multiple gateway replicas with load balancer"
            })

        return spofs

    def _identify_bottlenecks(
        self,
        architecture: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """Identify potential latency bottlenecks."""
        bottlenecks = []

        # Services with many dependents (from dependency graph)
        graph = architecture["dependency_graph"]
        avg_degree = graph["metrics"]["average_degree"]

        if avg_degree > 5:
            bottlenecks.append({
                "type": "high_coupling",
                "severity": "MEDIUM",
                "description": f"High average degree ({avg_degree:.1f}) in dependency graph",
                "recommendation": "Consider service decoupling and async communication"
            })

        # Check for missing health checks
        health_coverage = architecture["health_summary"]["coverage_percentage"]
        if health_coverage < 90:
            bottlenecks.append({
                "type": "health_check_coverage",
                "severity": "LOW",
                "description": f"Only {health_coverage:.1f}% services have health checks",
                "recommendation": "Add health checks to all services"
            })

        return bottlenecks
