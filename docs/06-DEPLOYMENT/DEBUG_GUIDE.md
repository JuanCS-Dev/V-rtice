# üîß VERTICE PLATFORM - UNIFIED DEBUG GUIDE

> **Guia Completo de Debugging para Todo o Ecossistema Vertice**
> Frontend (React/Vite) ‚Ä¢ Backend (FastAPI/Python) ‚Ä¢ CLI (Typer/Gemini) ‚Ä¢ Docker Infrastructure

**√öltima atualiza√ß√£o**: 2025-10-01
**Autor**: JuanCS-Dev
**Status**: Production-Ready

---

## üìë √çNDICE

1. [Vis√£o Geral da Arquitetura](#1-vis√£o-geral-da-arquitetura)
2. [Debugging do Frontend](#2-debugging-do-frontend)
3. [Debugging do Backend](#3-debugging-do-backend)
4. [Debugging do Vertice CLI](#4-debugging-do-vertice-cli)
5. [Debugging da Infraestrutura Docker](#5-debugging-da-infraestrutura-docker)
6. [Debugging de Servi√ßos Espec√≠ficos](#6-debugging-de-servi√ßos-espec√≠ficos)
7. [Troubleshooting Comum](#7-troubleshooting-comum)
8. [Ferramentas e Utilit√°rios](#8-ferramentas-e-utilit√°rios)
9. [Logs Centralizados](#9-logs-centralizados)
10. [Performance Profiling](#10-performance-profiling)

---

## 1. VIS√ÉO GERAL DA ARQUITETURA

### Stack Completo

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      VERTICE PLATFORM                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ   FRONTEND   ‚îÇ   ‚îÇ    BACKEND   ‚îÇ   ‚îÇ  VERTICE CLI ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  React/Vite  ‚îÇ   ‚îÇ  FastAPI/Py  ‚îÇ   ‚îÇ  Typer/Gemini‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Port: 5173  ‚îÇ   ‚îÇ  Port: 8000  ‚îÇ   ‚îÇ   Standalone ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ         ‚îÇ                   ‚îÇ                   ‚îÇ           ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
‚îÇ                             ‚îÇ                                ‚îÇ
‚îÇ              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                ‚îÇ
‚îÇ              ‚îÇ     API GATEWAY (8000)      ‚îÇ                ‚îÇ
‚îÇ              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îÇ
‚îÇ                             ‚îÇ                                ‚îÇ
‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ    ‚îÇ                        ‚îÇ                        ‚îÇ      ‚îÇ
‚îÇ  ‚îå‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  Redis     ‚îÇ   ‚îÇ  21 Microservices‚îÇ   ‚îÇ  Monitoring   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  (6379)    ‚îÇ   ‚îÇ  (8001-8017)     ‚îÇ   ‚îÇ  Prom/Grafana ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Servi√ßos Backend (21 Microservices)

| Port | Service | Description |
|------|---------|-------------|
| 8000 | API Gateway | Entry point, routing |
| 8001 | SINESP Service | Vehicle intelligence |
| 8002 | Cyber Service | System security monitoring |
| 8003 | Domain Service | Domain/DNS analysis |
| 8004 | IP Intelligence | IP threat analysis |
| 8005 | Network Monitor | Real-time network monitoring |
| 8006 | Nmap Service | Port scanning |
| 8007 | OSINT Service | Open-source intelligence |
| 8008 | Aurora Predict | ML prediction engine |
| 8009 | Atlas Service | Geographic intelligence |
| 8010 | Auth Service | Authentication/authorization |
| 8011 | Vuln Scanner | Vulnerability scanning |
| 8012 | Social Engineering | Social eng simulation |
| 8013 | Threat Intel | Threat intelligence aggregation |
| 8014 | Malware Analysis | Malware scanning/analysis |
| 8015 | SSL Monitor | SSL/TLS certificate monitoring |
| 8016 | Aurora Orchestrator | AI orchestration layer |
| 8017 | AI Agent Service | Advanced AI agent (brain) |
| 9090 | Prometheus | Metrics collection |
| 3001 | Grafana | Metrics visualization |
| 6379 | Redis | Cache layer |

### Tecnologias

**Frontend**:
- React 18.2
- Vite 5.2
- Tailwind CSS 3.4
- CSS Modules
- Leaflet (maps)
- xterm.js (terminal)

**Backend**:
- FastAPI 0.104+
- Uvicorn
- Pydantic 2.4
- httpx (async HTTP)
- Redis 5.0
- Python 3.11+

**CLI**:
- Typer (CLI framework)
- Google Gemini API
- Rich (terminal UI)
- Questionary (prompts)

**Infrastructure**:
- Docker & Docker Compose
- Nginx (reverse proxy)
- Prometheus (metrics)
- Grafana (dashboards)

---

## 2. DEBUGGING DO FRONTEND

### 2.1. Setup de Desenvolvimento

```bash
# Navegue para o frontend
cd /home/juan/vertice-dev/frontend

# Instale depend√™ncias
npm install

# Inicie o dev server
npm run dev
# Acesse: http://localhost:5173
```

### 2.2. Problemas Comuns e Solu√ß√µes

#### ‚ùå Erro: Build Failing com `@import must precede all other statements`

**Sintoma**:
```
@import must precede all other statements (besides @charset or empty @layer)
```

**Causa**: `@import` CSS ap√≥s diretivas `@tailwind`

**Solu√ß√£o**:
```css
/* src/index.css */
/* ‚úÖ CORRETO: imports ANTES de @tailwind */
@import './styles/themes.css';

@tailwind base;
@tailwind components;
@tailwind utilities;

/* ‚ùå ERRADO: imports DEPOIS */
@tailwind base;
@import './styles/themes.css'; /* Vai falhar */
```

#### ‚ùå Erro: `Could not resolve "../../../../styles/tokens/colors.css"`

**Sintoma**: Build falha buscando arquivos CSS em caminhos relativos quebrados

**Causa**: CSS modules importando tokens desnecessariamente (vari√°veis j√° s√£o globais)

**Solu√ß√£o**:
```css
/* ‚ùå REMOVER imports desnecess√°rios de *.module.css */
/* @import '../../../../styles/tokens/colors.css'; */
/* @import '../../../../styles/tokens/spacing.css'; */

/* ‚úÖ Vari√°veis CSS j√° est√£o dispon√≠veis globalmente via themes.css */
.myClass {
  color: var(--color-primary); /* Funciona sem import */
}
```

**Script para fix em massa**:
```bash
# Remove todos os @import de arquivos .module.css
find src -name "*.module.css" -type f -exec sed -i '/@import.*tokens/d' {} \;
```

#### ‚ùå Erro: `Expected ")" but found ";"`

**Sintoma**: Build falha com erro de sintaxe em componentes React

**Causa**: Padr√£o incorreto de `React.memo` com double parenthesis

**C√≥digo Problem√°tico**:
```javascript
// ‚ùå ERRADO - double parenthesis
const Component = (({ props }) => {
  return <div>...</div>;
};

export default React.memo(Component);
```

**Solu√ß√£o**:
```javascript
// ‚úÖ CORRETO - single parenthesis
const Component = ({ props }) => {
  return <div>...</div>;
};

export default React.memo(Component);
```

**Script de busca**:
```bash
# Encontra arquivos com double parenthesis
find src -name "*.jsx" -exec grep -l "^const.*= (({" {} \;
```

#### ‚ùå Erro: ESLint configuration invalid

**Sintoma**: `Invalid option '--ext' - perhaps you meant '-c'?`

**Causa**: ESLint 9.x mudou CLI interface

**Solu√ß√£o Tempor√°ria**:
```bash
# Skip linting, foque no build primeiro
npm run build
```

**Solu√ß√£o Permanente**:
```json
// package.json - atualizar script
{
  "scripts": {
    "lint": "eslint . --report-unused-disable-directives --max-warnings 0"
  }
}
```

#### ‚ùå Erro: `Could not resolve "../../../shared"`

**Sintoma**: Imports de componentes shared quebrados

**Causa**: Path relativo incorreto ou arquivo inexistente

**Debug**:
```bash
# Verifique se o diret√≥rio shared existe
ls -la src/components/shared/

# Verifique exports do index
cat src/components/shared/index.js
```

**Solu√ß√£o**:
```javascript
// Ajuste o path relativo
// De: import { Button } from '../../../shared'
// Para: import { Button } from '../../shared'

// Ou use path absoluto (configure vite.config.js)
import { Button } from '@/components/shared'
```

### 2.3. Build Process

```bash
# 1. Limpar cache
rm -rf node_modules/.vite
rm -rf dist/

# 2. Rebuild completo
npm run build

# 3. Verificar output
ls -la dist/
# Deve ter: index.html, assets/, vite.svg

# 4. Preview production build
npm run preview
# Acesse: http://localhost:4173
```

### 2.4. Debugging em Runtime

#### Browser DevTools

```javascript
// Enable React DevTools profiling
// Em qualquer componente:
console.log('[Component Name] props:', props);
console.log('[Component Name] state:', state);

// Performance measurement
performance.mark('start-operation');
// ... c√≥digo
performance.mark('end-operation');
performance.measure('operation', 'start-operation', 'end-operation');
console.log(performance.getEntriesByName('operation'));
```

#### Vite Debug Mode

```bash
# Start com debug logs
DEBUG=vite:* npm run dev

# Ou apenas transforms
DEBUG=vite:transform npm run dev
```

#### Network Issues

```javascript
// src/api/client.js
import axios from 'axios';

const client = axios.create({
  baseURL: import.meta.env.VITE_API_URL || 'http://localhost:8000',
  timeout: 10000,
});

// Interceptor para debug
client.interceptors.request.use(config => {
  console.log('[API Request]', config.method?.toUpperCase(), config.url);
  return config;
});

client.interceptors.response.use(
  response => {
    console.log('[API Response]', response.status, response.config.url);
    return response;
  },
  error => {
    console.error('[API Error]', error.response?.status, error.config?.url, error.message);
    return Promise.reject(error);
  }
);

export default client;
```

### 2.5. Testing

```bash
# Run unit tests
npm run test

# Run with UI
npm run test:ui

# Run with coverage
npm run test:coverage

# Watch mode
npm run test -- --watch
```

### 2.6. Checklist de Debug Frontend

```markdown
‚úÖ Frontend Debug Checklist:

‚ñ° `npm install` completou sem erros
‚ñ° `npm run build` passa 100% (sem erros)
‚ñ° ESLint configurado corretamente
‚ñ° CSS imports em ordem correta (themes.css antes de @tailwind)
‚ñ° Nenhum import de tokens em *.module.css
‚ñ° Todos React.memo com sintaxe correta
‚ñ° Paths relativos corretos (../ vs ../../)
‚ñ° Environment variables configuradas (.env)
‚ñ° DevTools React extension instalada
‚ñ° Network tab mostra requests corretos
‚ñ° Console sem erros cr√≠ticos
‚ñ° Hot reload funcionando
‚ñ° Production build testado (npm run preview)
```

---

## 3. DEBUGGING DO BACKEND

### 3.1. Setup de Desenvolvimento

```bash
# Navegue para o backend
cd /home/juan/vertice-dev/backend

# Ative o virtualenv (se necess√°rio)
source ../.venv/bin/activate

# Ou use o venv do projeto
python3 -m venv venv
source venv/bin/activate

# Instale depend√™ncias de um servi√ßo espec√≠fico
cd services/ai_agent_service
pip install -r requirements.txt
```

### 3.2. Estrutura de Servi√ßos

```
backend/
‚îú‚îÄ‚îÄ api_gateway/          # Entry point
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ ai_agent_service/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ reasoning_engine.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ memory_system.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tools_world_class.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tool_orchestrator.py
‚îÇ   ‚îú‚îÄ‚îÄ aurora_orchestrator_service/
‚îÇ   ‚îú‚îÄ‚îÄ threat_intel_service/
‚îÇ   ‚îú‚îÄ‚îÄ malware_analysis_service/
‚îÇ   ‚îú‚îÄ‚îÄ ... (18 outros servi√ßos)
```

### 3.3. Problemas Comuns e Solu√ß√µes

#### ‚ùå Erro: `ModuleNotFoundError: No module named 'fastapi'`

**Causa**: Depend√™ncias n√£o instaladas

**Solu√ß√£o**:
```bash
cd backend/services/[service_name]
pip install -r requirements.txt

# Ou instale globalmente no venv do projeto
pip install fastapi uvicorn httpx pydantic python-dotenv redis
```

#### ‚ùå Erro: `ImportError: cannot import name 'ReasoningEngine'`

**Causa**: M√≥dulos locais n√£o encontrados (PYTHONPATH)

**Solu√ß√£o**:
```bash
# Op√ß√£o 1: Run do diret√≥rio do servi√ßo
cd backend/services/ai_agent_service
uvicorn main:app --reload

# Op√ß√£o 2: Ajustar PYTHONPATH
export PYTHONPATH=/home/juan/vertice-dev/backend/services/ai_agent_service:$PYTHONPATH
python main.py

# Op√ß√£o 3: Use Docker (recomendado)
docker-compose up ai_agent_service
```

#### ‚ùå Erro: Port Already in Use

**Sintoma**: `OSError: [Errno 98] Address already in use`

**Debug**:
```bash
# Descubra qual processo est√° usando a porta
lsof -i :8017
# ou
netstat -tulpn | grep 8017

# Mate o processo
kill -9 [PID]

# Ou use outra porta
uvicorn main:app --port 8018 --reload
```

#### ‚ùå Erro: Connection Refused ao chamar outro servi√ßo

**Sintoma**: `httpx.ConnectError: [Errno 111] Connection refused`

**Causa**: Servi√ßo dependente n√£o est√° rodando

**Debug**:
```bash
# Liste todos os containers
docker ps

# Verifique se o servi√ßo alvo est√° UP
docker ps | grep threat_intel_service

# Se n√£o estiver, inicie-o
docker-compose up -d threat_intel_service

# Veja os logs
docker logs -f vertice-threat-intel
```

#### ‚ùå Erro: API Key Missing

**Sintoma**: `KeyError: 'ANTHROPIC_API_KEY'`

**Solu√ß√£o**:
```bash
# Crie .env na raiz do projeto
cd /home/juan/vertice-dev

cat > .env << EOF
# AI Services
ANTHROPIC_API_KEY=sk-ant-xxxxx
OPENAI_API_KEY=sk-xxxxx
GEMINI_API_KEY=xxxxx

# Threat Intelligence
ABUSEIPDB_API_KEY=xxxxx
VIRUSTOTAL_API_KEY=xxxxx
GREYNOISE_API_KEY=xxxxx
OTX_API_KEY=xxxxx

# Auth
GOOGLE_CLIENT_ID=xxxxx
GOOGLE_CLIENT_SECRET=xxxxx
JWT_SECRET=vertice-super-secret-key-2024

# Feature Flags
LLM_PROVIDER=anthropic
EOF

# Recarregue os containers
docker-compose down
docker-compose up -d
```

### 3.4. Running Services Standalone

```bash
# Modo 1: Uvicorn direto (desenvolvimento)
cd backend/services/ai_agent_service
uvicorn main:app --host 0.0.0.0 --port 8017 --reload

# Modo 2: Python direto (se main.py tem __main__)
python main.py

# Modo 3: Docker (produ√ß√£o-like)
docker-compose up ai_agent_service

# Modo 4: Docker com rebuild
docker-compose up --build ai_agent_service
```

### 3.5. Debugging com Logs

#### Adicionar Logs Detalhados

```python
# Em main.py de qualquer servi√ßo
import logging

# Configure logging
logging.basicConfig(
    level=logging.DEBUG,  # Mude para INFO em produ√ß√£o
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

# Use em endpoints
@app.post("/analyze")
async def analyze(request: AnalysisRequest):
    logger.info(f"Received analysis request: {request.target}")

    try:
        result = await perform_analysis(request.target)
        logger.info(f"Analysis completed: {result.status}")
        return result
    except Exception as e:
        logger.error(f"Analysis failed: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))
```

#### Ver Logs de Containers

```bash
# Logs de um servi√ßo espec√≠fico
docker logs -f vertice-ai-agent

# Logs com timestamp
docker logs -f --timestamps vertice-ai-agent

# √öltimas 100 linhas
docker logs --tail 100 vertice-ai-agent

# Logs de todos os servi√ßos
docker-compose logs -f

# Logs apenas do gateway
docker-compose logs -f api_gateway
```

### 3.6. Health Checks

```bash
# Check se o servi√ßo est√° respondendo
curl http://localhost:8017/health

# Check todos os servi√ßos via gateway
curl http://localhost:8000/health

# Check com jq para format bonito
curl -s http://localhost:8017/health | jq .
```

#### Implementar Health Check

```python
# Adicione em main.py de cada servi√ßo
@app.get("/health")
async def health_check():
    return {
        "status": "healthy",
        "service": "ai_agent_service",
        "version": "1.0.0",
        "timestamp": datetime.utcnow().isoformat(),
        "dependencies": {
            "redis": await check_redis(),
            "llm_api": await check_llm_api(),
        }
    }

async def check_redis():
    try:
        # Test Redis connection
        # return True if OK
        return {"status": "ok"}
    except:
        return {"status": "error"}
```

### 3.7. Interactive Debugging (pdb)

```python
# Adicione breakpoint no c√≥digo
import pdb

@app.post("/analyze")
async def analyze(request: AnalysisRequest):
    pdb.set_trace()  # Execu√ß√£o vai pausar aqui

    # Ou use o builtin (Python 3.7+)
    breakpoint()

    result = await perform_analysis(request.target)
    return result
```

**Uso**:
```bash
# Run uvicorn em modo interativo (n√£o --reload)
uvicorn main:app --host 0.0.0.0 --port 8017

# Fa√ßa request
curl -X POST http://localhost:8017/analyze -d '{"target":"test"}'

# Terminal vai entrar em debug mode:
# (Pdb) print(request)
# (Pdb) print(request.target)
# (Pdb) continue  # ou 'c' para continuar
```

### 3.8. Performance Profiling

```python
# Adicione profiling
import cProfile
import pstats
from io import StringIO

@app.post("/analyze")
async def analyze(request: AnalysisRequest):
    profiler = cProfile.Profile()
    profiler.enable()

    result = await perform_analysis(request.target)

    profiler.disable()
    s = StringIO()
    ps = pstats.Stats(profiler, stream=s).sort_stats('cumulative')
    ps.print_stats()

    logger.info(f"Profiling results:\n{s.getvalue()}")
    return result
```

### 3.9. Testing Backend

```bash
# Run pytest em um servi√ßo
cd backend/services/ai_agent_service
pytest test_world_class_tools.py -v

# Run com coverage
pytest --cov=. --cov-report=html

# Run apenas testes de integra√ß√£o
pytest -m integration

# Run com output detalhado
pytest -vv -s
```

### 3.10. Checklist de Debug Backend

```markdown
‚úÖ Backend Debug Checklist:

‚ñ° Python 3.11+ instalado
‚ñ° Virtualenv ativado
‚ñ° `pip install -r requirements.txt` completou
‚ñ° .env configurado com todas as API keys
‚ñ° Redis rodando (docker ou local)
‚ñ° Port desejada livre (n√£o em uso)
‚ñ° PYTHONPATH correto (se rodando fora do Docker)
‚ñ° Depend√™ncias externas acess√≠veis (APIs de terceiros)
‚ñ° Health check respondendo /health
‚ñ° Logs configurados (logging.basicConfig)
‚ñ° Tratamento de exce√ß√µes em todos endpoints
‚ñ° Timeout configurado em httpx.AsyncClient
‚ñ° CORS configurado no FastAPI (se necess√°rio)
‚ñ° Docker compose up sem erros
```

---

## 4. DEBUGGING DO VERTICE CLI

### 4.1. Setup

```bash
cd /home/juan/vertice-dev/vertice_cli

# Criar virtualenv
python3 -m venv venv
source venv/bin/activate

# Instalar depend√™ncias
pip install -r requirements.txt

# Configurar .env
cp .env.example .env
# Edite e adicione GEMINI_API_KEY
```

### 4.2. Estrutura

```
vertice_cli/
‚îú‚îÄ‚îÄ cli.py              # Main CLI commands (Or√°culo, Eureka, etc.)
‚îú‚îÄ‚îÄ main_cli.py         # Alternative entry point
‚îú‚îÄ‚îÄ utils.py            # Utilities (console, banner, git)
‚îú‚îÄ‚îÄ utils/              # Utility modules
‚îú‚îÄ‚îÄ modules/            # Additional modules
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ .env.example
```

### 4.3. Running CLI

```bash
# Modo 1: Python direto
python cli.py --help

# Modo 2: Make executable
chmod +x cli.py
./cli.py --help

# Modo 3: Install como package (recomendado)
pip install -e .
vertice --help
```

### 4.4. Problemas Comuns

#### ‚ùå Erro: `No module named 'google.generativeai'`

**Solu√ß√£o**:
```bash
pip install google-generativeai
```

#### ‚ùå Erro: `KeyError: 'GEMINI_API_KEY'`

**Solu√ß√£o**:
```bash
# Adicione ao .env
echo "GEMINI_API_KEY=your-key-here" >> .env

# Ou export tempor√°rio
export GEMINI_API_KEY=your-key-here
```

#### ‚ùå Erro: CLI n√£o encontra comandos

**Debug**:
```python
# Em cli.py, adicione debug
@app.callback()
def main():
    """Vertice CLI."""
    import sys
    print(f"Python path: {sys.path}")
    print(f"Current dir: {os.getcwd()}")
```

### 4.5. Debugging CLI Commands

```python
# Adicione verbose mode
@app.command()
def oraculo(verbose: bool = False):
    """Gera ideias t√©cnicas."""

    if verbose:
        console.print("[cyan]Debug mode enabled[/cyan]")
        console.print(f"Working dir: {os.getcwd()}")
        console.print(f"Files collected: {len(files)}")

    # ... resto do c√≥digo
```

**Uso**:
```bash
python cli.py oraculo --verbose
```

### 4.6. Gemini API Debugging

```python
# Test connection
import google.generativeai as genai
import os
from dotenv import load_dotenv

load_dotenv()
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

model = genai.GenerativeModel('gemini-1.5-pro-latest')

response = model.generate_content("Hello world")
print(response.text)
```

#### Rate Limiting

```python
import time
from functools import wraps

def rate_limit(calls_per_minute=15):
    """Decorator para rate limiting."""
    min_interval = 60.0 / calls_per_minute
    last_called = [0.0]

    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            elapsed = time.time() - last_called[0]
            left_to_wait = min_interval - elapsed

            if left_to_wait > 0:
                time.sleep(left_to_wait)

            last_called[0] = time.time()
            return func(*args, **kwargs)
        return wrapper
    return decorator

@rate_limit(calls_per_minute=15)
def call_gemini(prompt):
    response = model.generate_content(prompt)
    return response.text
```

### 4.7. Git Integration Debug

```python
# Test git commands
from utils import git_safe_execute

# Check if git repo
result = git_safe_execute("git status")
print(result)

# Check branch
result = git_safe_execute("git branch --show-current")
print(f"Current branch: {result.strip()}")
```

### 4.8. Checklist CLI Debug

```markdown
‚úÖ CLI Debug Checklist:

‚ñ° Python 3.11+ instalado
‚ñ° Virtualenv ativado
‚ñ° Depend√™ncias instaladas (requirements.txt)
‚ñ° .env configurado com GEMINI_API_KEY
‚ñ° Typer instalado corretamente
‚ñ° Rich e Questionary funcionando
‚ñ° Git dispon√≠vel no PATH
‚ñ° Permiss√£o de execu√ß√£o (chmod +x)
‚ñ° CLI entry point correto (app = typer.Typer())
‚ñ° Comandos registrados (@app.command())
‚ñ° Utils funcionando (banner, console)
‚ñ° Rate limiting implementado para API
```

---

## 5. DEBUGGING DA INFRAESTRUTURA DOCKER

### 5.1. Docker Compose Basics

```bash
# Start all services
docker-compose up -d

# Start specific service
docker-compose up -d ai_agent_service

# Stop all
docker-compose down

# Stop and remove volumes
docker-compose down -v

# Rebuild
docker-compose up --build

# View status
docker-compose ps

# View logs
docker-compose logs -f [service_name]
```

### 5.2. Problemas Comuns

#### ‚ùå Erro: `Cannot start service X: port is already allocated`

**Debug**:
```bash
# Encontre o processo usando a porta
sudo lsof -i :8017

# Mate o processo
sudo kill -9 [PID]

# Ou mude a porta no docker-compose.yml
ports:
  - "8018:80"  # Mude 8017 para 8018
```

#### ‚ùå Erro: Container reiniciando constantemente

**Debug**:
```bash
# Veja os logs
docker logs vertice-ai-agent

# Check exit code
docker inspect vertice-ai-agent | grep -A 5 "State"

# Run interativo para debug
docker run -it --rm vertice-ai-agent /bin/bash
```

#### ‚ùå Erro: Cannot connect to Docker daemon

**Solu√ß√£o**:
```bash
# Start Docker service
sudo systemctl start docker

# Add user to docker group
sudo usermod -aG docker $USER
newgrp docker

# Test
docker ps
```

#### ‚ùå Erro: Network vertice-network not found

**Solu√ß√£o**:
```bash
# Recrie a network
docker network create vertice-network

# Ou deixe o compose criar
docker-compose down
docker-compose up -d
```

### 5.3. Service Communication Debug

```bash
# Enter em um container
docker exec -it vertice-ai-agent /bin/bash

# Dentro do container, teste conectividade
curl http://threat_intel_service/health
curl http://redis:6379

# Test DNS resolution
nslookup threat_intel_service
ping threat_intel_service

# Check environment variables
env | grep SERVICE_URL
```

### 5.4. Volume Issues

```bash
# List volumes
docker volume ls

# Inspect volume
docker volume inspect vertice-dev_redis-data

# Remove unused volumes
docker volume prune

# Recreate volume
docker-compose down -v
docker-compose up -d
```

### 5.5. Resource Monitoring

```bash
# Check resource usage
docker stats

# Check disk usage
docker system df

# Clean up
docker system prune -a
```

### 5.6. Networking Debug

```bash
# Inspect network
docker network inspect vertice-network

# Check service IPs
docker inspect -f '{{.NetworkSettings.Networks.vertice-network.IPAddress}}' vertice-ai-agent

# Test connectivity between containers
docker exec vertice-ai-agent ping vertice-threat-intel
```

### 5.7. Volume Mounts vs Image Code (CR√çTICO)

**‚ö†Ô∏è ARMADILHA COMUM**: Volume mounts SOBRESCREVEM c√≥digo da imagem Docker, mesmo ap√≥s rebuild!

#### Problema

```yaml
# docker-compose.yml
services:
  my_service:
    build: ./backend/services/my_service
    volumes:
      - ./backend/services/my_service:/app  # ‚ö†Ô∏è SOBRESCREVE a imagem!
```

**Cen√°rio**:
1. Voc√™ corrige um bug no c√≥digo HOST (`my_service/main.py`)
2. Faz rebuild: `docker compose build my_service`
3. Container AINDA falha com o erro antigo! üò±

**Causa**: O volume mount `-v ./backend/services/my_service:/app` monta o diret√≥rio HOST sobre `/app` no container, **ignorando** os arquivos da imagem.

#### Diagn√≥stico

```bash
# 1. Verifique se tem volume mount
docker inspect my_service | grep -A 10 '"Mounts"'

# 2. Compare checksums (HOST vs Container)
md5sum /home/juan/vertice-dev/backend/services/my_service/main.py
docker exec my_service md5sum /app/main.py
# Se diferentes = problema!

# 3. Verifique timestamps
ls -l backend/services/my_service/main.py  # Modificado HOJE
docker exec my_service ls -l /app/main.py   # Modificado SEMANA PASSADA
```

#### Solu√ß√µes

**Op√ß√£o 1: Remover volume mount (Produ√ß√£o)**
```yaml
# docker-compose.yml
services:
  my_service:
    build: ./backend/services/my_service
    # volumes:  # ‚ùå REMOVER em produ√ß√£o
    #   - ./backend/services/my_service:/app
```

**Op√ß√£o 2: Rebuild SEM cache**
```bash
docker compose build --no-cache my_service
docker compose up -d my_service
```

**Op√ß√£o 3: Docker cp (Quick fix para builds demorados)**
```bash
# √ötil quando Dockerfile demora >5min (ex: compila Hyperscan)
docker cp ./backend/services/my_service/main.py my_service:/app/
docker cp ./backend/services/my_service/utils.py my_service:/app/
docker restart my_service
```

**Op√ß√£o 4: Limpar cache Python**
```bash
# Bytecode cache pode persistir com c√≥digo antigo
docker exec my_service find /app -type d -name __pycache__ -exec rm -rf {} +
docker exec my_service find /app -type f -name "*.pyc" -delete
docker restart my_service
```

#### Caso Real: RTE Service

**Problema**: Container rodava c√≥digo de 3 dias atr√°s (com Hyperscan real), HOST tinha c√≥digo novo (MockHyperscan).

```bash
# Diagn√≥stico
$ docker exec rte-service head -20 /app/hyperscan_matcher.py | grep "import hyperscan"
import hyperscan  # ‚ö†Ô∏è C√≥digo ANTIGO!

$ head -20 ./backend/services/rte_service/hyperscan_matcher.py | grep "class Mock"
class MockHyperscan:  # ‚úÖ C√≥digo NOVO!

# Solu√ß√£o: docker cp (rebuild demoraria 10+ min compilando Hyperscan)
$ docker cp ./backend/services/rte_service/hyperscan_matcher.py rte-service:/app/
$ docker cp ./backend/services/rte_service/main.py rte-service:/app/
$ docker restart rte-service
# ‚úÖ Funcionou!
```

#### üìä Tabela Comparativa das Solu√ß√µes

| Solu√ß√£o | Velocidade | Persist√™ncia | Quando Usar | Limita√ß√µes |
|---------|------------|--------------|-------------|------------|
| **Op√ß√£o 1: Remover volume mount** | ‚ö†Ô∏è Lenta (rebuild completo) | ‚úÖ Permanente | Produ√ß√£o, CI/CD | Perde hot-reload em dev |
| **Op√ß√£o 2: Rebuild --no-cache** | ‚ö†Ô∏è Muito lenta (5-30min) | ‚úÖ Permanente | Build complexos (depend√™ncias sistema) | Alto consumo de CPU/mem√≥ria |
| **Op√ß√£o 3: docker cp** | ‚úÖ R√°pida (<5s) | ‚ö†Ô∏è Tempor√°ria* | Dev, quick fixes, builds >5min | Perdido ao recreate container |
| **Op√ß√£o 4: Limpar cache Python** | ‚úÖ R√°pida (10-30s) | ‚úÖ Semi-permanente | Ap√≥s git pull, ap√≥s edits | S√≥ resolve bytecode cache |

\* docker cp √© tempor√°rio: mudan√ßas s√£o perdidas se container for **recreado** (n√£o se for apenas **restartado**)

#### üîÄ Flowchart de Decis√£o

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ C√≥digo corrigido n√£o reflete no    ‚îÇ
‚îÇ container ap√≥s rebuild?             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
               ‚îÇ
               ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Tem volume mount no docker-compose?  ‚îÇ
‚îÇ grep -A 3 "my_service:" docker-compose.yml‚îÇ
‚îÇ                                      ‚îÇ
‚îÇ volumes:                             ‚îÇ
‚îÇ   - ./backend/services/my_service:/app‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  SIM  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Tipo de mudan√ßa?                     ‚îÇ
‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   ‚îÇ                             ‚îÇ
   ‚îÇ C√≥digo Python (*.py)        ‚îÇ Depend√™ncias (requirements.txt)
   ‚îÇ                             ‚îÇ ou libs sistema (Dockerfile)
   ‚îÇ                             ‚îÇ
   ‚ñº                             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Build demora     ‚îÇ      ‚îÇ Rebuild obrigat√≥rio  ‚îÇ
‚îÇ >5 minutos?      ‚îÇ      ‚îÇ                      ‚îÇ
‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ docker compose build ‚îÇ
   ‚îÇ           ‚îÇ          ‚îÇ --no-cache service   ‚îÇ
   ‚îÇ SIM       ‚îÇ N√ÉO      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   ‚îÇ           ‚îÇ
   ‚ñº           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇdocker‚îÇ  ‚îÇLimpar cache ‚îÇ
‚îÇcp +  ‚îÇ  ‚îÇPython:      ‚îÇ
‚îÇrestart‚îÇ  ‚îÇ__pycache__  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ*.pyc        ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### üÜï Casos Reais - Sess√£o 2025-10-05

Esta sess√£o resolveu **12 containers unhealthy ‚Üí healthy** aplicando diferentes estrat√©gias:

##### Caso 1: maximus-core - Depend√™ncia Faltante (Rebuild Obrigat√≥rio)

```bash
# Sintoma
$ docker logs maximus-core --tail 10
ModuleNotFoundError: No module named 'aiohttp'

# Diagn√≥stico
$ grep aiohttp backend/services/maximus_core_service/enhanced_cognition_tools.py
import aiohttp  # ‚úÖ C√≥digo usa
$ grep aiohttp backend/services/maximus_core_service/requirements.txt
# (vazio) ‚ùå Faltava no requirements!

# Solu√ß√£o: Rebuild (mudan√ßa em Dockerfile/requirements)
$ echo "aiohttp==3.9.1" >> backend/services/maximus_core_service/requirements.txt
$ docker compose build --no-cache maximus_core_service
$ docker compose up -d maximus_core_service
# ‚úÖ Container healthy!
```

**Li√ß√£o**: Mudan√ßas em `requirements.txt` ou `Dockerfile` **exigem rebuild**, `docker cp` n√£o funciona.

##### Caso 2: narrative_filter - Configura√ß√£o Completa (Rebuild Estrat√©gico)

```bash
# Problema: ImportError + AttributeError + ConnectionRefused (m√∫ltiplos erros)
$ docker logs narrative_manipulation_filter --tail 50
ImportError: cannot import name 'get_settings' from 'config'
AttributeError: 'Settings' object has no attribute 'VERSION'
ConnectionRefused: localhost:5432  # Apontando para localhost em vez de postgres

# Corre√ß√µes aplicadas NO HOST:
# 1. Criar fun√ß√£o get_settings() em config.py
# 2. Fix imports relativos (sed global)
# 3. Corrigir attribute names (VERSION‚ÜíSERVICE_VERSION)
# 4. Mudar defaults de infraestrutura (localhost‚Üípostgres/redis/kafka)

# Rebuild estrat√©gico (--no-cache para garantir)
$ docker compose build --no-cache narrative_manipulation_filter
$ docker compose up -d narrative_manipulation_filter

# Resultado: 100% operacional
$ curl http://localhost:8213/health
{"status":"healthy","services":{"postgres":true,"redis":true,"kafka":true}}
```

**Li√ß√£o**: Mudan√ßas arquiteturais (imports, config) precisam de rebuild limpo.

##### Caso 3: 8x Healthchecks - Recreate sem Rebuild

```bash
# Problema: Containers funcionais mas marcados "unhealthy"
$ docker ps | grep unhealthy | wc -l
8

# Diagn√≥stico
$ docker inspect vertice-hcl-monitor --format '{{json .State.Health.Log}}' | jq '.[-1]'
{
  "ExitCode": 1,
  "Output": "/bin/sh: 1: curl: not found\n"
}

# Causa: Healthcheck usando curl (n√£o instalado em python:3.11-slim)
# docker-compose.yml:
#   healthcheck:
#     test: ["CMD-SHELL", "curl -f http://localhost:8023/health || exit 1"]

# Solu√ß√£o: Mudar para Python (sem rebuild!)
# Editar docker-compose.yml:
#   healthcheck:
#     test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8023/health')"]

# Recreate containers (N√ÉO rebuild)
$ docker compose up -d hcl_monitor_service hcl_planner_service hcl_kb_service # ... (8 servi√ßos)

# Aguardar 40s (start_period) e verificar
$ docker ps --filter "name=hcl" --format "table {{.Names}}\t{{.Status}}"
vertice-hcl-monitor    Up 50 seconds (healthy)
vertice-hcl-planner    Up 50 seconds (healthy)
vertice-hcl-kb         Up 50 seconds (healthy)
# ... todos healthy!
```

**Li√ß√£o**: Mudan√ßas em `docker-compose.yml` (healthcheck, env vars, ports) s√≥ precisam **recreate**, n√£o rebuild.

##### Caso 4: immunis-macrophage - Biblioteca Sistema (Rebuild com Dockerfile Fix)

```bash
# Erro
$ docker logs vertice-immunis-macrophage --tail 20
ModuleNotFoundError: No module named 'yara'

# Diagn√≥stico
$ grep yara backend/services/immunis_macrophage_service/requirements.txt
yara-python==4.3.1  # ‚úÖ Est√° no requirements

$ grep yara backend/services/immunis_macrophage_service/Dockerfile
# (vazio) ‚ùå Falta biblioteca sistema libyara-dev!

# Corre√ß√£o: Adicionar lib sistema no Dockerfile
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    libyara-dev \  # ‚Üê ADICIONADO
    && rm -rf /var/lib/apt/lists/*

# Rebuild obrigat√≥rio
$ docker compose build --no-cache immunis_macrophage_service
$ docker compose up -d immunis_macrophage_service
# ‚úÖ healthy ap√≥s 50s!
```

**Li√ß√£o**: Depend√™ncias de sistema operacional (apt-get, yum, apk) exigem rebuild completo.

#### üìã Checklist de Diagn√≥stico R√°pido

**Antes de escolher solu√ß√£o, responda:**

- [ ] A mudan√ßa √© s√≥ em c√≥digo Python? ‚Üí Considere `docker cp` ou limpar cache
- [ ] Mudou `requirements.txt` ou `Dockerfile`? ‚Üí **Rebuild obrigat√≥rio**
- [ ] Mudou `docker-compose.yml`? ‚Üí **Recreate** (n√£o rebuild)
- [ ] Build demora >5 minutos? ‚Üí Use `docker cp` para dev, rebuild para prod
- [ ] Container tem volume mount? ‚Üí **Problema prov√°vel**, veja checklist acima
- [ ] Erro persiste ap√≥s rebuild normal? ‚Üí Use `--no-cache`
- [ ] √â produ√ß√£o ou CI/CD? ‚Üí **Sempre rebuild**, nunca docker cp

**Comandos de diagn√≥stico r√°pido:**
```bash
# 1. Tem volume mount?
docker inspect my_service | grep -A 5 '"Mounts"'

# 2. C√≥digo HOST vs Container √© diferente?
md5sum ./backend/services/my_service/main.py
docker exec my_service md5sum /app/main.py

# 3. Build usou cache?
docker compose build my_service 2>&1 | grep CACHED

# 4. Container tem __pycache__ antigo?
docker exec my_service find /app -name "*.pyc" -exec ls -lh {} \; | head -5
```

### 5.8. Build Cache Mascarando Corre√ß√µes

**Sintoma**: Voc√™ corrige o c√≥digo, faz `docker compose build`, mas erro persiste.

**Causa**: Docker reutiliza layers em cache que t√™m c√≥digo antigo.

**Debug**:
```bash
# Veja se build usou cache
docker compose build my_service 2>&1 | grep CACHED

# Output:
#5 CACHED
#6 CACHED
#7 [5/5] COPY . .
#7 CACHED  # ‚ö†Ô∏è Copiou arquivos antigos do cache!
```

**Solu√ß√£o**:
```bash
# Force rebuild completo
docker compose build --no-cache my_service

# Ou para todos os servi√ßos
docker compose build --no-cache

# Ou rebuild + recreate container
docker compose up --build --force-recreate my_service
```

### 5.9. Imports Opcionais para Depend√™ncias Pesadas

**Problema**: Biblioteca est√° no `requirements.txt` mas instala√ß√£o falhou silenciosamente, causando `ImportError` em runtime.

**Solu√ß√£o: Try/Except Imports**

```python
# ‚ùå ANTES: Import direto
from prometheus_client import CollectorRegistry, Gauge, push_to_gateway
from kafka import KafkaProducer
from sklearn.metrics import r2_score

# ‚úÖ DEPOIS: Import opcional com fallback
try:
    from prometheus_client import CollectorRegistry, Gauge, push_to_gateway
    PROMETHEUS_AVAILABLE = True
except ImportError:
    PROMETHEUS_AVAILABLE = False
    CollectorRegistry = None
    Gauge = None
    push_to_gateway = None

try:
    from kafka import KafkaProducer
    from kafka.errors import KafkaError
    KAFKA_AVAILABLE = True
except ImportError:
    KAFKA_AVAILABLE = False
    KafkaProducer = None
    KafkaError = Exception

# Use nos m√©todos
def setup_prometheus(self):
    if not PROMETHEUS_AVAILABLE:
        logger.warning("Prometheus client not available, metrics disabled")
        return

    self.registry = CollectorRegistry()
    # ... resto do c√≥digo
```

**Vantagens**:
- Container inicia mesmo sem depend√™ncia opcional
- Logs claros sobre features desabilitadas
- Facilita desenvolvimento incremental
- Produ√ß√£o continua funcionando (degraded mode)

### 5.10. Containers Duplicados (Naming Conflicts)

**Problema**: `docker ps` mostra containers com nomes diferentes para o mesmo servi√ßo.

```bash
$ docker ps --format "{{.Names}}"
hcl-executor           # ‚ùå Duplicado
vertice-hcl-executor   # ‚úÖ Oficial
rte-service            # ‚ùå Duplicado
vertice-rte            # ‚úÖ Oficial
```

**Causa**: M√∫ltiplas defini√ß√µes no `docker-compose.yml` ou m√∫ltiplos docker-compose files.

**Debug**:
```bash
# Encontre defini√ß√µes duplicadas
grep -n "hcl.*executor:" docker-compose.yml
# 542:  hcl-executor:
# 892:  hcl_executor_service:

# Veja quais est√£o rodando
docker ps --filter "name=hcl" --format "table {{.Names}}\t{{.Image}}\t{{.Status}}"
```

**Solu√ß√£o**:
```bash
# Pare duplicados problem√°ticos
docker stop hcl-executor rte-service

# Mantenha apenas os oficiais (vertice-*)
docker ps | grep vertice-hcl-executor  # ‚úÖ Este est√° OK

# Remova containers √≥rf√£os
docker compose down --remove-orphans
```

### 5.11. Debugging Workflow Completo

```bash
# ========================================
# CONTAINER RESTARTING - WORKFLOW DEBUG
# ========================================

# 1. Identifique o container problem√°tico
docker ps -a | grep -i restart
# OUTPUT: my_service  Restarting (1) 5 seconds ago

# 2. Veja os logs (√∫ltimas linhas mostram o erro)
docker logs my_service 2>&1 | tail -50
# OUTPUT: ImportError: cannot import name 'get_mode_policy'

# 3. Verifique se c√≥digo no container difere do HOST
docker exec my_service cat /app/file.py | head -20
cat ./backend/services/my_service/file.py | head -20
# Compare visualmente ou com diff

# 4. Verifique volume mounts
docker inspect my_service | grep -A 10 '"Mounts"'
# Se tem volume mount: c√≥digo HOST √© usado
# Se N√ÉO tem: c√≥digo da imagem √© usado

# 5A. Se TEM volume mount: corrija no HOST
vim ./backend/services/my_service/file.py
docker restart my_service

# 5B. Se N√ÉO TEM volume mount: rebuild imagem
docker compose build --no-cache my_service
docker compose up -d my_service

# 5C. Se build demora muito: docker cp como workaround
docker cp ./backend/services/my_service/file.py my_service:/app/
docker restart my_service

# 6. Valide a corre√ß√£o
docker logs my_service 2>&1 | tail -20
# Deve mostrar: "INFO: Started server process"

# 7. Test health endpoint
curl http://localhost:PORT/health
# OUTPUT: {"status":"healthy"}
```

### 5.12. Checklist Docker Debug

```markdown
‚úÖ Docker Debug Checklist:

‚ñ° Docker daemon running (sudo systemctl status docker)
‚ñ° User in docker group (groups | grep docker)
‚ñ° docker-compose.yml syntax v√°lido
‚ñ° Todas as portas livres (n√£o em uso)
‚ñ° .env file presente na raiz
‚ñ° Networks criadas (docker network ls)
‚ñ° Volumes criados (docker volume ls)
‚ñ° Todos containers UP (docker-compose ps)
‚ñ° Logs sem erros cr√≠ticos (docker-compose logs)
‚ñ° Services comunicando entre si (curl interno)
‚ñ° Health checks passando
‚ñ° Resources suficientes (RAM, disk)

üÜï VERIFICA√á√ïES AVAN√áADAS (Aprendizados 2025-10-04):
‚ñ° Volume mounts N√ÉO sobrescrevendo c√≥digo corrigido
‚ñ° C√≥digo no container IGUAL ao c√≥digo no HOST (md5sum)
‚ñ° Build SEM usar cache para arquivos modificados
‚ñ° Imports opcionais implementados para deps pesadas
‚ñ° Sem containers duplicados (naming conflicts)
‚ñ° Python __pycache__ limpo ap√≥s mudan√ßas
‚ñ° Dockerfile COPY atualizado (se sem volume mount)
```

---

## 6. DEBUGGING DE SERVI√áOS ESPEC√çFICOS

### 6.1. AI Agent Service (Port 8017)

**Componentes**:
- Reasoning Engine (chain-of-thought)
- Memory System (short/long-term)
- Tool Orchestrator (parallel execution)
- World-Class Tools (21 tools)

**Debug Espec√≠fico**:
```bash
# Test reasoning engine
curl -X POST http://localhost:8017/think \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Analyze IP 1.2.3.4",
    "context": "security"
  }'

# Test tool execution
curl -X POST http://localhost:8017/execute-tool \
  -H "Content-Type: application/json" \
  -d '{
    "tool_name": "ip_intelligence",
    "parameters": {"ip": "1.2.3.4"}
  }'

# Check memory
curl http://localhost:8017/memory/context/session-123
```

**Logs Importantes**:
```python
logger.info(f"[ReasoningEngine] Starting thought chain for: {query}")
logger.info(f"[ToolOrchestrator] Executing {len(tools)} tools in parallel")
logger.info(f"[MemorySystem] Retrieved {len(memories)} relevant memories")
```

### 6.2. Aurora Orchestrator (Port 8016)

**Purpose**: Coordena m√∫ltiplos servi√ßos para an√°lise hol√≠stica

**Debug**:
```bash
# Comprehensive analysis
curl -X POST http://localhost:8016/orchestrate \
  -H "Content-Type: application/json" \
  -d '{
    "target": "example.com",
    "analysis_types": ["domain", "ssl", "threat_intel", "vuln_scan"]
  }'

# Check orchestration status
curl http://localhost:8016/status/[job_id]
```

### 6.3. Threat Intel Service (Port 8013)

**APIs Integradas**:
- AbuseIPDB
- VirusTotal
- GreyNoise
- AlienVault OTX

**Debug**:
```bash
# Test API keys
curl http://localhost:8013/check-keys

# IP reputation
curl "http://localhost:8013/ip/1.2.3.4"

# Domain reputation
curl "http://localhost:8013/domain/malicious.com"
```

**Common Issues**:
- API key inv√°lida: Check .env
- Rate limit: Implement caching
- Timeout: Increase httpx timeout

### 6.4. Malware Analysis (Port 8014)

**Debug**:
```bash
# Upload file for analysis
curl -X POST http://localhost:8014/analyze \
  -F "file=@suspicious.exe"

# Check analysis status
curl http://localhost:8014/analysis/[hash]
```

### 6.5. Network Monitor (Port 8005)

**Requirements**: Precisa de `NET_ADMIN` e `NET_RAW` capabilities

**Debug**:
```bash
# Check capabilities
docker exec vertice-network-monitor capsh --print

# Start monitoring
curl -X POST http://localhost:8005/start

# Get events
curl http://localhost:8005/events

# Stop monitoring
curl -X POST http://localhost:8005/stop
```

### 6.6. OSINT Service (Port 8007)

**Features**:
- Social media investigation
- Breach data search
- Google dorking
- Dark web monitoring

**Debug**:
```bash
# Social media investigation
curl -X POST http://localhost:8007/investigate \
  -H "Content-Type: application/json" \
  -d '{
    "target": "username",
    "platforms": ["twitter", "linkedin", "github"]
  }'

# Breach data search
curl "http://localhost:8007/breach/email@example.com"
```

---

## 7. TROUBLESHOOTING COMUM

### 7.1. Frontend n√£o conecta ao Backend

**Sintoma**: CORS errors, network failed

**Debug**:
```javascript
// Check API URL
console.log('API URL:', import.meta.env.VITE_API_URL);

// Test connectivity
fetch('http://localhost:8000/health')
  .then(r => r.json())
  .then(d => console.log('Backend:', d))
  .catch(e => console.error('Error:', e));
```

**Solu√ß√£o**:
```python
# Em api_gateway/main.py
from fastapi.middleware.cors import CORSMiddleware

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173", "http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
```

### 7.2. Redis Connection Failed

**Debug**:
```bash
# Test Redis
docker exec -it vertice-redis redis-cli ping
# Deve retornar: PONG

# Check connections
docker exec -it vertice-redis redis-cli INFO clients

# Monitor commands
docker exec -it vertice-redis redis-cli MONITOR
```

**Solu√ß√£o**:
```python
# Em qualquer servi√ßo usando Redis
import redis

try:
    r = redis.Redis(host='redis', port=6379, decode_responses=True)
    r.ping()
    logger.info("Redis connection OK")
except redis.ConnectionError as e:
    logger.error(f"Redis connection failed: {e}")
```

### 7.3. High Memory Usage

**Debug**:
```bash
# Check memory by container
docker stats --no-stream

# Check memory limit
docker inspect vertice-ai-agent | grep -i memory

# Set memory limit
# Em docker-compose.yml:
services:
  ai_agent_service:
    mem_limit: 2g
    mem_reservation: 1g
```

### 7.4. Slow Response Times

**Debug**:
```bash
# Time requests
time curl http://localhost:8017/health

# Detailed timing
curl -w "@curl-format.txt" -o /dev/null -s http://localhost:8017/analyze

# curl-format.txt:
# time_total:  %{time_total}\n
# time_connect:  %{time_connect}\n
# time_starttransfer:  %{time_starttransfer}\n
```

**Solutions**:
- Add caching (Redis)
- Implement async operations
- Use connection pooling
- Optimize database queries
- Add pagination

### 7.5. Database Locks (se usar PostgreSQL/MySQL)

```sql
-- Check active locks
SELECT * FROM pg_locks WHERE granted = false;

-- Kill long-running queries
SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE state = 'active' AND query_start < NOW() - INTERVAL '5 minutes';
```

---

## 8. FERRAMENTAS E UTILIT√ÅRIOS

### 8.1. Health Check Script

```bash
#!/bin/bash
# health_check.sh

SERVICES=(
  "8000:API Gateway"
  "8001:SINESP"
  "8002:Cyber"
  "8003:Domain"
  "8004:IP Intel"
  "8005:Network Monitor"
  "8006:Nmap"
  "8007:OSINT"
  "8008:Aurora Predict"
  "8009:Atlas"
  "8010:Auth"
  "8011:Vuln Scanner"
  "8012:Social Eng"
  "8013:Threat Intel"
  "8014:Malware Analysis"
  "8015:SSL Monitor"
  "8016:Aurora Orchestrator"
  "8017:AI Agent"
)

echo "=== VERTICE HEALTH CHECK ==="
for service in "${SERVICES[@]}"; do
  port="${service%%:*}"
  name="${service##*:}"

  if curl -s -f "http://localhost:$port/health" > /dev/null; then
    echo "‚úÖ $name (port $port): HEALTHY"
  else
    echo "‚ùå $name (port $port): DOWN"
  fi
done

echo ""
echo "=== INFRASTRUCTURE ==="
docker exec vertice-redis redis-cli ping > /dev/null 2>&1 && echo "‚úÖ Redis: OK" || echo "‚ùå Redis: DOWN"
curl -s http://localhost:9090/-/healthy > /dev/null && echo "‚úÖ Prometheus: OK" || echo "‚ùå Prometheus: DOWN"
curl -s http://localhost:3001/api/health > /dev/null && echo "‚úÖ Grafana: OK" || echo "‚ùå Grafana: DOWN"
```

**Uso**:
```bash
chmod +x health_check.sh
./health_check.sh
```

### 8.2. Log Aggregation Script

```bash
#!/bin/bash
# aggregate_logs.sh

OUTPUT_DIR="./logs_$(date +%Y%m%d_%H%M%S)"
mkdir -p "$OUTPUT_DIR"

echo "Collecting logs to $OUTPUT_DIR..."

# Frontend logs
npm run build > "$OUTPUT_DIR/frontend_build.log" 2>&1

# Backend logs
for service in $(docker-compose ps --services); do
  echo "Collecting logs from $service..."
  docker logs "$service" > "$OUTPUT_DIR/${service}.log" 2>&1
done

# Docker stats
docker stats --no-stream > "$OUTPUT_DIR/docker_stats.txt"

# System info
df -h > "$OUTPUT_DIR/disk_usage.txt"
free -h > "$OUTPUT_DIR/memory_usage.txt"

echo "Logs collected in $OUTPUT_DIR"
tar -czf "${OUTPUT_DIR}.tar.gz" "$OUTPUT_DIR"
echo "Archive created: ${OUTPUT_DIR}.tar.gz"
```

### 8.3. Performance Test Script

```bash
#!/bin/bash
# perf_test.sh

echo "=== VERTICE PERFORMANCE TEST ==="

# Test API Gateway
echo "Testing API Gateway..."
ab -n 1000 -c 10 http://localhost:8000/health

# Test AI Agent
echo "Testing AI Agent..."
ab -n 100 -c 5 -p request.json -T application/json http://localhost:8017/analyze

# Test Threat Intel
echo "Testing Threat Intel..."
ab -n 500 -c 10 http://localhost:8013/ip/8.8.8.8

echo "Tests completed!"
```

### 8.4. Database Backup Script (se aplic√°vel)

```bash
#!/bin/bash
# backup_db.sh

BACKUP_DIR="./backups"
TIMESTAMP=$(date +%Y%m%d_%H%M%S)

mkdir -p "$BACKUP_DIR"

# Backup Redis
docker exec vertice-redis redis-cli SAVE
docker cp vertice-redis:/data/dump.rdb "$BACKUP_DIR/redis_$TIMESTAMP.rdb"

# Backup volumes
docker run --rm -v vertice-dev_redis-data:/data -v "$BACKUP_DIR":/backup alpine tar czf /backup/redis-volume_$TIMESTAMP.tar.gz /data

echo "Backup completed: $BACKUP_DIR"
```

---

## 9. LOGS CENTRALIZADOS

### 9.1. Loki + Grafana (Opcional)

```yaml
# docker-compose.yml - adicionar
loki:
  image: grafana/loki:latest
  ports:
    - "3100:3100"
  volumes:
    - ./loki-config.yml:/etc/loki/local-config.yaml
  networks:
    - vertice-network

promtail:
  image: grafana/promtail:latest
  volumes:
    - /var/log:/var/log
    - ./promtail-config.yml:/etc/promtail/config.yml
  networks:
    - vertice-network
```

### 9.2. Structured Logging

```python
# Implemente em todos os servi√ßos
import structlog

logger = structlog.get_logger()

@app.post("/analyze")
async def analyze(request: AnalysisRequest):
    logger.info(
        "analysis_started",
        target=request.target,
        user_id=request.user_id,
        timestamp=datetime.utcnow().isoformat()
    )

    try:
        result = await perform_analysis(request.target)
        logger.info("analysis_completed", target=request.target, status="success")
        return result
    except Exception as e:
        logger.error("analysis_failed", target=request.target, error=str(e), exc_info=True)
        raise
```

---

## 10. PERFORMANCE PROFILING

### 10.1. Frontend Performance

```javascript
// src/utils/performance.js
export const measurePerformance = (name, fn) => {
  const start = performance.now();
  const result = fn();
  const end = performance.now();

  console.log(`[Performance] ${name}: ${(end - start).toFixed(2)}ms`);

  // Send to analytics
  if (window.gtag) {
    window.gtag('event', 'timing_complete', {
      name: name,
      value: Math.round(end - start),
    });
  }

  return result;
};

// Uso:
measurePerformance('fetchData', () => {
  return axios.get('/api/data');
});
```

### 10.2. Backend Performance

```python
# Add profiling middleware
from time import time
from starlette.middleware.base import BaseHTTPMiddleware

class PerformanceMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request, call_next):
        start = time()
        response = await call_next(request)
        duration = time() - start

        response.headers["X-Process-Time"] = str(duration)

        logger.info(
            "request_completed",
            method=request.method,
            path=request.url.path,
            duration=duration,
            status_code=response.status_code
        )

        return response

app.add_middleware(PerformanceMiddleware)
```

### 10.3. Load Testing

```bash
# Install locust
pip install locust

# Create locustfile.py
cat > locustfile.py << 'EOF'
from locust import HttpUser, task, between

class VerticeUser(HttpUser):
    wait_time = between(1, 3)

    @task(3)
    def health_check(self):
        self.client.get("/health")

    @task(1)
    def analyze_ip(self):
        self.client.post("/api/ip/analyze", json={"ip": "8.8.8.8"})
EOF

# Run load test
locust -f locustfile.py --host=http://localhost:8000
# Acesse: http://localhost:8089
```

---

## üéØ QUICK REFERENCE CARD

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  VERTICE DEBUG CHEAT SHEET                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                              ‚îÇ
‚îÇ FRONTEND                                                     ‚îÇ
‚îÇ ‚Ä¢ Dev:     npm run dev                                       ‚îÇ
‚îÇ ‚Ä¢ Build:   npm run build                                     ‚îÇ
‚îÇ ‚Ä¢ Test:    npm run test                                      ‚îÇ
‚îÇ ‚Ä¢ URL:     http://localhost:5173                             ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ BACKEND                                                      ‚îÇ
‚îÇ ‚Ä¢ Start All:  docker-compose up -d                           ‚îÇ
‚îÇ ‚Ä¢ Logs:       docker-compose logs -f [service]               ‚îÇ
‚îÇ ‚Ä¢ Health:     curl http://localhost:8000/health              ‚îÇ
‚îÇ ‚Ä¢ Restart:    docker-compose restart [service]               ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ CLI                                                          ‚îÇ
‚îÇ ‚Ä¢ Run:     python cli.py --help                              ‚îÇ
‚îÇ ‚Ä¢ Env:     source venv/bin/activate                          ‚îÇ
‚îÇ ‚Ä¢ Test:    python cli.py oraculo                             ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ DOCKER                                                       ‚îÇ
‚îÇ ‚Ä¢ Status:  docker-compose ps                                 ‚îÇ
‚îÇ ‚Ä¢ Logs:    docker logs -f [container]                        ‚îÇ
‚îÇ ‚Ä¢ Shell:   docker exec -it [container] /bin/bash             ‚îÇ
‚îÇ ‚Ä¢ Clean:   docker system prune -a                            ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ COMMON PORTS                                                 ‚îÇ
‚îÇ ‚Ä¢ 5173:  Frontend Dev Server                                 ‚îÇ
‚îÇ ‚Ä¢ 8000:  API Gateway                                         ‚îÇ
‚îÇ ‚Ä¢ 8017:  AI Agent Service                                    ‚îÇ
‚îÇ ‚Ä¢ 6379:  Redis                                               ‚îÇ
‚îÇ ‚Ä¢ 9090:  Prometheus                                          ‚îÇ
‚îÇ ‚Ä¢ 3001:  Grafana                                             ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ EMERGENCY COMMANDS                                           ‚îÇ
‚îÇ ‚Ä¢ Kill port:  sudo lsof -i :[port] | grep LISTEN | awk '{print $2}' | xargs kill -9
‚îÇ ‚Ä¢ Restart all: docker-compose down && docker-compose up -d   ‚îÇ
‚îÇ ‚Ä¢ Clear cache: rm -rf node_modules/.vite dist/ && npm install‚îÇ
‚îÇ                                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## 11. DEBUGGING SISTEM√ÅTICO: METODOLOGIA E CASOS REAIS

### 11.1 FILOSOFIA: PLANEJAMENTO > TENTATIVA E ERRO

**REGRA DE OURO**: Nunca execute a√ß√µes "√†s cegas" esperando que funcionem.

```
‚ùå ERRADO: Tentativa e Erro
1. Criar c√≥digo gen√©rico
2. Executar docker build
3. Ver erro
4. Tentar corrigir
5. Repetir at√© funcionar

‚úÖ CORRETO: An√°lise ‚Üí Planejamento ‚Üí Execu√ß√£o
1. DIAGN√ìSTICO COMPLETO
   - Ler estrutura de arquivos
   - Verificar integra√ß√µes existentes
   - Identificar depend√™ncias
   - Entender o "whole picture"

2. CLASSIFICA√á√ÉO POR PADR√ÉO
   - Agrupar problemas similares
   - Identificar casos especiais
   - Documentar decis√µes arquiteturais

3. EXECU√á√ÉO MET√ìDICA
   - Implementar por padr√£o identificado
   - Testar incrementalmente
   - Validar cada etapa

4. VALIDA√á√ÉO E DOCUMENTA√á√ÉO
   - Confirmar funcionamento
   - Atualizar documenta√ß√£o
   - Registrar aprendizados
```

---

### 11.2 CASO REAL: CORRE√á√ÉO SISTEM√ÅTICA DE 22 SERVI√áOS UNHEALTHY

**Contexto**: 22 servi√ßos com status UNHEALTHY devido a falta de `api.py`.

#### FASE 1: DIAGN√ìSTICO ESTRUTURAL

```bash
# N√ÉO fazer:
for service in *; do
  cp template.py $service/api.py
  docker build $service
done

# FAZER: An√°lise completa primeiro
docker compose ps | grep unhealthy  # Identificar servi√ßos
ls backend/services/*/  # Verificar estrutura
grep -r "import" backend/services/*/main.py  # Entender depend√™ncias
```

**Descobertas do diagn√≥stico**:
- 7 servi√ßos Immunis: T√™m `*_core.py` mas sem `api.py`
- 5 servi√ßos HCL: T√™m `main.py` completo, precisam wrapper
- 2 servi√ßos funcionais: T√™m `main.py`, precisam wrapper
- 2 servi√ßos placeholder: SEM implementa√ß√£o real
- 3 servi√ßos com `api.py`: Precisam rebuild apenas

#### FASE 2: CLASSIFICA√á√ÉO E ESTRAT√âGIA

```python
# Padr√£o identificado via an√°lise:
SERVICES_PATTERNS = {
    "IMMUNIS": {
        "pattern": "Tem {service}_core.py mas sem api.py",
        "action": "Criar api.py com optional imports",
        "template": "API_TEMPLATE com graceful degradation",
        "count": 7
    },
    "HCL": {
        "pattern": "main.py completo com FastAPI app",
        "action": "Criar wrapper: from main import app",
        "template": "Simple re-export",
        "count": 5
    },
    "FUNCTIONAL": {
        "pattern": "main.py funcional usado em produ√ß√£o",
        "action": "Criar wrapper simples",
        "template": "Re-export pattern",
        "count": 2
    },
    "PLACEHOLDER": {
        "pattern": "Apenas __init__.py com docstring",
        "discovery": "Zero refer√™ncias no codebase",
        "action": "Comentar no docker-compose + documentar",
        "count": 2,
        "justificativa": "N√£o criar c√≥digo production-ready sem prop√≥sito"
    }
}
```

**Decis√£o Cr√≠tica - Seriema Graph**:

```bash
# Investiga√ß√£o revelou:
find . -name "*seriema*" -type f
# ‚Üí backend/services/narrative_manipulation_filter/seriema_graph_client.py

# An√°lise do client:
head -50 seriema_graph_client.py
# DESCOBERTA: Client conecta DIRETO ao Neo4j (bolt://neo4j:7687)
#             N√£o usa HTTP service intermedi√°rio!

# DECIS√ÉO ARQUITETURAL:
# ‚úÖ Comentar seriema_graph service (redundante)
# ‚úÖ Documentar em README.md
# ‚ùå N√ÉO criar REST API wrapper desnecess√°rio
```

---

### 11.3 PADR√ïES DE C√ìDIGO: OPTIONAL IMPORTS

**Problema**: Servi√ßos com depend√™ncias pesadas que podem falhar.

```python
# ‚ùå ERRADO: Import direto que quebra tudo
from heavy_module import HeavyClass

core = HeavyClass()  # BOOM se m√≥dulo n√£o existe

# ‚úÖ CORRETO: Optional imports com graceful degradation
try:
    from heavy_module import HeavyClass
    CORE_AVAILABLE = True
except ImportError:
    logger.warning("HeavyClass not available - running in limited mode")
    CORE_AVAILABLE = False
    HeavyClass = None

# Initialize only if available
if CORE_AVAILABLE and HeavyClass:
    try:
        core = HeavyClass()
    except Exception as e:
        logger.warning(f"Core initialization failed: {e}")
        core = None
else:
    core = None

# Use with safety checks
@app.post("/process")
async def process(request: Request):
    if not core:
        raise HTTPException(
            status_code=503,
            detail="Core not available - service in limited mode"
        )
    return await core.process(request.data)
```

**Vantagens**:
- Service sobe mesmo sem depend√™ncias
- Healthcheck passa (status: limited)
- Debug mais f√°cil (service responde)
- Production-ready (fail gracefully)

---

### 11.4 HONESTIDADE ARQUITETURAL

**Princ√≠pio**: N√£o criar c√≥digo "production-ready" sem prop√≥sito real.

```yaml
# ANTES: Service placeholder rodando
tataca_ingestion:
  build: ./backend/services/tataca_ingestion
  command: uvicorn main:app --host 0.0.0.0 --port 8028
  # main.py n√£o existe, vai falhar

# TENTA√á√ÉO: Criar main.py "m√≠nimo funcional"
# ‚ùå PROBLEMA: Viola REGRA DE OURO
# - C√≥digo quality-first sem fun√ß√£o
# - Desperdi√ßa recursos Docker
# - Confunde arquitetura

# CORRETO: Honestidade arquitetural
# tataca_ingestion:
#   build: ./backend/services/tataca_ingestion
#   # COMENTADO: Placeholder sem implementa√ß√£o
#   # Ver: backend/services/tataca_ingestion/README.md

# + README.md documentando:
# - Status atual (placeholder)
# - Prop√≥sito planejado
# - Por que est√° desabilitado
# - Pr√≥ximos passos
```

---

### 11.5 BUILD STRATEGIES: DEPEND√äNCIAS PESADAS

**Problema**: PyTorch (670MB) + CUDA libs causam timeout.

```bash
# ‚ùå ERRADO: Build s√≠ncrono travando terminal
docker compose build --no-cache rte_service
# Espera 5+ minutos travado...

# ‚úÖ CORRETO: Build ass√≠ncrono com monitoramento
docker compose build --no-cache rte_service 2>&1 | tee /tmp/build.log &
BUILD_PID=$!

# Continua trabalhando em outros servi√ßos
docker compose build --no-cache google_osint_service  # R√°pido (30s)
docker compose build --no-cache hcl_*_service  # Paralelo

# Monitora quando necess√°rio
tail -f /tmp/build.log
# ou
docker compose ps rte_service
```

**Timeout Management**:

```bash
# Para comandos longos, usar timeout estendido
docker compose build --no-cache heavy_service &
sleep 300  # 5 minutos
docker compose ps heavy_service  # Verificar status
```

---

### 11.6 WORKFLOW COMPLETO: SERVI√áO UNHEALTHY ‚Üí HEALTHY

```bash
# ETAPA 1: DIAGN√ìSTICO (N√ÉO PULE ISSO!)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
ls backend/services/TARGET_SERVICE/  # Estrutura
cat backend/services/TARGET_SERVICE/main.py | head -50  # Implementa√ß√£o
grep -r "TARGET_SERVICE" backend/services/  # Integra√ß√µes
awk '/TARGET_SERVICE:/,/restart:/' docker-compose.yml  # Config

# ETAPA 2: CLASSIFICA√á√ÉO
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Tem main.py funcional? ‚Üí Wrapper pattern
# Tem *_core.py? ‚Üí Optional imports pattern
# S√≥ __init__.py? ‚Üí Investigar se √© placeholder
# Nenhum arquivo? ‚Üí Criar implementa√ß√£o completa OU desabilitar

# ETAPA 3: IMPLEMENTA√á√ÉO
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Criar api.py conforme padr√£o identificado
cat > backend/services/TARGET_SERVICE/api.py <<'EOF'
"""Service API Entry Point."""
from main import app
__all__ = ["app"]
EOF

# Atualizar docker-compose.yml
sed -i 's/uvicorn main:app/uvicorn api:app/' docker-compose.yml

# ETAPA 4: BUILD & TEST (DEBUG_GUIDE 5.7)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
docker compose build --no-cache TARGET_SERVICE
docker compose stop TARGET_SERVICE
docker compose rm -f TARGET_SERVICE
docker compose up -d TARGET_SERVICE

# ETAPA 5: VALIDA√á√ÉO
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
sleep 5  # Aguardar startup
curl http://localhost:PORT/health  # Deve retornar 200
docker logs TARGET_SERVICE --tail 30  # Verificar logs

# ETAPA 6: DOCUMENTA√á√ÉO
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# Atualizar README se necess√°rio
# Adicionar coment√°rios arquiteturais
# Registrar decis√µes importantes
```

---

### 11.7 DECIS√ïES ARQUITETURAIS: DOCUMENTATION PATTERNS

**Quando desabilitar um servi√ßo**: Documente SEMPRE.

```markdown
# backend/services/DISABLED_SERVICE/README.md

# Service Name - Status

## üöß STATUS ATUAL

Este servi√ßo est√° **desabilitado** no `docker-compose.yml`.

### Por qu√™?

[Explica√ß√£o t√©cnica clara]

### Alternativa Atual

[Como a funcionalidade √© implementada hoje]

### Se Precisar Habilitar no Futuro

1. [Passo 1]
2. [Passo 2]
3. [Valida√ß√£o]

### Refer√™ncias

- C√≥digo relacionado: `path/to/file.py`
- Docker compose: Linha X-Y comentada
- Decis√£o tomada em: YYYY-MM-DD
```

**Quando criar wrapper**: Comente o prop√≥sito.

```python
"""Service API Entry Point.

This module serves as the API entry point for the [Service Name].
It imports the FastAPI application from the main module.

The actual implementation is in main.py, which handles:
- [Feature 1]
- [Feature 2]
- [Integration with X]

Architecture Decision:
- Used wrapper pattern (not direct main.py) for consistency
- Allows future middleware injection if needed
- Follows project standard established in HCL services
"""

from main import app

__all__ = ["app"]
```

---

### 11.8 ANTI-PATTERNS: O QUE N√ÉO FAZER

```python
# ‚ùå ANTI-PATTERN 1: C√≥digo gen√©rico para problema espec√≠fico
# Problema: Service precisa de api.py
# Solu√ß√£o ruim:
app = FastAPI()  # App vazio sem prop√≥sito
@app.get("/health")
async def health():
    return {"status": "ok"}  # Mente sobre status real

# Solu√ß√£o correta:
# Analise ANTES se service √© necess√°rio
# Se n√£o: comente e documente
# Se sim: implemente funcionalidade real

# ‚ùå ANTI-PATTERN 2: Ignorar integra√ß√µes existentes
# Problema: Criar seriema_graph service HTTP
# N√£o investigou: SeriemaGraphClient j√° existe conectando direto ao Neo4j
# Resultado: C√≥digo redundante e confuso

# Solu√ß√£o correta:
grep -r "seriema" backend/services/  # Investigar USO real
# Descobrir client direto ‚Üí N√£o criar service HTTP

# ‚ùå ANTI-PATTERN 3: Build sem --no-cache ap√≥s mudan√ßas
# Problema: C√≥digo atualizado mas container usa vers√£o antiga
docker compose build service  # Usa cache!
docker compose up -d service  # Roda c√≥digo antigo

# Solu√ß√£o correta (Se√ß√£o 5.7):
docker compose build --no-cache service  # For√ßa rebuild
docker compose stop service && docker compose rm -f service
docker compose up -d service

# ‚ùå ANTI-PATTERN 4: N√£o validar ap√≥s mudan√ßas
docker compose up -d service  # Sobe
# Assume que est√° OK sem testar

# Solu√ß√£o correta:
docker compose up -d service
sleep 5  # Aguardar startup
curl http://localhost:PORT/health  # VALIDAR
docker logs service --tail 30  # VERIFICAR logs
```

---

### 11.9 M√âTRICAS DE SUCESSO DESTA METODOLOGIA

**Sess√£o de debugging 2025-10-05**:

```
PROBLEMA INICIAL:
- 22 servi√ßos UNHEALTHY
- Causa: Falta de api.py
- Tempo estimado (tentativa e erro): 6-8 horas
- Risco de c√≥digo gen√©rico: ALTO

ABORDAGEM SISTEM√ÅTICA:
Fase 1: Diagn√≥stico completo (30min)
Fase 2A: 6 Immunis services (60min)
Fase 2B: 5 HCL services (45min)
Fase 2C: 4 outros services (30min)
Fase 3: Rebuild 3 existentes (20min)

RESULTADO:
‚úÖ 16 servi√ßos corrigidos funcionalmente
‚úÖ 2 servi√ßos desabilitados honestamente
‚úÖ 0 c√≥digo gen√©rico/placeholder criado
‚úÖ 100% production-ready code
‚úÖ Documenta√ß√£o completa
‚úÖ Tempo total: ~3 horas (50% mais r√°pido)
‚úÖ Quality-first mantido
```

**Li√ß√µes**:
1. **Diagn√≥stico economiza tempo**: 30min planejando evita 3h corrigindo
2. **Agrupamento por padr√£o**: 5 servi√ßos similares = 1 template + script
3. **Honestidade > C√≥digo bonito**: Comentar placeholder > Criar mock
4. **Whole picture primeiro**: Entender integra√ß√µes evita c√≥digo redundante

---

### 11.10 CHECKLIST: ANTES DE CRIAR QUALQUER C√ìDIGO

```bash
‚òê Li a estrutura de arquivos do servi√ßo?
‚òê Verifiquei se main.py ou core j√° existem?
‚òê Busquei refer√™ncias no codebase (grep -r)?
‚òê Entendi as integra√ß√µes com outros servi√ßos?
‚òê Identifiquei o padr√£o arquitetural correto?
‚òê Considerei se o servi√ßo √© realmente necess√°rio?
‚òê Li o docker-compose.yml para ver config?
‚òê Verifiquei depend√™ncias no requirements.txt?
‚òê Tenho o "whole picture" antes de implementar?

Se TODAS respostas = SIM: PODE IMPLEMENTAR
Se QUALQUER = N√ÉO: INVESTIGUE MAIS
```

---

### 11.11 RECURSOS E TEMPLATES

**Template: Optional Imports Pattern**

```python
"""Service with Optional Dependencies."""
import logging
from typing import Optional
from fastapi import FastAPI, HTTPException

logger = logging.getLogger(__name__)

# Optional import with graceful degradation
try:
    from heavy_core import HeavyCore
    CORE_AVAILABLE = True
except ImportError:
    logger.warning("HeavyCore not available - running in limited mode")
    CORE_AVAILABLE = False
    HeavyCore = None

app = FastAPI(title="Service Name")

# Initialize only if available
core: Optional[HeavyCore] = None
if CORE_AVAILABLE and HeavyCore:
    try:
        core = HeavyCore()
        logger.info("Core initialized successfully")
    except Exception as e:
        logger.warning(f"Core initialization failed: {e}")

@app.get("/health")
async def health():
    return {
        "status": "healthy",
        "core_available": core is not None,
        "mode": "full" if core else "limited"
    }

@app.post("/process")
async def process(data: dict):
    if not core:
        raise HTTPException(
            status_code=503,
            detail="Core not available"
        )
    return await core.process(data)
```

**Template: Simple Wrapper**

```python
"""Service API Entry Point.

Wrapper pattern for services with complete main.py implementation.
"""

from main import app

__all__ = ["app"]
```

**Script: Automated API Creation**

```python
#!/usr/bin/env python3
"""Generate api.py for multiple services following same pattern."""

SERVICES = ["service1", "service2", "service3"]
TEMPLATE = '''"""[SERVICE_NAME] - API Entry Point."""

from main import app

__all__ = ["app"]
'''

for service in SERVICES:
    content = TEMPLATE.replace("[SERVICE_NAME]", service.title())
    with open(f"backend/services/{service}/api.py", "w") as f:
        f.write(content)
    print(f"‚úÖ Created api.py for {service}")
```

---

## üìù NOTAS FINAIS

Este guia cobre os cen√°rios mais comuns de debugging. Para problemas espec√≠ficos:

1. **Check os logs primeiro**: 90% dos problemas est√£o nos logs
2. **Isole o problema**: Frontend? Backend? Networking?
3. **Use health checks**: Valide que depend√™ncias est√£o UP
4. **Test incrementalmente**: Um componente por vez
5. **Document issues**: Mantenha um log de problemas recorrentes

**Manuten√ß√£o deste documento**:
- Atualize com novos servi√ßos
- Adicione troubleshooting conforme surgem
- Versione no git

**Contribui√ß√µes**:
- Issues resolvidos devem ser adicionados aqui
- Solu√ß√µes criativas devem ser compartilhadas
- Mantenha exemplos pr√°ticos e testados

---

**√öltima atualiza√ß√£o**: 2025-10-04
**Vers√£o**: 1.1.0
**Mantido por**: JuanCS-Dev

**Changelog v1.1.0 (2025-10-04)**:
- ‚úÖ Adicionadas se√ß√µes 5.7-5.12: Debugging avan√ßado de containers
- ‚úÖ Volume mounts vs Image code (armadilha cr√≠tica)
- ‚úÖ Build cache mascarando corre√ß√µes
- ‚úÖ Imports opcionais para depend√™ncias pesadas
- ‚úÖ Containers duplicados (naming conflicts)
- ‚úÖ Workflow completo de debugging de containers
- ‚úÖ Caso real documentado: RTE Service (docker cp solution)

**Links √öteis**:
- Reposit√≥rio: `/home/juan/vertice-dev`
- Documenta√ß√£o: `/home/juan/vertice-dev/docs`
- Issues: Track problemas conhecidos

---

*"Debug is twice as hard as writing the code in the first place. Therefore, if you write the code as cleverly as possible, you are, by definition, not smart enough to debug it." - Brian Kernighan*
