# Estado do Deploy GKE - Organismo VÃ©rtice

**Ãšltima atualizaÃ§Ã£o**: 2025-10-25 11:50 BRT
**Commit**: `aa0125cd` - feat(deploy): Add GKE deployment infrastructure

## ğŸ¯ Objetivo

Deployar o Organismo VÃ©rtice completo (15 serviÃ§os) no GKE cluster `vertice-us-cluster` (regiÃ£o us-east1).

## ğŸ“Š Status Atual

### âœ… CAMADA 1 - FundaÃ§Ã£o (PARCIALMENTE OK)

**Funcionando:**
- âœ… **PostgreSQL**: 1/1 Running (StatefulSet)
  - Superuser: `juan-dev` (criado)
  - Port: 5432

- âœ… **Redis**: 1/1 Running
  - Port: 6379

- âœ… **Auth Service**: 2/2 Running
  - Port: 8006 (corrigido de 8001)
  - Database fix: `/home/maximus/Documentos/V-rtice/backend/services/auth_service/database.py:29-38`
  - ConexÃ£o com PostgreSQL funcionando

- âœ… **API Gateway**: 2/2 Running
  - Port: 8001

**Pendente:**
- âš ï¸ **Kafka**: 1/2 CrashLoopBackOff
  - Zookeeper: OK (1/1)
  - Kafka container: CRASHANDO
  - Tentativa de fix: Changed KAFKA_ZOOKEEPER_CONNECT to "localhost:2181" + startup delay
  - **AÃ§Ã£o necessÃ¡ria**: Investigar logs do Kafka, voltar nisso BREVE (pedido do usuÃ¡rio)

### âŒ CAMADA 2 - ConsciÃªncia (MAXIMUS) - CRASHANDO

**Todos os 5 serviÃ§os crashando com mesmo erro:**

```
ModuleNotFoundError: No module named '_demonstration'
```

**ServiÃ§os afetados:**
1. maximus-core-service (port 8150)
2. maximus-eureka (port 8151)
3. maximus-oraculo (port 8152)
4. maximus-orchestrator-service (port 8153)
5. maximus-predict (port 8154)

**Causa raiz:**
- Arquivo: `/home/maximus/Documentos/V-rtice/backend/services/maximus_core_service/main.py:17`
- Import: `from _demonstration.maximus_integrated import MaximusIntegrated`
- **DiretÃ³rio `_demonstration` nÃ£o existe no repositÃ³rio**
- Funciona no PC do usuÃ¡rio mas nÃ£o estÃ¡ commitado
- Dockerfile referencia: `PYTHONPATH=/app:/app/_demonstration` (linha 70)

**AÃ§Ãµes necessÃ¡rias:**
1. Localizar diretÃ³rio `_demonstration` no PC do usuÃ¡rio
2. Copiar para o repositÃ³rio OU refatorar imports
3. Rebuild imagens MAXIMUS
4. Push para Artifact Registry
5. Redeploy pods

### ğŸ›‘ CAMADA 3 - Imunologia (DESLIGADA PROPOSITALMENTE)

**Status**: Todos escalados para 0 rÃ©plicas

**Motivo**: PrevenÃ§Ã£o de falsos positivos durante inicializaÃ§Ã£o
O sistema imune pode detectar a atividade de startup como ameaÃ§as sem o MAXIMUS ativo para supervisionar.

**ServiÃ§os (todos 0/1):**
1. immunis-api-service (port 8070)
2. active-immune-core (port 8071)
3. adaptive-immune-system (port 8072)
4. ai-immune-system (port 8073)
5. reflex-triage-engine (port 8074)

**SequÃªncia correta de inicializaÃ§Ã£o:**
1. âœ… FundaÃ§Ã£o (Postgres, Redis, Auth, Gateway) - DONE
2. â³ ConsciÃªncia (MAXIMUS) - aguardando fix `_demonstration`
3. â³ Imunologia - ativar SOMENTE apÃ³s MAXIMUS estar Ready

**Comando para ativar quando MAXIMUS estiver OK:**
```bash
kubectl scale deployment --all -n vertice --replicas=1 --selector=tier=imunologia
```

## ğŸ—ï¸ Infraestrutura GCP

### Cluster GKE
- **Nome**: `vertice-us-cluster`
- **RegiÃ£o**: `us-east1`
- **Tipo**: Regional (multi-zone HA)
- **Nodes**: 2 (auto-scaled de 1â†’2 durante deploy)
- **Machine**: `e2-standard-4` (4 vCPU, 16GB RAM)
- **Status**: âœ… RUNNING

### Artifact Registry
- **Registry**: `us-east1-docker.pkg.dev/projeto-vertice/vertice-images`
- **Imagens disponÃ­veis** (13 total):
  - `python311-uv:latest` (base image)
  - `api_gateway:latest`
  - `auth_service:latest`
  - 5x MAXIMUS: `maximus_core_service`, `maximus_eureka`, `maximus_oraculo`, `maximus_orchestrator_service`, `maximus_predict`
  - 5x Immunology: `immunis_api_service`, `active_immune_core`, `adaptive_immune_system`, `ai_immune_system`, `reflex_triage_engine`

### Namespaces & ConfigMaps
- **Namespace**: `vertice`
- **ConfigMap**: `vertice-global-config` (LOG_LEVEL=INFO, ENVIRONMENT=production)
- **Secret**: `vertice-core-secrets` (POSTGRES_*, REDIS_*, GEMINI_API_KEY, etc.)

## ğŸ”§ CorreÃ§Ãµes Aplicadas

### 1. Auth Service Database Connection
**Arquivo**: `backend/services/auth_service/database.py:29-38`

**Problema**:
- Hardcoded `DATABASE_URL`
- Kubernetes nÃ£o expande `$(VAR)` em env values
- Conflito com `POSTGRES_HOST`/`POSTGRES_PORT` auto-injetados pelo Service

**SoluÃ§Ã£o**:
```python
DB_USER = os.getenv("POSTGRES_USER", "postgres")
DB_PASSWORD = os.getenv("POSTGRES_PASSWORD", "postgres")
DB_NAME = os.getenv("POSTGRES_DB", "vertice_auth")
DB_HOST = os.getenv("DB_HOST", "postgres")  # Renamed to avoid conflict
DB_PORT = os.getenv("DB_PORT", "5432")

DATABASE_URL = f"postgresql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"
```

### 2. Auth Service Port Configuration
**Arquivos**:
- `k8s/camada-1-fundacao/auth-service-deployment.yaml`

**MudanÃ§a**: 8001 â†’ 8006 (match Dockerfile EXPOSE)
- containerPort: 8006
- SERVICE_PORT: "8006"
- livenessProbe port: 8006
- readinessProbe port: 8006
- Service port: 8006

### 3. Image Naming (Docker vs K8s)
**Problema**: Docker permite underscores, K8s resource names nÃ£o

**SoluÃ§Ã£o**:
- **Image paths**: `vertice-images/maximus_core_service:latest` (underscores OK)
- **K8s resources**: `metadata.name: maximus-core-service` (hyphens)
- Applied via sed replacements em todos YAMLs Layer 2 & 3

### 4. Kafka Multi-Container Coordination
**Arquivo**: `k8s/camada-1-fundacao/kafka-statefulset.yaml`

**Tentativa de fix** (ainda nÃ£o funcionou):
```yaml
env:
  - name: KAFKA_ZOOKEEPER_CONNECT
    value: "localhost:2181"  # Changed from "zookeeper:2181"

command: ["/bin/bash", "-c"]
args:
  - |
    echo "Waiting for Zookeeper to be ready..."
    while ! nc -z localhost 2181; do sleep 1; done
    echo "Zookeeper is ready, starting Kafka..."
    exec /etc/confluent/docker/run
```

**Status**: Kafka container ainda crashando, precisa investigaÃ§Ã£o adicional

## ğŸ“ Arquivos Criados/Modificados

### Kubernetes Manifests (`k8s/`)
```
k8s/
â”œâ”€â”€ namespaces/
â”‚   â””â”€â”€ vertice-namespace.yaml
â”œâ”€â”€ configmaps/
â”‚   â””â”€â”€ global-config.yaml
â”œâ”€â”€ secrets/
â”‚   â””â”€â”€ vertice-core-secrets.yaml
â”œâ”€â”€ camada-1-fundacao/
â”‚   â”œâ”€â”€ postgres-statefulset.yaml
â”‚   â”œâ”€â”€ redis-deployment.yaml
â”‚   â”œâ”€â”€ kafka-statefulset.yaml
â”‚   â”œâ”€â”€ auth-service-deployment.yaml
â”‚   â””â”€â”€ api-gateway-deployment.yaml
â”œâ”€â”€ camada-2-consciencia/
â”‚   â”œâ”€â”€ maximus_core_service-deployment.yaml
â”‚   â”œâ”€â”€ maximus_eureka-deployment.yaml
â”‚   â”œâ”€â”€ maximus_oraculo-deployment.yaml
â”‚   â”œâ”€â”€ maximus_orchestrator_service-deployment.yaml
â”‚   â””â”€â”€ maximus_predict-deployment.yaml
â””â”€â”€ camada-3-imunologia/
    â”œâ”€â”€ immunis_api_service-deployment.yaml
    â”œâ”€â”€ active_immune_core-deployment.yaml
    â”œâ”€â”€ adaptive_immune_system-deployment.yaml
    â”œâ”€â”€ ai_immune_system-deployment.yaml
    â””â”€â”€ reflex_triage_engine-deployment.yaml
```

### Scripts (`scripts/`)
```
scripts/
â”œâ”€â”€ gcp/
â”‚   â”œâ”€â”€ provision_gke_infra.sh       # Cria cluster + registry
â”‚   â””â”€â”€ push_selected_services.sh    # Build + push images
â””â”€â”€ k8s/
    â””â”€â”€ deploy_organism.sh            # Deploy completo orchestrado
```

### CÃ³digo Backend
```
backend/services/auth_service/database.py  # Fixed PostgreSQL connection
```

## ğŸš€ Comandos Ãšteis

### Conectar ao cluster
```bash
gcloud container clusters get-credentials vertice-us-cluster --region=us-east1
```

### Ver pods
```bash
kubectl get pods -n vertice
kubectl get pods -n vertice -o wide
kubectl get pods -n vertice --sort-by=.metadata.creationTimestamp
```

### Logs
```bash
# Specific pod
kubectl logs -n vertice <pod-name>

# All pods of a service
kubectl logs -n vertice -l app=maximus-core-service --tail=50

# Follow logs
kubectl logs -n vertice <pod-name> -f
```

### Escalar serviÃ§os
```bash
# Scale down
kubectl scale deployment --all -n vertice --replicas=0 --selector=tier=imunologia

# Scale up
kubectl scale deployment --all -n vertice --replicas=1 --selector=tier=consciencia
```

### Redeploy
```bash
# Apply changes
kubectl apply -f k8s/camada-2-consciencia/

# Force restart
kubectl rollout restart deployment/maximus-core-service -n vertice

# Delete pods (recreate with new config)
kubectl delete pods -n vertice -l tier=consciencia
```

### Docker/Registry
```bash
# Configure Docker auth
gcloud auth configure-docker us-east1-docker.pkg.dev

# List images
gcloud artifacts docker images list us-east1-docker.pkg.dev/projeto-vertice/vertice-images

# Build and push
docker build -t us-east1-docker.pkg.dev/projeto-vertice/vertice-images/maximus_core_service:latest .
docker push us-east1-docker.pkg.dev/projeto-vertice/vertice-images/maximus_core_service:latest
```

## â­ï¸ PrÃ³ximas AÃ§Ãµes (Prioridade)

### 1. ğŸ”´ CRÃTICO: Fix MAXIMUS `_demonstration` Module

**LocalizaÃ§Ã£o no PC do usuÃ¡rio**: â“ (precisa encontrar)

**OpÃ§Ãµes**:
a) Copiar `_demonstration/` para `backend/services/maximus_core_service/`
b) Refatorar import em `main.py` para usar mÃ³dulo existente
c) Verificar se `MaximusIntegrated` existe em outro lugar

**ApÃ³s fix**:
```bash
cd backend/services/maximus_core_service
docker build -t us-east1-docker.pkg.dev/projeto-vertice/vertice-images/maximus_core_service:latest .
docker push us-east1-docker.pkg.dev/projeto-vertice/vertice-images/maximus_core_service:latest

# Repeat for all 5 MAXIMUS services

kubectl rollout restart deployment -n vertice -l tier=consciencia
```

### 2. ğŸŸ¡ IMPORTANTE: Fix Kafka

**Debug**:
```bash
kubectl logs -n vertice kafka-0 -c kafka --tail=100
kubectl describe pod kafka-0 -n vertice
```

**Investigar**:
- Por que Kafka estÃ¡ crashando mesmo com startup delay?
- Verificar Zookeeper logs
- Testar conectividade localhost:2181

### 3. ğŸŸ¢ Deploy Immune System (SOMENTE APÃ“S MAXIMUS OK)

**Verificar MAXIMUS Ready**:
```bash
kubectl get pods -n vertice -l tier=consciencia
# Todos devem estar 1/1 Running
```

**Ativar Imunologia**:
```bash
kubectl scale deployment --all -n vertice --replicas=1 --selector=tier=imunologia
kubectl get pods -n vertice -l tier=imunologia -w
```

### 4. ğŸ”µ ValidaÃ§Ã£o Final

- [ ] Todos os 15 serviÃ§os Running (17 pods total: 7 foundation + 5 MAXIMUS + 5 immune)
- [ ] Health checks passando
- [ ] Verificar logs para erros
- [ ] Testar API Gateway external endpoint
- [ ] Validar comunicaÃ§Ã£o inter-serviÃ§os

## ğŸ› Issues Conhecidos

1. **MAXIMUS crashando**: `ModuleNotFoundError: No module named '_demonstration'`
2. **Kafka crashando**: Zookeeper OK mas Kafka container falha
3. **Immune system desligado**: Preventivo, aguardando MAXIMUS

## ğŸ“ Notas do UsuÃ¡rio

- "tem uma sequencia de inicializaÃ§Ã£o do organismo" - MAXIMUS precisa estar ativo antes do sistema imune
- "no meu pc ta rodando" KKKKKKKKKK - `_demonstration` existe localmente mas nÃ£o no repo
- "arruma esse kafka, n Ã© critico agora, mas acumula e fica uma merda depois pra debugar"
- "ok, mas voltamos nele em BREVE" - sobre Kafka

---

**Para continuar**:
1. Localizar `_demonstration` no PC
2. Commitar ao repo
3. Rebuild/push MAXIMUS images
4. Deploy e validar

**Cluster permanece ativo**, pode retomar o deploy a qualquer momento.
