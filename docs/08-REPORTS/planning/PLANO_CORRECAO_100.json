{
  "metadata": {
    "versao": "1.0",
    "timestamp": "2025-10-18T23:07:45Z",
    "autor": "Executor Tático Backend",
    "objetivo": "Ressurreição 100% Absoluta do Backend Vértice-MAXIMUS",
    "tempo_total_estimado": "6-8 horas",
    "fases": 5,
    "items_total": 52
  },
  
  "fase_1_bloqueadores_criticos": {
    "descricao": "Resolver bloqueadores que impedem funcionamento básico",
    "tempo_estimado": "3.5 horas",
    "items": [
      {
        "id": "FIX-001",
        "categoria": "A",
        "prioridade": 1,
        "modulo": "DOCKER_SERVICES_BUILD",
        "problema": "Nenhum container backend construído",
        "causa_raiz": "docker system prune removeu todas as imagens",
        "solucao": {
          "tipo": "docker_build",
          "arquivos_afetados": [],
          "steps": [
            {
              "step": 1,
              "acao": "Listar todos os serviços que precisam ser construídos",
              "comando": "docker compose config --services | grep -v -E '(postgres|redis|grafana|prometheus|qdrant|zookeeper|kafka)' | tee /tmp/services_to_build.txt"
            },
            {
              "step": 2,
              "acao": "Build paralelo de serviços backend (batch 1: core services)",
              "comando": "docker compose build api-gateway auth-service osint-service --parallel",
              "timeout": "15min"
            },
            {
              "step": 3,
              "acao": "Build batch 2: HCL services",
              "comando": "docker compose build hcl-planner hcl-analyzer hcl-executor hcl-monitor hcl-kb-service --parallel",
              "timeout": "15min"
            },
            {
              "step": 4,
              "acao": "Build batch 3: OSINT/Intel services",
              "comando": "docker compose build google-osint-service network-recon-service threat-intel-service vuln-intel-service --parallel",
              "timeout": "15min"
            },
            {
              "step": 5,
              "acao": "Build batch 4: Immune system services",
              "comando": "docker compose build adaptive-immunity-service immunis-api-service immunis-bcell-service immunis-cytotoxic-t-service immunis-nk-service immunis-treg-service --parallel",
              "timeout": "15min"
            },
            {
              "step": 6,
              "acao": "Build batch 5: Remaining services",
              "comando": "while read service; do docker compose build $service || echo \"FAILED: $service\" >> /tmp/build_failures.txt; done < /tmp/services_to_build.txt",
              "timeout": "30min"
            }
          ],
          "validacao": {
            "tipo": "image_count",
            "comando": "docker images | grep vertice-dev | wc -l",
            "criterio_sucesso": "count >= 70"
          },
          "rollback": {
            "comando": "echo 'No rollback needed - builds are idempotent'"
          }
        },
        "tempo_estimado": "90min",
        "dependencias": []
      },
      {
        "id": "FIX-002",
        "categoria": "A",
        "prioridade": 2,
        "modulo": "DOCKER_COMPOSE_ORPHAN_SERVICES",
        "problema": "24 serviços no filesystem não estão no docker-compose.yml",
        "causa_raiz": "Desenvolvimento desacoplado da orquestração",
        "solucao": {
          "tipo": "docker_compose_update",
          "arquivos_afetados": ["docker-compose.yml"],
          "steps": [
            {
              "step": 1,
              "acao": "Backup do docker-compose.yml atual",
              "comando": "cp docker-compose.yml docker-compose.yml.backup.pre_orphan_fix"
            },
            {
              "step": 2,
              "acao": "Gerar definições para serviços órfãos críticos",
              "comando": "cat > /tmp/orphan_services_template.yml << 'ORPHANEOF'\nservices:\n  active-immune-core:\n    build: ./backend/services/active_immune_core\n    networks:\n      - vertice-network\n    depends_on:\n      - postgres\n      - redis\n  \n  adaptive-immune-system:\n    build: ./backend/services/adaptive_immune_system\n    networks:\n      - vertice-network\n    depends_on:\n      - postgres\n      - redis\n  \n  ai-immune-system:\n    build: ./backend/services/ai_immune_system\n    networks:\n      - vertice-network\n    depends_on:\n      - postgres\n      - redis\n  \n  reactive-fabric-analysis:\n    build: ./backend/services/reactive_fabric_analysis\n    networks:\n      - vertice-network\n    depends_on:\n      - postgres\n      - redis\n  \n  reactive-fabric-core:\n    build: ./backend/services/reactive_fabric_core\n    networks:\n      - vertice-network\n    depends_on:\n      - postgres\n      - redis\n  \n  reflex-triage-engine:\n    build: ./backend/services/reflex_triage_engine\n    networks:\n      - vertice-network\n    depends_on:\n      - postgres\n      - redis\n  \n  homeostatic-regulation:\n    build: ./backend/services/homeostatic_regulation\n    networks:\n      - vertice-network\n    depends_on:\n      - postgres\n      - redis\n  \n  narrative-manipulation-filter:\n    build: ./backend/services/narrative_manipulation_filter\n    networks:\n      - vertice-network\n    depends_on:\n      - postgres\n      - redis\nORPHANEOF\n"
            },
            {
              "step": 3,
              "acao": "MANUAL: Adicionar serviços órfãos ao docker-compose.yml",
              "comando": "echo 'AÇÃO MANUAL NECESSÁRIA: Arquiteto-Chefe deve revisar e adicionar serviços órfãos'",
              "nota": "Requer decisão humana sobre quais serviços órfãos devem ser orquestrados vs deprecated"
            }
          ],
          "validacao": {
            "tipo": "manual",
            "comando": "docker compose config --services | wc -l",
            "criterio_sucesso": "Verificar se serviços críticos foram adicionados"
          },
          "rollback": {
            "comando": "cp docker-compose.yml.backup.pre_orphan_fix docker-compose.yml"
          }
        },
        "tempo_estimado": "45min",
        "dependencias": [],
        "status": "PARCIAL - requer decisão arquitetural"
      },
      {
        "id": "FIX-003",
        "categoria": "A",
        "prioridade": 3,
        "modulo": "INCOMPLETE_SERVICES",
        "problema": "8 serviços sem Dockerfile ou requirements.txt",
        "causa_raiz": "Desenvolvimento incompleto",
        "solucao": {
          "tipo": "complete_artifacts",
          "arquivos_afetados": [
            "backend/services/adaptive_immunity_db/Dockerfile",
            "backend/services/adaptive_immunity_db/requirements.txt",
            "backend/services/agent_communication/Dockerfile",
            "backend/services/command_bus_service/requirements.txt",
            "backend/services/mock_vulnerable_apps/Dockerfile",
            "backend/services/narrative_filter_service/requirements.txt",
            "backend/services/purple_team/Dockerfile",
            "backend/services/purple_team/requirements.txt",
            "backend/services/verdict_engine_service/requirements.txt"
          ],
          "steps": [
            {
              "step": 1,
              "acao": "Gerar Dockerfile genérico para serviços faltantes",
              "comando": "cat > /tmp/generic_service_dockerfile << 'DOCKEREOF'\nFROM python:3.11-slim\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY . .\n\nCMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\nDOCKEREOF\n"
            },
            {
              "step": 2,
              "acao": "Criar Dockerfiles faltantes",
              "comando": "for service in adaptive_immunity_db agent_communication mock_vulnerable_apps purple_team; do [ ! -f backend/services/$service/Dockerfile ] && cp /tmp/generic_service_dockerfile backend/services/$service/Dockerfile; done"
            },
            {
              "step": 3,
              "acao": "Gerar requirements.txt mínimo para serviços faltantes",
              "comando": "cat > /tmp/generic_requirements.txt << 'REQEOF'\nfastapi==0.104.1\nuvicorn[standard]==0.24.0\npydantic==2.5.0\npython-dotenv==1.0.0\nREQEOF\n"
            },
            {
              "step": 4,
              "acao": "Criar requirements.txt faltantes",
              "comando": "for service in adaptive_immunity_db command_bus_service narrative_filter_service purple_team verdict_engine_service; do [ ! -f backend/services/$service/requirements.txt ] && cp /tmp/generic_requirements.txt backend/services/$service/requirements.txt; done"
            }
          ],
          "validacao": {
            "tipo": "file_check",
            "comando": "find backend/services -type d -maxdepth 1 ! -name '__pycache__' | while read d; do [ -f \"$d/Dockerfile\" ] && [ -f \"$d/requirements.txt\" ] || echo \"INCOMPLETE: $d\"; done",
            "criterio_sucesso": "Apenas __pycache__ ou serviços intencionalmente incompletos reportados"
          },
          "rollback": {
            "comando": "git checkout backend/services/*/Dockerfile backend/services/*/requirements.txt"
          }
        },
        "tempo_estimado": "30min",
        "dependencias": []
      },
      {
        "id": "FIX-004",
        "categoria": "A",
        "prioridade": 4,
        "modulo": "DATABASE_MIGRATIONS",
        "problema": "PostgreSQL sem schemas/tabelas",
        "causa_raiz": "Migrations nunca executadas",
        "solucao": {
          "tipo": "database_migration",
          "arquivos_afetados": [],
          "steps": [
            {
              "step": 1,
              "acao": "Verificar se há scripts de migration",
              "comando": "find backend -name 'migrations' -o -name 'alembic' -o -name '*migration*.py' | head -20"
            },
            {
              "step": 2,
              "acao": "Executar migrations de auth_service (se existir)",
              "comando": "cd backend/services/auth_service && [ -d migrations ] && alembic upgrade head || echo 'No alembic found'"
            },
            {
              "step": 3,
              "acao": "Criar tabelas básicas manualmente se necessário",
              "comando": "docker compose exec -T postgres psql -U vertice -d vertice_db << 'SQLEOF'\nCREATE TABLE IF NOT EXISTS users (\n    id SERIAL PRIMARY KEY,\n    username VARCHAR(255) UNIQUE NOT NULL,\n    email VARCHAR(255) UNIQUE NOT NULL,\n    hashed_password VARCHAR(255) NOT NULL,\n    is_active BOOLEAN DEFAULT TRUE,\n    created_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE IF NOT EXISTS osint_scans (\n    id SERIAL PRIMARY KEY,\n    target VARCHAR(255) NOT NULL,\n    scan_type VARCHAR(100),\n    status VARCHAR(50),\n    results JSONB,\n    created_at TIMESTAMP DEFAULT NOW()\n);\n\nCREATE TABLE IF NOT EXISTS threat_intelligence (\n    id SERIAL PRIMARY KEY,\n    indicator VARCHAR(500) NOT NULL,\n    indicator_type VARCHAR(100),\n    severity VARCHAR(50),\n    metadata JSONB,\n    created_at TIMESTAMP DEFAULT NOW()\n);\nSQLEOF\n"
            },
            {
              "step": 4,
              "acao": "Validar tabelas criadas",
              "comando": "docker compose exec -T postgres psql -U vertice -d vertice_db -c '\\dt'"
            }
          ],
          "validacao": {
            "tipo": "table_count",
            "comando": "docker compose exec -T postgres psql -U vertice -d vertice_db -t -c \"SELECT COUNT(*) FROM information_schema.tables WHERE table_schema = 'public';\"",
            "criterio_sucesso": "count >= 3"
          },
          "rollback": {
            "comando": "docker compose exec -T postgres psql -U vertice -d vertice_db -c 'DROP SCHEMA public CASCADE; CREATE SCHEMA public;'"
          }
        },
        "tempo_estimado": "30min",
        "dependencias": ["FIX-001"]
      },
      {
        "id": "FIX-005",
        "categoria": "A",
        "prioridade": 5,
        "modulo": "CORE_SERVICES_STARTUP",
        "problema": "Serviços core não estão rodando",
        "causa_raiz": "Consequência de FIX-001",
        "solucao": {
          "tipo": "docker_start",
          "arquivos_afetados": [],
          "steps": [
            {
              "step": 1,
              "acao": "Subir infraestrutura base",
              "comando": "docker compose up -d postgres redis qdrant"
            },
            {
              "step": 2,
              "acao": "Aguardar healthchecks da infra",
              "comando": "sleep 15 && docker compose ps postgres redis qdrant"
            },
            {
              "step": 3,
              "acao": "Subir serviços core",
              "comando": "docker compose up -d api-gateway auth-service osint-service"
            },
            {
              "step": 4,
              "acao": "Aguardar healthchecks dos serviços",
              "comando": "sleep 20 && docker compose ps api-gateway auth-service osint-service"
            },
            {
              "step": 5,
              "acao": "Verificar logs de erros",
              "comando": "docker compose logs --tail=50 api-gateway auth-service osint-service | grep -i error || echo 'No errors found'"
            }
          ],
          "validacao": {
            "tipo": "healthcheck",
            "comando": "docker compose ps | grep -E '(api-gateway|auth-service|osint-service)' | grep -c 'Up'",
            "criterio_sucesso": "count == 3"
          },
          "rollback": {
            "comando": "docker compose down"
          }
        },
        "tempo_estimado": "15min",
        "dependencias": ["FIX-001", "FIX-004"]
      }
    ]
  },
  
  "fase_2_falhas_funcionais": {
    "descricao": "Restaurar funcionalidade básica de endpoints e workflows",
    "tempo_estimado": "1.5 horas",
    "items": [
      {
        "id": "FIX-006",
        "categoria": "B",
        "prioridade": 6,
        "modulo": "ENDPOINT_VALIDATION",
        "problema": "Endpoints não validados",
        "causa_raiz": "Containers não estavam rodando",
        "solucao": {
          "tipo": "endpoint_test",
          "steps": [
            {
              "step": 1,
              "acao": "Testar healthcheck do API Gateway",
              "comando": "curl -f http://localhost:8000/health || echo 'FAIL: api-gateway health'"
            },
            {
              "step": 2,
              "acao": "Testar healthcheck do Auth Service",
              "comando": "curl -f http://localhost:8001/health || echo 'FAIL: auth-service health'"
            },
            {
              "step": 3,
              "acao": "Testar endpoint de registro",
              "comando": "curl -X POST http://localhost:8001/register -H 'Content-Type: application/json' -d '{\"username\":\"test\",\"email\":\"test@test.com\",\"password\":\"test123\"}' || echo 'FAIL: register'"
            },
            {
              "step": 4,
              "acao": "Extrair todas as rotas do API Gateway",
              "comando": "curl -s http://localhost:8000/openapi.json | jq '.paths | keys' > /tmp/api_routes.json"
            }
          ],
          "validacao": {
            "tipo": "http_status",
            "comando": "curl -s -o /dev/null -w '%{http_code}' http://localhost:8000/health",
            "criterio_sucesso": "status_code == 200"
          },
          "rollback": null
        },
        "tempo_estimado": "30min",
        "dependencias": ["FIX-005"]
      },
      {
        "id": "FIX-007",
        "categoria": "B",
        "prioridade": 7,
        "modulo": "WORKFLOW_E2E_OSINT",
        "problema": "Workflow OSINT Deep Search não testado",
        "causa_raiz": "Sistema estava down",
        "solucao": {
          "tipo": "e2e_test",
          "steps": [
            {
              "step": 1,
              "acao": "Testar workflow OSINT completo",
              "comando": "curl -X POST http://localhost:8000/api/v1/osint/scan -H 'Content-Type: application/json' -d '{\"target\":\"example.com\",\"depth\":1}' > /tmp/osint_test_result.json"
            },
            {
              "step": 2,
              "acao": "Validar response",
              "comando": "jq '.status, .results' /tmp/osint_test_result.json"
            }
          ],
          "validacao": {
            "tipo": "json_field",
            "comando": "jq -r '.status' /tmp/osint_test_result.json",
            "criterio_sucesso": "status in ['success', 'completed', 'running']"
          },
          "rollback": null
        },
        "tempo_estimado": "20min",
        "dependencias": ["FIX-006"]
      }
    ]
  },
  
  "fase_3_dividas_tecnicas": {
    "descricao": "Resolver dívidas técnicas e elevar qualidade",
    "tempo_estimado": "1 hora",
    "items": [
      {
        "id": "FIX-008",
        "categoria": "C",
        "prioridade": 8,
        "modulo": "TEST_COVERAGE",
        "problema": "Coverage desconhecido",
        "causa_raiz": "Pytest não executado",
        "solucao": {
          "tipo": "test_execution",
          "steps": [
            {
              "step": 1,
              "acao": "Executar pytest com coverage",
              "comando": "cd backend && pytest tests/ --cov=backend --cov-report=json:../coverage_backend_resurrection.json --cov-report=term-missing -v",
              "timeout": "10min"
            },
            {
              "step": 2,
              "acao": "Analisar coverage por módulo",
              "comando": "jq '.totals.percent_covered' coverage_backend_resurrection.json"
            }
          ],
          "validacao": {
            "tipo": "coverage_threshold",
            "comando": "jq '.totals.percent_covered' coverage_backend_resurrection.json",
            "criterio_sucesso": "coverage >= 70 (target: 95)"
          },
          "rollback": null
        },
        "tempo_estimado": "30min",
        "dependencias": ["FIX-005"]
      }
    ]
  },
  
  "fase_4_seguranca": {
    "descricao": "Corrigir gaps de segurança",
    "tempo_estimado": "30min",
    "items": [
      {
        "id": "FIX-009",
        "categoria": "D",
        "prioridade": 9,
        "modulo": "SECRETS_MANAGEMENT",
        "problema": "Credenciais hardcoded",
        "causa_raiz": "Setup inicial inseguro",
        "solucao": {
          "tipo": "secrets_migration",
          "steps": [
            {
              "step": 1,
              "acao": "MANUAL: Migrar credenciais para .env ou Docker secrets",
              "comando": "echo 'AÇÃO MANUAL: Arquiteto-Chefe deve configurar secrets management'",
              "nota": "Requer decisão sobre usar .env, Vault, ou Docker Secrets"
            }
          ],
          "validacao": {
            "tipo": "manual",
            "criterio_sucesso": "Credenciais não mais hardcoded em código"
          },
          "rollback": null
        },
        "tempo_estimado": "30min",
        "dependencias": [],
        "status": "MANUAL"
      }
    ]
  },
  
  "fase_5_observabilidade": {
    "descricao": "Garantir visibilidade completa do sistema",
    "tempo_estimado": "1 hora",
    "items": [
      {
        "id": "FIX-010",
        "categoria": "E",
        "prioridade": 10,
        "modulo": "HEALTHCHECKS_ALL",
        "problema": "Healthchecks de 85 serviços não validados",
        "causa_raiz": "Containers não rodando",
        "solucao": {
          "tipo": "healthcheck_validation",
          "steps": [
            {
              "step": 1,
              "acao": "Listar todos os serviços com healthcheck",
              "comando": "docker compose ps --format json | jq -r '.[] | select(.Health != null) | .Name + \": \" + .Health'"
            },
            {
              "step": 2,
              "acao": "Criar script de validação automática",
              "comando": "cat > /tmp/validate_all_healthchecks.sh << 'HEALTHEOF'\n#!/bin/bash\nfor service in $(docker compose ps --services); do\n  port=$(docker compose port $service 8000 2>/dev/null | cut -d: -f2)\n  if [ ! -z \"$port\" ]; then\n    status=$(curl -s -o /dev/null -w '%{http_code}' http://localhost:$port/health)\n    echo \"$service: $status\"\n  fi\ndone\nHEALTHEOF\nchmod +x /tmp/validate_all_healthchecks.sh"
            },
            {
              "step": 3,
              "acao": "Executar validação",
              "comando": "/tmp/validate_all_healthchecks.sh > /tmp/healthcheck_results.txt"
            }
          ],
          "validacao": {
            "tipo": "healthcheck_count",
            "comando": "grep '200' /tmp/healthcheck_results.txt | wc -l",
            "criterio_sucesso": "count >= 70% dos serviços backend"
          },
          "rollback": null
        },
        "tempo_estimado": "30min",
        "dependencias": ["FIX-005"]
      }
    ]
  },
  
  "checkpoints_validacao": [
    {
      "checkpoint": "20%",
      "apos_items": ["FIX-001"],
      "validacoes": [
        "docker images | grep vertice-dev | wc -l >= 70",
        "git status --short (verificar mudanças)"
      ]
    },
    {
      "checkpoint": "40%",
      "apos_items": ["FIX-003", "FIX-004"],
      "validacoes": [
        "docker compose exec -T postgres psql -U vertice -d vertice_db -c '\\dt' | wc -l >= 3",
        "find backend/services -name Dockerfile | wc -l >= 85"
      ]
    },
    {
      "checkpoint": "60%",
      "apos_items": ["FIX-005", "FIX-006"],
      "validacoes": [
        "docker compose ps | grep 'Up' | wc -l >= 5",
        "curl -f http://localhost:8000/health"
      ]
    },
    {
      "checkpoint": "80%",
      "apos_items": ["FIX-007", "FIX-008"],
      "validacoes": [
        "jq '.totals.percent_covered' coverage_backend_resurrection.json >= 70",
        "curl -s http://localhost:8000/openapi.json | jq '.paths | length' >= 10"
      ]
    },
    {
      "checkpoint": "100%",
      "apos_items": ["FIX-010"],
      "validacoes": [
        "grep '200' /tmp/healthcheck_results.txt | wc -l >= 50",
        "docker compose ps | grep -c 'Up (healthy)' >= 70"
      ]
    }
  ],
  
  "criterios_certificacao_100": {
    "containers_healthy": ">=85% dos serviços backend (target: 100%)",
    "healthchecks_passing": ">=85% dos healthchecks (target: 100%)",
    "endpoints_ok": ">=90% dos endpoints respondendo 200/201 (target: 100%)",
    "workflows_functional": ">=5/6 workflows E2E funcionais (target: 6/6)",
    "test_coverage": ">=70% (target: 95%)",
    "padrao_pagani_violations": "<=5 (target: 0)",
    "servicos_orfaos": "<=10 (target: 0)",
    "servicos_incompletos": "<=3 (target: 0)"
  },
  
  "protocolo_execucao": {
    "modo": "SYSTEMATIC",
    "falha_handling": "CONTINUE_ON_NON_CRITICAL",
    "logging": {
      "success_log": "SUCCESSFUL_FIXES.json",
      "failure_log": "FAILED_FIXES.json",
      "progress_log": "EXECUTION_PROGRESS.json"
    },
    "commit_strategy": "ATOMIC_PER_FIX",
    "rollback_strategy": "INDIVIDUAL_ITEM"
  },
  
  "proximos_passos_apos_plano": [
    "1. Revisar plano com Arquiteto-Chefe",
    "2. Aprovar items MANUAL (FIX-002, FIX-009)",
    "3. Executar FASE 1 (FIX-001 a FIX-005)",
    "4. Checkpoint 40% - validar estado",
    "5. Executar FASE 2 (FIX-006 a FIX-007)",
    "6. Checkpoint 60% - validar endpoints",
    "7. Executar FASE 3 (FIX-008)",
    "8. Checkpoint 80% - validar coverage",
    "9. Executar FASE 4 e 5 (FIX-009 a FIX-010)",
    "10. Checkpoint 100% - certificação final"
  ]
}
