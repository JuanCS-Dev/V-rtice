# Plano de Certifica√ß√£o de Release v0.9 - MAXIMUS Consciousness Stack
## Sess√£o 03: Release Liturgia + Benchmarks + E2E Validation

**Autor**: Juan Carlo de Souza (JuanCS-DEV @github)  
**Colaborador**: Copilot/Claude-Sonnet-4.5  
**Email**: juan.brainfarma@gmail.com  
**Data**: 2025-01-09  
**Vers√£o**: 1.0  
**Status**: üü¢ APROVADO PARA EXECU√á√ÉO

---

## SUM√ÅRIO EXECUTIVO

Este documento apresenta o plano completo para a **Certifica√ß√£o de Release v0.9**, unificando os seguintes elementos cr√≠ticos:

1. **Release Liturgia** (Thread A) - SBOM, assinatura, checklist Doutrina
2. **Benchmarks de Lat√™ncia** (Adendo 3) - Valida√ß√£o de performance < 500ms
3. **Testes E2E** (Thread B) - Valida√ß√£o integra√ß√£o CLI ‚Üí MAXIMUS ‚Üí Frontend
4. **Documenta√ß√£o Audit√°vel** - Artefatos completos para conformidade

**Objetivo Macro**: Conduzir o processo completo de release da vers√£o 0.9, garantindo qualidade, seguran√ßa, performance e ader√™ncia √† Doutrina V√©rtice.

**Dura√ß√£o Estimada**: 7-10 dias √∫teis  
**Equipe**: Arquiteto-Chefe + Copilot (Claude) + GPT (tarefas paralelas)  
**Criticidade**: ALTA - Milestone de Release

---

## 1. CONTEXTO E MOTIVA√á√ÉO

### 1.1 Por Que Agora?

A Sess√£o 01 estabeleceu os **contratos** (Interface Charter, Matriz Telemetria, Zero Trust).  
A Sess√£o 02 definiu o **protocolo compartilhado** para integra√ß√£o Cockpit.  
A Sess√£o 03 completa o ciclo com **entrega validada** - um release production-ready com todas as garantias de qualidade.

### 1.2 O Que Significa "Release v0.9"?

- **vcli-go** em estado deploy√°vel com SBOM e assinatura
- **Frontend** com tipos TypeScript completos e documenta√ß√£o
- **MAXIMUS Core** com m√©tricas de performance validadas
- **Documenta√ß√£o** completa e audit√°vel
- **Pipeline** reproduc√≠vel e automatizada

### 1.3 Alinhamento com Doutrina V√©rtice

| Artigo | Aplica√ß√£o |
|--------|-----------|
| II - Regra de Ouro | 100% production-ready, zero placeholders |
| III - Confian√ßa Zero | Valida√ß√£o rigorosa de todos artefatos |
| IV - Antifragilidade | Benchmarks + E2E simulando falhas |
| V - Legisla√ß√£o Pr√©via | Checklist Doutrina before release |
| VI - Magnitude Hist√≥rica | SBOM + assinaturas = rastreabilidade |

---

## 2. ESCOPO DETALHADO

### 2.1 Thread A - Release Liturgia

#### Objetivo
Executar o workflow completo de release conforme `release-liturgia.yml`, gerando artefatos assinados e audit√°veis.

#### Componentes Cobertos
1. **vcli-go** (CLI Go)
2. **Frontend** (React + TypeScript)
3. **MAXIMUS Core** (Python services)
4. **Monitoring Dashboards** (Grafana JSON)

#### Artefatos Gerados

##### SBOM (Software Bill of Materials)
```bash
# Gera√ß√£o via syft
$ scripts/release/generate-sbom.sh vcli-go sbom-vcli-go.json
$ scripts/release/generate-sbom.sh frontend sbom-frontend.json
$ scripts/release/generate-sbom.sh maximus-core sbom-maximus.json
```

**Formato**: CycloneDX JSON  
**Conte√∫do**: Todas as depend√™ncias diretas e transitivas  
**Storage**: GitHub Releases + repository artifacts/

##### Vulnerability Scan
```bash
# Scan via grype
$ scripts/release/vulnerability-scan.sh sbom-vcli-go.json
```

**Threshold**: Zero vulnerabilidades CRITICAL, m√°ximo 3 HIGH com justificativa  
**Relat√≥rio**: JSON + HTML para auditoria

##### Assinatura Digital
```bash
# Assinatura via cosign
$ scripts/release/sign-artifact.sh vcli-go --attest sbom-vcli-go.json
```

**Chave**: Cosign staging key (secrets)  
**Attestation**: Publicado via Rekor transparency log  
**Verifica√ß√£o**: `cosign verify --key cosign.pub vcli-go-v0.9`

##### Checklist Regra de Ouro
```markdown
## Release Checklist v0.9 - vcli-go

### Testes
- [x] Unit tests passing (95%+ coverage)
- [x] Integration tests passing
- [x] E2E tests passing (C1 scenario)

### Qualidade
- [x] Linters passed (golangci-lint)
- [x] Format checked (gofmt)
- [x] Security scan (gosec) - zero high

### Supply Chain
- [x] SBOM generated (CycloneDX)
- [x] Vulnerabilities scanned (grype)
- [x] Artifact signed (cosign)
- [x] Attestation published (Rekor)

### Doutrina V√©rtice
- [x] NO PLACEHOLDER - c√≥digo completo
- [x] NO MOCK - implementa√ß√µes reais
- [x] PRODUCTION-READY - deploy√°vel
- [x] CONSCI√äNCIA-COMPLIANT - documenta√ß√£o filos√≥fica

### Aprova√ß√£o
- [ ] Arquiteto-Chefe: ___________
- [ ] Data: ___________
```

#### Pipeline Automation

**Workflow**: `.github/workflows/release-liturgia.yml`

```yaml
name: Release Liturgia v0.9

on:
  workflow_dispatch:
    inputs:
      component:
        description: 'Component to release'
        required: true
        type: choice
        options:
          - vcli-go
          - frontend
          - maximus-core
          - all

jobs:
  generate-sbom:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Generate SBOM
        run: |
          ./scripts/release/generate-sbom.sh ${{ inputs.component }}
      - name: Upload SBOM
        uses: actions/upload-artifact@v3
        with:
          name: sbom-${{ inputs.component }}
          path: sbom-*.json

  vulnerability-scan:
    needs: generate-sbom
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Download SBOM
        uses: actions/download-artifact@v3
      - name: Scan vulnerabilities
        run: |
          ./scripts/release/vulnerability-scan.sh sbom-*.json
      - name: Upload report
        uses: actions/upload-artifact@v3
        with:
          name: vuln-report-${{ inputs.component }}
          path: vuln-report-*.html

  sign-artifact:
    needs: vulnerability-scan
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Install cosign
        uses: sigstore/cosign-installer@v3
      - name: Sign artifact
        env:
          COSIGN_PASSWORD: ${{ secrets.COSIGN_PASSWORD }}
          COSIGN_KEY: ${{ secrets.COSIGN_KEY }}
        run: |
          ./scripts/release/sign-artifact.sh ${{ inputs.component }} \
            --attest sbom-${{ inputs.component }}.json
      - name: Verify signature
        run: |
          cosign verify --key cosign.pub ${{ inputs.component }}-v0.9

  create-release:
    needs: sign-artifact
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Generate release notes
        run: |
          ./scripts/release/generate-release-notes.sh v0.9
      - name: Create GitHub Release
        uses: softprops/action-gh-release@v1
        with:
          tag_name: v0.9-${{ inputs.component }}
          name: Release v0.9 - ${{ inputs.component }}
          body_path: RELEASE_NOTES.md
          files: |
            sbom-*.json
            vuln-report-*.html
            *.sig
```

#### Deliverables Thread A

| Artefato | Localiza√ß√£o | Status |
|----------|-------------|--------|
| `release-liturgia.yml` | `.github/workflows/` | ‚è≥ A criar |
| `generate-sbom.sh` | `scripts/release/` | üîÑ Verificar |
| `vulnerability-scan.sh` | `scripts/release/` | üîÑ Verificar |
| `sign-artifact.sh` | `scripts/release/` | üîÑ Verificar |
| `RELEASE_CHECKLIST.md` | `docs/cGPT/session-03/thread-a/` | ‚úÖ Criado |
| `PIPELINES_INVENTORY.md` | `docs/cGPT/session-03/thread-a/` | ‚úÖ Criado |
| SBOM files | `artifacts/sbom/` | ‚è≥ A gerar |
| Vulnerability reports | `artifacts/vuln-reports/` | ‚è≥ A gerar |
| Signed artifacts | GitHub Releases | ‚è≥ A publicar |

---

### 2.2 Adendo 3 - Benchmarks de Lat√™ncia

#### Objetivo
Executar benchmarks completos dos endpoints MAXIMUS que alimentam o cockpit consciente, validando targets de performance (p95 < 500ms).

#### Endpoints Cr√≠ticos

| Endpoint | Protocolo | Target (p95) | Prioridade |
|----------|-----------|--------------|------------|
| `/maximus/v1/consciousness/stream` | WebSocket | < 50ms | CR√çTICA |
| `/maximus/v1/consciousness/state` | REST GET | < 200ms | ALTA |
| `/maximus/v1/consciousness/arousal/history` | REST GET | < 300ms (1h) | M√âDIA |
| `/maximus/v1/consciousness/esgt/events` | REST GET | < 200ms | ALTA |
| `/vcli/v1/commands` | REST POST | < 300ms | ALTA |

#### Metodologia

##### Ferramentas

**k6** (Load Testing)
```javascript
// tests/performance/consciousness-stream-benchmark.js
import ws from 'k6/ws';
import { check } from 'k6';
import { Trend } from 'k6/metrics';

const latencyTrend = new Trend('event_latency');

export let options = {
  stages: [
    { duration: '1m', target: 10 },   // ramp-up
    { duration: '3m', target: 50 },   // sustained
    { duration: '1m', target: 100 },  // spike
    { duration: '1m', target: 0 },    // ramp-down
  ],
  thresholds: {
    'event_latency': ['p(95)<50'],
    'ws_connecting': ['p(95)<100'],
  },
};

export default function () {
  const url = 'ws://localhost:8080/maximus/v1/consciousness/stream';
  
  const res = ws.connect(url, function (socket) {
    socket.on('message', (data) => {
      const event = JSON.parse(data);
      const latency = Date.now() - event.timestamp;
      
      latencyTrend.add(latency);
      check(latency, { 
        'latency < 50ms': (l) => l < 50 
      });
    });
    
    socket.setTimeout(() => {
      socket.close();
    }, 30000);
  });
}
```

**hey** (HTTP Benchmarking)
```bash
# Benchmark REST endpoints
$ hey -n 10000 -c 50 -m GET \
  -H "Authorization: Bearer $TOKEN" \
  http://localhost:8080/maximus/v1/consciousness/state

# Target: p95 < 200ms
```

**ghz** (gRPC Benchmarking)
```bash
# Benchmark gRPC streaming
$ ghz --insecure \
  --proto ./api/consciousness.proto \
  --call consciousness.ConsciousnessService/StreamMetrics \
  --duration 60s \
  --connections 10 \
  --rps 100 \
  localhost:9090
```

##### Cen√°rios de Teste

###### Cen√°rio 1: Baseline (Normal Load)
- **Conex√µes**: 10 simult√¢neas
- **RPS**: 50 req/s
- **Dura√ß√£o**: 5 minutos
- **Objetivo**: Estabelecer baseline de performance

###### Cen√°rio 2: Sustained High Load
- **Conex√µes**: 50 simult√¢neas
- **RPS**: 200 req/s
- **Dura√ß√£o**: 10 minutos
- **Objetivo**: Validar performance sob carga sustentada

###### Cen√°rio 3: Spike Test
- **Ramp-up**: 10 ‚Üí 100 conex√µes em 30s
- **Sustenta√ß√£o**: 100 conex√µes por 2 min
- **Ramp-down**: 100 ‚Üí 10 em 30s
- **Objetivo**: Validar resili√™ncia a spikes

###### Cen√°rio 4: Soak Test (Long Duration)
- **Conex√µes**: 20 constantes
- **RPS**: 100 req/s
- **Dura√ß√£o**: 4 horas (overnight)
- **Objetivo**: Detectar memory leaks e degrada√ß√£o

#### Execu√ß√£o

```bash
# Script master de benchmarks
$ SCENARIO=baseline ./tests/performance/run-benchmarks.sh

# Cen√°rios individuais
$ SCENARIO=baseline ./tests/performance/run-benchmarks.sh
$ SCENARIO=high-load ./tests/performance/run-benchmarks.sh
$ SCENARIO=spike ./tests/performance/run-benchmarks.sh
$ SCENARIO=soak ./tests/performance/run-benchmarks.sh

# Coletar relat√≥rios
$ ls tests/performance/reports/
  baseline-20250109-223000.json
  baseline-20250109-223000.html
  high-load-20250109-230000.json
  ...
```

#### Formato do Relat√≥rio

```markdown
# Benchmarks de Lat√™ncia - MAXIMUS v0.9
**Data**: 2025-01-09  
**Ambiente**: Staging (8 cores, 16GB RAM, Docker)  
**Status**: ‚úÖ APROVADO - Targets atingidos

## Resumo Executivo

| Endpoint | Target (p95) | Resultado (p95) | Status |
|----------|--------------|-----------------|--------|
| Streaming | < 50ms | 42ms | ‚úÖ |
| State | < 200ms | 178ms | ‚úÖ |
| Arousal History (1h) | < 300ms | 267ms | ‚úÖ |
| ESGT Events | < 200ms | 189ms | ‚úÖ |
| Commands | < 300ms | 245ms | ‚úÖ |

**Conclus√£o**: Todos os endpoints atingiram os targets de performance. Sistema aprovado para release v0.9.

## Detalhamento por Endpoint

### /maximus/v1/consciousness/stream (WebSocket)

**Configura√ß√£o**:
- Protocolo: WebSocket
- Payload m√©dio: 2.3 KB
- Frequ√™ncia: 10 eventos/s

**Resultados Cen√°rio Baseline**:
| M√©trica | p50 | p95 | p99 | Max |
|---------|-----|-----|-----|-----|
| Handshake | 45ms | 87ms | 124ms | 203ms |
| Event Latency | 18ms | 42ms | 78ms | 156ms |
| Throughput | - | - | - | 120 evt/s |

**Gr√°ficos**: [Ver dashboard Grafana]

**Observa√ß√µes**:
- Performance dentro do esperado
- Spike de lat√™ncia aos 5min detectado (GC pause)
- Connection drops: 0
- Reconnections: 0

**Recomenda√ß√µes**:
- ‚úÖ NENHUMA - Performance adequada

### [Repetir para cada endpoint...]

## Bottlenecks Identificados

**Nenhum bottleneck cr√≠tico detectado.**

Observa√ß√µes menores:
1. GC pause aos 5min - Considerar tuning (n√£o cr√≠tico)
2. Cache hit rate 75% (target 80%) - Poss√≠vel otimiza√ß√£o futura

## A√ß√µes Tomadas

1. ‚úÖ Ajuste de GC heap size: 2GB ‚Üí 4GB
2. ‚úÖ Connection pool: 10 ‚Üí 25
3. ‚úÖ Query index adicionado em `esgt_events.timestamp`

## Baseline Estabelecido

Estes resultados estabelecem o baseline para monitoramento cont√≠nuo. Qualquer regress√£o > 10% deve disparar alerta.
```

#### Deliverables Adendo 3

| Artefato | Localiza√ß√£o | Status |
|----------|-------------|--------|
| `run-benchmarks.sh` | `tests/performance/` | ‚è≥ A criar |
| Scripts k6 | `tests/performance/*.js` | ‚è≥ A criar |
| Relat√≥rio HTML | `tests/performance/reports/` | ‚è≥ A gerar |
| Dashboard Grafana | `monitoring/grafana/dashboards/performance-benchmarks.json` | ‚è≥ A criar |
| `MAXIMUS_LATENCY_BENCHMARKS.md` | `docs/performance/` | ‚è≥ A criar |
| `performance_latency_overview.json` | `docs/performance/` | ‚è≥ Atualizar |

---

### 2.3 Thread B - Testes E2E

#### Objetivo
Implementar e executar su√≠te E2E m√≠nima validando fluxo completo CLI ‚Üí MAXIMUS ‚Üí Frontend.

#### Cen√°rio Principal (C1): Happy Path - Command Execution

**Descri√ß√£o**: Usu√°rio executa comando no CLI que aciona MAXIMUS e reflete no Frontend.

**Fluxo**:
```mermaid
sequenceDiagram
    participant User
    participant CLI as vcli-go
    participant API as MAXIMUS API
    participant Frontend as React App
    
    User->>CLI: vcli maximus status
    CLI->>API: POST /vcli/v1/commands
    API-->>CLI: 200 OK {status: "healthy"}
    CLI-->>User: Display status
    API->>Frontend: WS /consciousness/stream
    Frontend->>Frontend: Update dashboard
```

**Implementa√ß√£o**:

```python
# tests/e2e/test_c1_command_execution.py
import pytest
import subprocess
import requests
from playwright.sync_api import Page, expect

@pytest.fixture
def setup_environment():
    """Setup E2E test environment"""
    # Start services via docker-compose
    subprocess.run(["docker-compose", "-f", "docker-compose.e2e.yml", "up", "-d"])
    yield
    subprocess.run(["docker-compose", "-f", "docker-compose.e2e.yml", "down"])

def test_c1_happy_path_command_execution(page: Page, setup_environment):
    """
    E2E Test C1: Happy Path - Command Execution
    
    Validates:
    - CLI command execution
    - API response correctness
    - Frontend state update
    - End-to-end latency < 500ms
    """
    
    # Step 1: Execute CLI command
    start_time = time.time()
    result = subprocess.run(
        ["vcli", "maximus", "status"],
        capture_output=True,
        text=True
    )
    cli_latency = time.time() - start_time
    
    # Assert: CLI execution successful
    assert result.returncode == 0
    assert "healthy" in result.stdout.lower()
    assert cli_latency < 0.3  # < 300ms
    
    # Step 2: Validate API response
    response = requests.get("http://localhost:8080/maximus/v1/consciousness/state")
    assert response.status_code == 200
    data = response.json()
    assert data["status"] == "healthy"
    assert "arousal_level" in data
    
    # Step 3: Validate Frontend update
    page.goto("http://localhost:3000/consciousness")
    
    # Wait for WebSocket connection
    page.wait_for_selector('[data-testid="ws-connected"]', timeout=5000)
    
    # Assert: Status displayed correctly
    status_element = page.locator('[data-testid="consciousness-status"]')
    expect(status_element).to_contain_text("healthy")
    
    # Assert: Arousal level displayed
    arousal_element = page.locator('[data-testid="arousal-level"]')
    expect(arousal_element).to_be_visible()
    
    # Step 4: Validate end-to-end latency
    end_time = time.time()
    e2e_latency = end_time - start_time
    
    assert e2e_latency < 0.5  # < 500ms total
    
    # Step 5: Capture metrics for report
    return {
        "test": "C1_happy_path",
        "status": "PASSED",
        "cli_latency": cli_latency,
        "e2e_latency": e2e_latency,
        "timestamp": time.time()
    }
```

**Script de Execu√ß√£o**:

```bash
#!/bin/bash
# tests/e2e/run-e2e.sh

set -e

echo "üß™ Starting E2E Test Suite for Release v0.9"

# Step 1: Setup environment
echo "üì¶ Setting up E2E environment..."
docker-compose -f docker-compose.e2e.yml up -d
sleep 10  # Wait for services to be ready

# Step 2: Run tests
echo "üî¨ Running E2E tests..."
pytest tests/e2e/ \
  --junit-xml=tests/e2e/reports/junit-report.xml \
  --html=tests/e2e/reports/report.html \
  --self-contained-html \
  -v

# Step 3: Collect metrics
echo "üìä Collecting metrics..."
python tests/e2e/collect_metrics.py > tests/e2e/reports/metrics.json

# Step 4: Generate report
echo "üìÑ Generating E2E report..."
python tests/e2e/generate_report.py

# Step 5: Teardown
echo "üßπ Cleaning up..."
docker-compose -f docker-compose.e2e.yml down

echo "‚úÖ E2E Test Suite completed!"
```

**docker-compose.e2e.yml**:

```yaml
version: '3.8'

services:
  maximus-api:
    build: ./backend/services/maximus_core_service
    environment:
      - ENV=e2e
      - LOG_LEVEL=INFO
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 5s
      timeout: 3s
      retries: 10

  vcli-bridge:
    build: ./vcli-go
    environment:
      - MAXIMUS_URL=http://maximus-api:8080
    depends_on:
      - maximus-api

  frontend:
    build: ./frontend
    environment:
      - REACT_APP_API_URL=http://maximus-api:8080
    ports:
      - "3000:3000"
    depends_on:
      - maximus-api

  playwright:
    image: mcr.microsoft.com/playwright:latest
    volumes:
      - ./tests/e2e:/tests
    depends_on:
      - frontend
```

#### Deliverables Thread B

| Artefato | Localiza√ß√£o | Status |
|----------|-------------|--------|
| `run-e2e.sh` | `tests/e2e/` | ‚è≥ A criar |
| `docker-compose.e2e.yml` | `./` | ‚è≥ A criar |
| `test_c1_command_execution.py` | `tests/e2e/` | ‚è≥ A criar |
| `collect_metrics.py` | `tests/e2e/` | ‚è≥ A criar |
| `generate_report.py` | `tests/e2e/` | ‚è≥ A criar |
| Relat√≥rio JUnit | `tests/e2e/reports/` | ‚è≥ A gerar |
| Relat√≥rio HTML | `tests/e2e/reports/` | ‚è≥ A gerar |
| `E2E_TEST_RESULTS.md` | `docs/cGPT/session-03/thread-b/` | ‚è≥ A criar |

---

## 3. CRONOGRAMA DE EXECU√á√ÉO

### Fase 1: Prepara√ß√£o (Dias 1-2)

#### Dia 1 - Setup Infraestrutura
- [ ] Verificar exist√™ncia de scripts release (`generate-sbom.sh`, etc)
- [ ] Criar scripts faltantes
- [ ] Instalar ferramentas (syft, grype, cosign, k6, hey, ghz)
- [ ] Configurar secrets (COSIGN_PASSWORD, COSIGN_KEY)
- [ ] Criar workflow `release-liturgia.yml`

#### Dia 2 - Prepara√ß√£o Testes
- [ ] Criar estrutura `tests/e2e/`
- [ ] Implementar `docker-compose.e2e.yml`
- [ ] Criar scripts base (`run-e2e.sh`, `run-benchmarks.sh`)
- [ ] Configurar ambiente de staging

### Fase 2: Execu√ß√£o Release (Dias 3-5)

#### Dia 3 - SBOM + Vulnerability Scan
- [ ] Gerar SBOM para vcli-go
- [ ] Gerar SBOM para frontend
- [ ] Gerar SBOM para maximus-core
- [ ] Executar vulnerability scan
- [ ] Revisar findings e justificar exce√ß√µes

#### Dia 4 - Assinatura + Attestation
- [ ] Assinar artefatos vcli-go
- [ ] Assinar artefatos frontend
- [ ] Assinar artefatos maximus-core
- [ ] Publicar attestations no Rekor
- [ ] Verificar assinaturas

#### Dia 5 - Checklist + Release
- [ ] Preencher RELEASE_CHECKLIST.md
- [ ] Executar pipeline release-liturgia.yml
- [ ] Validar artefatos gerados
- [ ] Criar GitHub Releases
- [ ] Atualizar PIPELINES_INVENTORY.md

### Fase 3: Valida√ß√£o Performance (Dias 6-7)

#### Dia 6 - Benchmarks Execution
- [ ] Executar Cen√°rio 1 (Baseline)
- [ ] Executar Cen√°rio 2 (High Load)
- [ ] Executar Cen√°rio 3 (Spike)
- [ ] Iniciar Cen√°rio 4 (Soak - overnight)

#### Dia 7 - An√°lise e Otimiza√ß√£o
- [ ] Analisar resultados Soak Test
- [ ] Compilar relat√≥rios
- [ ] Identificar bottlenecks (se houver)
- [ ] Implementar otimiza√ß√µes cr√≠ticas
- [ ] Re-executar testes afetados
- [ ] Documentar em MAXIMUS_LATENCY_BENCHMARKS.md

### Fase 4: Testes E2E (Dias 8-9)

#### Dia 8 - Implementa√ß√£o E2E
- [ ] Implementar test_c1_command_execution.py
- [ ] Implementar collect_metrics.py
- [ ] Implementar generate_report.py
- [ ] Executar primeira rodada de testes
- [ ] Corrigir issues encontrados

#### Dia 9 - Valida√ß√£o Final
- [ ] Executar su√≠te E2E completa
- [ ] Gerar relat√≥rios JUnit + HTML
- [ ] Validar lat√™ncia < 500ms
- [ ] Documentar resultados em E2E_TEST_RESULTS.md

### Fase 5: Documenta√ß√£o e Encerramento (Dia 10)

#### Dia 10 - Finaliza√ß√£o
- [ ] Atualizar README.md com instru√ß√µes de release
- [ ] Atualizar STATUS_VISUAL.md com progresso
- [ ] Criar RESUMO_EXECUTIVO_SESSAO.md
- [ ] Atualizar copilot_session.md
- [ ] Commit e push de todos artefatos
- [ ] Apresentar para aprova√ß√£o do Arquiteto-Chefe

---

## 4. ESTRUTURA DE ARQUIVOS CRIADOS

```
vertice-dev/
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ release-liturgia.yml         # ‚è≥ A criar
‚îÇ
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ release/
‚îÇ       ‚îú‚îÄ‚îÄ generate-sbom.sh             # üîÑ Verificar/Criar
‚îÇ       ‚îú‚îÄ‚îÄ vulnerability-scan.sh        # üîÑ Verificar/Criar
‚îÇ       ‚îú‚îÄ‚îÄ sign-artifact.sh             # üîÑ Verificar/Criar
‚îÇ       ‚îî‚îÄ‚îÄ generate-release-notes.sh    # ‚è≥ A criar
‚îÇ
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ e2e/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ run-e2e.sh                   # ‚è≥ A criar
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ test_c1_command_execution.py # ‚è≥ A criar
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ collect_metrics.py           # ‚è≥ A criar
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ generate_report.py           # ‚è≥ A criar
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ reports/                     # ‚è≥ A gerar
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ junit-report.xml
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ report.html
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ metrics.json
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ performance/
‚îÇ       ‚îú‚îÄ‚îÄ run-benchmarks.sh            # ‚è≥ A criar
‚îÇ       ‚îú‚îÄ‚îÄ consciousness-stream-benchmark.js # ‚è≥ A criar
‚îÇ       ‚îú‚îÄ‚îÄ rest-endpoints-benchmark.sh  # ‚è≥ A criar
‚îÇ       ‚îî‚îÄ‚îÄ reports/                     # ‚è≥ A gerar
‚îÇ           ‚îú‚îÄ‚îÄ baseline-*.json
‚îÇ           ‚îú‚îÄ‚îÄ high-load-*.json
‚îÇ           ‚îî‚îÄ‚îÄ spike-*.json
‚îÇ
‚îú‚îÄ‚îÄ artifacts/
‚îÇ   ‚îú‚îÄ‚îÄ sbom/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sbom-vcli-go.json            # ‚è≥ A gerar
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sbom-frontend.json           # ‚è≥ A gerar
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sbom-maximus.json            # ‚è≥ A gerar
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ vuln-reports/
‚îÇ       ‚îú‚îÄ‚îÄ vcli-go-vuln.html            # ‚è≥ A gerar
‚îÇ       ‚îú‚îÄ‚îÄ frontend-vuln.html           # ‚è≥ A gerar
‚îÇ       ‚îî‚îÄ‚îÄ maximus-vuln.html            # ‚è≥ A gerar
‚îÇ
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ cGPT/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ copilot_session.md           # ‚úÖ Atualizado
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SESSAO_03_PLANO_CERTIFICACAO_RELEASE.md # ‚úÖ Este arquivo
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ session-03/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ thread-a/
‚îÇ   ‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ RELEASE_CHECKLIST_v0.9.md # ‚è≥ A preencher
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ thread-b/
‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ E2E_TEST_RESULTS.md  # ‚è≥ A criar
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ performance/
‚îÇ       ‚îî‚îÄ‚îÄ MAXIMUS_LATENCY_BENCHMARKS.md # ‚è≥ A criar
‚îÇ
‚îî‚îÄ‚îÄ docker-compose.e2e.yml               # ‚è≥ A criar
```

---

## 5. DEPEND√äNCIAS E PR√â-REQUISITOS

### Ferramentas Necess√°rias

| Ferramenta | Vers√£o | Prop√≥sito | Instala√ß√£o |
|------------|--------|-----------|------------|
| syft | >= 0.90 | SBOM generation | `brew install syft` |
| grype | >= 0.70 | Vulnerability scan | `brew install grype` |
| cosign | >= 2.0 | Artifact signing | `brew install cosign` |
| k6 | >= 0.45 | Load testing | `brew install k6` |
| hey | latest | HTTP benchmarking | `brew install hey` |
| ghz | >= 0.115 | gRPC benchmarking | `brew install ghz` |
| playwright | >= 1.40 | E2E testing | `npm install -D @playwright/test` |
| pytest | >= 7.0 | Python testing | `pip install pytest` |

### Secrets Necess√°rios (GitHub)

```bash
# Cosign keys (staging)
COSIGN_PASSWORD=<staging-password>
COSIGN_KEY=<base64-encoded-private-key>

# Benchmark targets
BENCH_TARGET_API=http://staging.vertice.dev:8080
BENCH_TARGET_WS=ws://staging.vertice.dev:8080

# Tokens
GITHUB_TOKEN=<for-release-creation>
```

### Acesso e Permiss√µes

- [ ] Acesso write ao reposit√≥rio GitHub
- [ ] Permiss√£o para criar Releases
- [ ] Acesso aos secrets do reposit√≥rio
- [ ] Acesso ao ambiente de staging
- [ ] Credenciais de registry (Docker Hub / GHCR)

---

## 6. M√âTRICAS DE SUCESSO

### Release Liturgia (Thread A)

| M√©trica | Target | Como Medir |
|---------|--------|------------|
| SBOM gerado | 100% componentes | Arquivos JSON presentes |
| Vulnerabilidades cr√≠ticas | 0 | Relat√≥rio grype |
| Artefatos assinados | 100% | Verifica√ß√£o cosign |
| Checklist completo | 100% itens | Documento preenchido |
| Pipeline executado | Sucesso | GitHub Actions verde |

### Benchmarks (Adendo 3)

| M√©trica | Target | Como Medir |
|---------|--------|------------|
| Endpoints benchmarkados | 5/5 | Scripts executados |
| Streaming latency (p95) | < 50ms | Relat√≥rio k6 |
| REST latency (p95) | < 200ms | Relat√≥rio hey |
| Targets atingidos | >= 80% | Compara√ß√£o com baseline |
| Bottlenecks identificados | Documentados | Relat√≥rio final |

### Testes E2E (Thread B)

| M√©trica | Target | Como Medir |
|---------|--------|------------|
| Cen√°rio C1 implementado | 100% | C√≥digo pytest |
| Testes passando | 100% | JUnit report |
| E2E latency (p95) | < 500ms | M√©tricas coletadas |
| Cobertura de fluxo | 100% (CLI‚ÜíAPI‚ÜíFrontend) | Valida√ß√£o manual |
| Relat√≥rio gerado | Completo | HTML + JSON |

### Documenta√ß√£o

| M√©trica | Target | Como Medir |
|---------|--------|------------|
| Relat√≥rios criados | 5 documentos | Arquivos MD |
| Checklists preenchidos | 100% | Aprova√ß√£o humana |
| Status atualizado | copilot_session.md | Commit recente |
| Artefatos versionados | Git commit | Hash commit |

---

## 7. RISCOS E MITIGA√á√ïES

### Riscos Identificados

| Risco | Probabilidade | Impacto | Mitiga√ß√£o |
|-------|---------------|---------|-----------|
| Scripts release n√£o existem | ALTA | ALTO | Criar scripts gen√©ricos baseados em templates |
| Benchmarks revelam performance ruim | M√âDIA | ALTO | Buffer de 2 dias para otimiza√ß√µes (Dia de Caos) |
| E2E tests flaky | M√âDIA | M√âDIO | Implementar retries e timeouts generosos |
| Secrets indispon√≠veis | BAIXA | ALTO | Usar chaves staging tempor√°rias |
| Vulnerabilidades cr√≠ticas | M√âDIA | ALTO | Processo de exce√ß√£o documentado |
| Ambiente staging inst√°vel | M√âDIA | M√âDIO | Fallback para ambiente local Docker |

### Plano de Conting√™ncia

#### Se Scripts N√£o Existirem
1. Criar scripts b√°sicos funcionais (3-4h)
2. Executar manualmente e documentar comandos
3. Automa√ß√£o completa fica para post-release

#### Se Performance N√£o Atingir Targets
1. Ativar "Dia de Caos" (Adendo 2) - 1 dia extra
2. Profiling e otimiza√ß√µes priorit√°rias
3. Se n√£o resolver: documentar como "known limitation" e roadmap fix

#### Se E2E Falhar
1. Debugging detalhado com logs
2. Simplificar cen√°rio C1 se necess√°rio
3. Valida√ß√£o manual como fallback

---

## 8. CRIT√âRIOS DE APROVA√á√ÉO

### Gate 1: Release Artifacts (Fim da Fase 2)

**Checklist de Aprova√ß√£o**:
- [ ] SBOM gerado para todos componentes
- [ ] Zero vulnerabilidades CRITICAL (ou justificadas)
- [ ] Artefatos assinados e verific√°veis
- [ ] Checklist Regra de Ouro 100% completo
- [ ] Pipeline executado sem erros

**Aprovador**: Arquiteto-Chefe  
**Crit√©rio**: Todos itens checked

### Gate 2: Performance Validation (Fim da Fase 3)

**Checklist de Aprova√ß√£o**:
- [ ] >= 80% dos endpoints atingem targets
- [ ] Nenhum bottleneck CR√çTICO n√£o resolvido
- [ ] Relat√≥rio completo e documentado
- [ ] Baseline estabelecido para monitoramento

**Aprovador**: Arquiteto-Chefe  
**Crit√©rio**: Todos itens checked OU otimiza√ß√µes agendadas para v0.9.1

### Gate 3: E2E Validation (Fim da Fase 4)

**Checklist de Aprova√ß√£o**:
- [ ] Cen√°rio C1 implementado e passando
- [ ] E2E latency < 500ms
- [ ] Fluxo completo validado (CLI ‚Üí API ‚Üí Frontend)
- [ ] Relat√≥rios gerados e armazenados

**Aprovador**: Arquiteto-Chefe  
**Crit√©rio**: Todos itens checked

### Gate Final: Documenta√ß√£o (Fim da Fase 5)

**Checklist de Aprova√ß√£o**:
- [ ] Todos documentos criados e commitados
- [ ] Status atualizado (copilot_session.md, STATUS_VISUAL.md)
- [ ] Resumo executivo redigido
- [ ] Artefatos organizados e versionados
- [ ] Apresenta√ß√£o preparada

**Aprovador**: Arquiteto-Chefe  
**Crit√©rio**: Aprova√ß√£o formal da apresenta√ß√£o final

---

## 9. COMUNICA√á√ÉO E CERIM√îNIAS

### Daily Async Updates

**Canal**: #session-03-release  
**Formato**:
```markdown
## Update - 2025-01-10

### Hoje
- Criado workflow release-liturgia.yml
- Implementado generate-sbom.sh para vcli-go
- Iniciado vulnerability scan

### Amanh√£
- Finalizar SBOM para frontend e maximus
- Configurar cosign signing
- Executar primeiro pipeline completo

### Bloqueios
- Aguardando secrets COSIGN_KEY (ticket #123)
```

### Checkpoint Mid-Week (Dia 5)

**Participantes**: Arquiteto-Chefe + Copilot  
**Agenda**:
1. Revisar progresso Fase 2 (30min)
2. Validar artefatos gerados (30min)
3. Ajustar cronograma se necess√°rio (15min)
4. Aprovar Gate 1 (15min)

### Checkpoint Final (Dia 10)

**Participantes**: Arquiteto-Chefe + Copilot + GPT (se aplic√°vel)  
**Agenda**:
1. Apresentar resultados completos (45min)
2. Demonstra√ß√£o de release v0.9 (30min)
3. Revisar m√©tricas de sucesso (15min)
4. Aprovar Gates 2 e 3 (15min)
5. Planejar pr√≥ximos passos (15min)

---

## 10. PR√ìXIMOS PASSOS IMEDIATOS

### Para Iniciar AGORA

1. **Verificar Scripts Existentes**
   ```bash
   ls -la scripts/release/
   # Se n√£o existirem, criar estrutura base
   ```

2. **Instalar Ferramentas**
   ```bash
   brew install syft grype cosign k6 hey ghz
   pip install pytest playwright
   npx playwright install
   ```

3. **Criar Workflow Base**
   ```bash
   touch .github/workflows/release-liturgia.yml
   # Copiar template do plano
   ```

4. **Criar Estrutura E2E**
   ```bash
   mkdir -p tests/e2e/reports
   mkdir -p tests/performance/reports
   touch tests/e2e/run-e2e.sh
   chmod +x tests/e2e/run-e2e.sh
   ```

5. **Configurar Secrets** (se dispon√≠vel)
   ```bash
   # Via GitHub Settings > Secrets
   # Ou criar arquivo local para staging
   touch .env.staging
   ```

---

## 11. CONCLUS√ÉO

Este plano apresenta uma abordagem estruturada e completa para a **Certifica√ß√£o de Release v0.9**, unificando Release Liturgia, Benchmarks de Performance e Testes E2E em um √∫nico esfor√ßo coordenado de 7-10 dias.

**Destaques do Plano**:
- ‚úÖ Alinhamento total com Doutrina V√©rtice
- ‚úÖ Cronograma realista com buffers de caos
- ‚úÖ M√©tricas claras de sucesso
- ‚úÖ Gates de aprova√ß√£o bem definidos
- ‚úÖ Planos de conting√™ncia para riscos
- ‚úÖ Artefatos audit√°veis e versionados

**Pr√≥xima A√ß√£o**: Aprova√ß√£o do Arquiteto-Chefe para iniciar Fase 1 (Prepara√ß√£o).

---

**Status**: üü¢ APROVADO PARA EXECU√á√ÉO  
**Data de Cria√ß√£o**: 2025-01-09  
**Autor**: Juan Carlo de Souza (JuanCS-DEV @github)  
**Colaborador**: Copilot/Claude-Sonnet-4.5  
**Email**: juan.brainfarma@gmail.com  
**Vers√£o**: 1.0

---

## AP√äNDICE A - COMANDOS R√ÅPIDOS

### SBOM Generation
```bash
# vcli-go
scripts/release/generate-sbom.sh vcli-go artifacts/sbom/sbom-vcli-go.json

# frontend
scripts/release/generate-sbom.sh frontend artifacts/sbom/sbom-frontend.json

# maximus-core
scripts/release/generate-sbom.sh maximus-core artifacts/sbom/sbom-maximus.json
```

### Vulnerability Scan
```bash
scripts/release/vulnerability-scan.sh artifacts/sbom/sbom-vcli-go.json
```

### Artifact Signing
```bash
scripts/release/sign-artifact.sh vcli-go --attest artifacts/sbom/sbom-vcli-go.json
```

### Benchmarks
```bash
SCENARIO=baseline ./tests/performance/run-benchmarks.sh
SCENARIO=high-load ./tests/performance/run-benchmarks.sh
SCENARIO=spike ./tests/performance/run-benchmarks.sh
```

### E2E Tests
```bash
./tests/e2e/run-e2e.sh
```

### Release Pipeline
```bash
# Manual trigger via GitHub Actions UI
# Or via gh CLI:
gh workflow run release-liturgia.yml -f component=vcli-go
```

---

## AP√äNDICE B - TEMPLATES

### Template: RELEASE_CHECKLIST_v0.9.md

```markdown
# Release Checklist v0.9 - [COMPONENT]

**Data**: 2025-01-XX  
**Respons√°vel**: [Nome]  
**Status**: üîÑ Em Progresso

## Testes
- [ ] Unit tests passing (>= 95% coverage)
- [ ] Integration tests passing
- [ ] E2E tests passing (C1 scenario)

## Qualidade
- [ ] Linters passed
- [ ] Format checked
- [ ] Security scan - zero critical
- [ ] Code review aprovado

## Supply Chain
- [ ] SBOM generated (CycloneDX)
- [ ] Vulnerabilities scanned (grype)
- [ ] Critical findings: [N] - Justificativas: [link]
- [ ] Artifact signed (cosign)
- [ ] Signature verified
- [ ] Attestation published (Rekor)

## Doutrina V√©rtice
- [ ] NO PLACEHOLDER - c√≥digo completo
- [ ] NO MOCK - implementa√ß√µes reais
- [ ] PRODUCTION-READY - deploy√°vel agora
- [ ] CONSCI√äNCIA-COMPLIANT - docs filos√≥ficas

## Performance (se aplic√°vel)
- [ ] Benchmarks executados
- [ ] Targets de lat√™ncia atingidos
- [ ] Bottlenecks documentados

## Documenta√ß√£o
- [ ] README atualizado
- [ ] CHANGELOG gerado
- [ ] Release notes redigidas
- [ ] API docs atualizadas

## Aprova√ß√£o
- [ ] Arquiteto-Chefe: ___________ Data: ___________
```

---

**FIM DO DOCUMENTO**
