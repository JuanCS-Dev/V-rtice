# ðŸ§  vCLI-Go Natural Language Parser Blueprint

**MAXIMUS Session | Day 75 | Focus: NLP Command Parser**  
**Doutrina âœ“ | NO MOCK | NO PLACEHOLDER | PRODUCTION-READY**

---

## ðŸŽ¯ Vision Statement

Transform vcli-go into a **truly conversational CLI** that understands natural language with the same sophistication as GitHub Copilot CLI. Users speak their intent naturally ("mostra os pods do namespace default que tÃ£o com problema") and vcli-go intelligently translates to precise commands.

### Success Criteria
- âœ… Parse arbitrary natural language input with 95%+ accuracy
- âœ… Support Portuguese and English seamlessly
- âœ… Handle typos, colloquialisms, and ambiguity gracefully
- âœ… Provide intelligent clarifications when ambiguous
- âœ… Learn from user patterns (feedback loop)
- âœ… Zero latency degradation (< 50ms parsing overhead)
- âœ… 100% type-safe Go implementation
- âœ… Comprehensive test coverage (â‰¥ 90%)

---

## ðŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Natural Language Parser                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Tokenizer   â”‚â”€â”€â”€â”€â”€â–¶â”‚  Intent      â”‚â”€â”€â”€â”€â”€â–¶â”‚  Command    â”‚ â”‚
â”‚  â”‚  Normalizer  â”‚      â”‚  Classifier  â”‚      â”‚  Generator  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                      â”‚                      â”‚        â”‚
â”‚         â–¼                      â–¼                      â–¼        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Entity      â”‚      â”‚  Context     â”‚      â”‚  Validator  â”‚ â”‚
â”‚  â”‚  Extractor   â”‚      â”‚  Manager     â”‚      â”‚  Suggester  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                      â”‚                      â”‚        â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                â”‚                                â”‚
â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚                         â”‚  Learning   â”‚                        â”‚
â”‚                         â”‚  Engine     â”‚                        â”‚
â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“¦ Component Breakdown

### 1. **Tokenizer & Normalizer** (`internal/nlp/tokenizer`)

**Purpose**: Convert raw natural language input into normalized tokens.

**Capabilities**:
- Multi-language support (PT-BR, EN)
- Typo correction using Levenshtein distance
- Slang/colloquialism normalization
- Stop word removal (configurable)
- Stemming/lemmatization

**Example**:
```
Input:  "mostra os pods do namespace default que tÃ£o com problema"
Output: [VERB:show, NOUN:pods, PREP:in, NOUN:namespace, IDENTIFIER:default, 
         FILTER:status, CONDITION:problem]
```

**Implementation**:
```go
type Token struct {
    Raw        string
    Normalized string
    Type       TokenType  // VERB, NOUN, IDENTIFIER, FILTER, etc.
    Language   Language   // PT_BR, EN
    Confidence float64
}

type Tokenizer interface {
    Tokenize(input string) ([]Token, error)
    Normalize(tokens []Token) []Token
    CorrectTypos(tokens []Token) []Token
}
```

---

### 2. **Intent Classifier** (`internal/nlp/intent`)

**Purpose**: Determine user's primary intent from tokenized input.

**Intent Categories**:
- `QUERY` - Retrieve information (list, get, show, describe)
- `ACTION` - Execute operation (create, delete, apply, scale)
- `INVESTIGATE` - Analyze/diagnose (investigate, analyze, debug)
- `ORCHESTRATE` - Workflow execution (run, execute, start)
- `NAVIGATE` - UI navigation (open, launch, switch)
- `CONFIGURE` - Settings management (set, configure, enable)
- `HELP` - Request assistance (help, explain, how)

**Implementation**:
```go
type Intent struct {
    Category   IntentCategory
    Verb       string           // Primary action verb
    Target     string           // Primary target (pods, deployments, etc.)
    Modifiers  []Modifier       // Filters, flags, options
    Confidence float64
}

type IntentClassifier interface {
    Classify(tokens []Token) (*Intent, error)
    GetAlternatives(tokens []Token) ([]*Intent, error) // Ambiguity handling
}
```

**Classification Strategy**:
1. **Rule-based patterns** for common structures
2. **Similarity matching** against known command patterns
3. **Context-aware disambiguation** using conversation history
4. **Confidence scoring** to request clarification when < 0.75

---

### 3. **Entity Extractor** (`internal/nlp/entities`)

**Purpose**: Extract structured entities from natural language.

**Entity Types**:
- **K8s Resources**: pods, deployments, services, namespaces
- **Identifiers**: names, labels, selectors
- **Filters**: status conditions, time ranges, metrics
- **Values**: numbers, strings, booleans
- **Workflows**: offensive, defensive, monitoring operations

**Example**:
```
Input:  "scale deployment nginx to 5 replicas in prod namespace"
Entities:
  - Resource: deployment
  - Name: nginx
  - Count: 5
  - Namespace: prod
```

**Implementation**:
```go
type Entity struct {
    Type       EntityType
    Value      string
    Normalized string
    Metadata   map[string]interface{}
    Span       [2]int  // Start/end position in original input
}

type EntityExtractor interface {
    Extract(tokens []Token, intent *Intent) ([]Entity, error)
    ResolveAmbiguity(entities []Entity, context *Context) ([]Entity, error)
}
```

---

### 4. **Context Manager** (`internal/nlp/context`)

**Purpose**: Maintain conversational context and state.

**Context Tracking**:
- Last N commands executed
- Current namespace/context
- User preferences and patterns
- Clarification history
- Pending confirmations

**Implementation**:
```go
type Context struct {
    SessionID       string
    History         []HistoryEntry
    CurrentResource string
    CurrentNS       string
    Preferences     UserPreferences
    LastIntent      *Intent
    PendingAction   *PendingAction
}

type ContextManager interface {
    Get(sessionID string) (*Context, error)
    Update(sessionID string, update ContextUpdate) error
    ResolveReference(ref string, ctx *Context) (string, error) // "it", "that", "same"
}
```

---

### 5. **Command Generator** (`internal/nlp/generator`)

**Purpose**: Generate executable vcli commands from parsed intent.

**Generation Pipeline**:
1. Map intent to command structure
2. Populate arguments from entities
3. Apply context-based defaults
4. Add required flags/options
5. Validate against command schema

**Example**:
```
Intent:   QUERY pods with filter status=error in namespace=default
Command:  k8s get pods -n default --field-selector=status.phase!=Running
```

**Implementation**:
```go
type Command struct {
    Path      []string          // ["k8s", "get", "pods"]
    Flags     map[string]string
    Args      []string
    PipeChain []Command         // For complex pipelines
    Confidence float64
}

type CommandGenerator interface {
    Generate(intent *Intent, entities []Entity, ctx *Context) (*Command, error)
    GetAlternatives(intent *Intent) ([]Command, error)
    Validate(cmd *Command) error
}
```

---

### 6. **Validator & Suggester** (`internal/nlp/validator`)

**Purpose**: Validate generated commands and suggest corrections.

**Validation Checks**:
- Command syntax correctness
- Required arguments present
- Flag compatibility
- Resource existence (when possible)
- Permission viability

**Suggestion Types**:
- Did you mean? (typo correction)
- Missing required flags
- Alternative approaches
- Related commands

**Implementation**:
```go
type ValidationResult struct {
    Valid       bool
    Errors      []ValidationError
    Warnings    []ValidationWarning
    Suggestions []CommandSuggestion
}

type Validator interface {
    Validate(cmd *Command, ctx *Context) (*ValidationResult, error)
    Suggest(cmd *Command, validationResult *ValidationResult) ([]Command, error)
}
```

---

### 7. **Learning Engine** (`internal/nlp/learning`)

**Purpose**: Learn from user interactions to improve accuracy.

**Learning Mechanisms**:
- **Explicit feedback**: User confirms/corrects interpretations
- **Implicit feedback**: Command execution success/failure
- **Pattern mining**: Identify common phrasings
- **Personalization**: Adapt to individual user styles

**Storage**:
```go
type LearningData struct {
    UserID           string
    PatternFrequency map[string]int        // NL pattern â†’ frequency
    IntentMapping    map[string]string     // NL phrase â†’ Intent
    EntityAliases    map[string]string     // User aliases â†’ canonical names
    FeedbackLog      []FeedbackEntry
}

type LearningEngine interface {
    Learn(input string, intent *Intent, feedback Feedback) error
    GetPatterns(userID string) ([]Pattern, error)
    AdaptClassifier(userID string) error
}
```

---

## ðŸ—‚ï¸ File Structure

```
vcli-go/
â”œâ”€â”€ internal/
â”‚   â””â”€â”€ nlp/
â”‚       â”œâ”€â”€ nlp.go                    # Main NLP interface
â”‚       â”œâ”€â”€ tokenizer/
â”‚       â”‚   â”œâ”€â”€ tokenizer.go          # Tokenization logic
â”‚       â”‚   â”œâ”€â”€ normalizer.go         # Text normalization
â”‚       â”‚   â”œâ”€â”€ typo_corrector.go     # Levenshtein-based correction
â”‚       â”‚   â””â”€â”€ tokenizer_test.go
â”‚       â”œâ”€â”€ intent/
â”‚       â”‚   â”œâ”€â”€ classifier.go         # Intent classification
â”‚       â”‚   â”œâ”€â”€ patterns.go           # Rule-based patterns
â”‚       â”‚   â”œâ”€â”€ similarity.go         # Similarity scoring
â”‚       â”‚   â””â”€â”€ classifier_test.go
â”‚       â”œâ”€â”€ entities/
â”‚       â”‚   â”œâ”€â”€ extractor.go          # Entity extraction
â”‚       â”‚   â”œâ”€â”€ k8s_entities.go       # Kubernetes-specific
â”‚       â”‚   â”œâ”€â”€ workflow_entities.go  # Workflow-specific
â”‚       â”‚   â””â”€â”€ extractor_test.go
â”‚       â”œâ”€â”€ context/
â”‚       â”‚   â”œâ”€â”€ manager.go            # Context management
â”‚       â”‚   â”œâ”€â”€ history.go            # Command history
â”‚       â”‚   â”œâ”€â”€ resolver.go           # Reference resolution
â”‚       â”‚   â””â”€â”€ manager_test.go
â”‚       â”œâ”€â”€ generator/
â”‚       â”‚   â”œâ”€â”€ generator.go          # Command generation
â”‚       â”‚   â”œâ”€â”€ k8s_generator.go      # K8s command generation
â”‚       â”‚   â”œâ”€â”€ workflow_generator.go # Workflow generation
â”‚       â”‚   â””â”€â”€ generator_test.go
â”‚       â”œâ”€â”€ validator/
â”‚       â”‚   â”œâ”€â”€ validator.go          # Command validation
â”‚       â”‚   â”œâ”€â”€ suggester.go          # Smart suggestions
â”‚       â”‚   â””â”€â”€ validator_test.go
â”‚       â””â”€â”€ learning/
â”‚           â”œâ”€â”€ engine.go             # Learning engine
â”‚           â”œâ”€â”€ storage.go            # Pattern storage
â”‚           â”œâ”€â”€ feedback.go           # Feedback processing
â”‚           â””â”€â”€ engine_test.go
â”œâ”€â”€ internal/shell/
â”‚   â”œâ”€â”€ nlp_executor.go               # NLP-aware executor
â”‚   â””â”€â”€ nlp_mode.go                   # NLP mode handler
â””â”€â”€ pkg/
    â””â”€â”€ nlp/
        â””â”€â”€ types.go                  # Public NLP types
```

---

## ðŸŽ¨ User Experience Flow

### Example 1: Simple Query
```
User:  "mostra os pods com problema"
vCLI:  
  ðŸ§  Understood: Show pods with issues
  ðŸ“‹ Executing: k8s get pods --field-selector=status.phase!=Running
  
  [Output: pods list]
```

### Example 2: Ambiguous Intent
```
User:  "escala nginx"
vCLI:  
  ðŸ¤” Clarification needed:
  
  Did you mean:
  1. Scale deployment/nginx (current: 3 replicas)
  2. Scale statefulset/nginx (current: 2 replicas)
  
  Type 1, 2, or clarify further â€º
```

### Example 3: Learning from Feedback
```
User:  "pods quebrados no prod"
vCLI:  
  ðŸ§  Understood: Show broken pods in prod namespace
  ðŸ“‹ Executing: k8s get pods -n prod --field-selector=status.phase!=Running
  
  [Output: pods list]
  
  ðŸ‘ Was this correct? [y/n/edit] â€º y
  
  âœ… Learned! Will remember "quebrados" = error/failed status
```

### Example 4: Context Awareness
```
User:  "mostra os pods do default"
vCLI:  [shows pods]

User:  "agora escala o primeiro pra 5"
vCLI:  
  ðŸ§  Understood: Scale first pod from previous list to 5 replicas
  ðŸ“‹ Executing: k8s scale deployment/nginx -n default --replicas=5
```

---

## ðŸ”§ Implementation Strategy

### Phase 1: Foundation (Week 1-2)
**Goal**: Core NLP infrastructure

**Deliverables**:
- [ ] Tokenizer with PT/EN support
- [ ] Basic intent classifier (rule-based)
- [ ] Entity extractor for K8s resources
- [ ] Context manager skeleton
- [ ] Integration with shell executor

**Tests**:
- Unit tests for each component (â‰¥ 90% coverage)
- Integration test: "mostra pods" â†’ "k8s get pods"

---

### Phase 2: Intelligence (Week 3-4)
**Goal**: Advanced understanding

**Deliverables**:
- [ ] Typo correction
- [ ] Similarity-based intent matching
- [ ] Ambiguity detection & clarification UI
- [ ] Command generator for all vcli commands
- [ ] Validator with smart suggestions

**Tests**:
- Typo handling: "posd" â†’ "pods"
- Ambiguity: "scale nginx" â†’ clarification prompt
- Complex commands: "show failed pods in prod namespace last 1h"

---

### Phase 3: Learning (Week 5-6)
**Goal**: Adaptive intelligence

**Deliverables**:
- [ ] Learning engine with BadgerDB storage
- [ ] Feedback collection UI
- [ ] Pattern mining from history
- [ ] User-specific adaptations
- [ ] Confidence scoring refinement

**Tests**:
- Learning: User says "quebrado" â†’ remembers as "failed"
- Personalization: User's common patterns prioritized
- Confidence: Low confidence triggers clarification

---

### Phase 4: Polish (Week 7-8)
**Goal**: Production readiness

**Deliverables**:
- [ ] Performance optimization (< 50ms)
- [ ] Comprehensive error handling
- [ ] Documentation & examples
- [ ] Tutorial mode
- [ ] Metrics & telemetry

**Tests**:
- Performance: 10k parses < 500ms total
- Edge cases: empty input, very long input, garbage input
- Stress test: concurrent parsing

---

## ðŸ“Š Success Metrics

### Quantitative
- **Accuracy**: â‰¥ 95% correct intent classification
- **Latency**: < 50ms parsing overhead
- **Coverage**: Support 100% of vcli commands
- **Test Coverage**: â‰¥ 90%

### Qualitative
- **User Satisfaction**: "Feels like talking to a human"
- **Learning Curve**: New users productive in < 5 minutes
- **Error Recovery**: Graceful handling of all invalid inputs
- **Confidence**: Users trust the parser's interpretations

---

## ðŸ”¬ Testing Strategy

### 1. Unit Tests
```go
// tokenizer_test.go
func TestTokenizer_Portuguese(t *testing.T) {
    input := "mostra os pods com problema"
    tokens, err := tokenizer.Tokenize(input)
    
    require.NoError(t, err)
    assert.Equal(t, "show", tokens[0].Normalized)
    assert.Equal(t, TokenType_VERB, tokens[0].Type)
}

// classifier_test.go
func TestClassifier_QueryIntent(t *testing.T) {
    tokens := []Token{
        {Normalized: "show", Type: TokenType_VERB},
        {Normalized: "pods", Type: TokenType_NOUN},
    }
    
    intent, err := classifier.Classify(tokens)
    require.NoError(t, err)
    assert.Equal(t, IntentCategory_QUERY, intent.Category)
}
```

### 2. Integration Tests
```go
func TestNLP_EndToEnd_SimpleQuery(t *testing.T) {
    nlp := NewNLP()
    cmd, err := nlp.Parse("mostra os pods")
    
    require.NoError(t, err)
    assert.Equal(t, []string{"k8s", "get", "pods"}, cmd.Path)
}
```

### 3. Golden Tests
Store expected outputs for regression testing:
```
testdata/
â”œâ”€â”€ simple_queries.golden
â”œâ”€â”€ complex_filters.golden
â”œâ”€â”€ ambiguous_inputs.golden
â””â”€â”€ typos.golden
```

---

## ðŸš€ Quick Start Implementation

### Step 1: Bootstrap Package
```bash
mkdir -p internal/nlp/{tokenizer,intent,entities,context,generator,validator,learning}
```

### Step 2: Define Core Interface
```go
// internal/nlp/nlp.go
package nlp

type Parser interface {
    Parse(input string) (*ParseResult, error)
    ParseWithContext(input string, ctx *Context) (*ParseResult, error)
    Learn(input string, feedback Feedback) error
}

type ParseResult struct {
    Command      *Command
    Intent       *Intent
    Confidence   float64
    Alternatives []Command
    Clarification *ClarificationRequest
}
```

### Step 3: Implement Tokenizer (MVP)
Start with simple rule-based tokenization before adding sophistication.

### Step 4: Integrate with Shell
Modify `internal/shell/executor.go` to detect NL input and route to parser.

---

## ðŸŽ“ Research References

### NLP Techniques
- **Levenshtein Distance**: Typo correction
- **TF-IDF**: Pattern matching
- **Edit Distance**: Similarity scoring
- **Stemming/Lemmatization**: Text normalization

### Go Libraries (Evaluated)
- `github.com/kljensen/snowball` - Stemming
- `github.com/texttheater/golang-levenshtein` - Edit distance
- `github.com/ikawaha/kagome` - Tokenization (if needed)
- BadgerDB - Learning data storage

---

## ðŸ›¡ï¸ Doutrina Compliance

### NO MOCK
- All parsing logic fully implemented
- No placeholder functions
- Real typo correction algorithms

### Quality-First
- 100% type safety with Go generics where appropriate
- Comprehensive docstrings
- Error handling at every layer
- Graceful degradation on low confidence

### Production-Ready
- Performance benchmarks
- Telemetry integration
- Backward compatibility (original command syntax still works)
- Feature flags for gradual rollout

---

## ðŸ“ Example Patterns to Support

### Portuguese
```
"mostra os pods"                          â†’ k8s get pods
"lista deployments do namespace prod"     â†’ k8s get deployments -n prod
"escala nginx pra 5"                      â†’ k8s scale deployment/nginx --replicas=5
"deleta o pod nginx-abc123"               â†’ k8s delete pod nginx-abc123
"pods com problema"                       â†’ k8s get pods --field-selector=status.phase!=Running
"logs do pod nginx Ãºltimas 100 linhas"   â†’ k8s logs nginx --tail=100
```

### English
```
"show me the pods"                        â†’ k8s get pods
"scale nginx to 5 replicas"               â†’ k8s scale deployment/nginx --replicas=5
"delete the failing pods"                 â†’ k8s delete pods --field-selector=status.phase=Failed
"run offensive workflow"                  â†’ orchestrate offensive apt-simulation
"investigate suspicious activity"         â†’ investigate
```

### Advanced
```
"mostra pods que nÃ£o tÃ£o rodando no prod nos Ãºltimos 30min"
â†’ k8s get pods -n prod --field-selector=status.phase!=Running 
  (filtered by time if supported)

"escala todos os deployments com label app=api pra 3"
â†’ k8s scale deployments -l app=api --replicas=3
```

---

## ðŸŽ¯ Success Declaration

This parser will be COMPLETE when:

1. âœ… User can describe intent naturally in PT or EN
2. âœ… Parser generates correct command â‰¥95% of time
3. âœ… Ambiguity is detected and clarification requested
4. âœ… Parser learns from feedback
5. âœ… Performance impact negligible (< 50ms)
6. âœ… Test coverage â‰¥ 90%
7. âœ… Documentation complete with examples
8. âœ… Integration with existing shell seamless

---

**Blueprint Status**: COMPLETE  
**Ready for Implementation**: YES  
**Estimated Effort**: 8 weeks (4 sprints)  
**Risk Level**: MEDIUM (new domain, but well-architected)  

**Next Steps**: Create detailed roadmap â†’ Begin Phase 1 implementation

---

*"The best interface is the one that understands you."*  
*â€” MAXIMUS Design Philosophy*
