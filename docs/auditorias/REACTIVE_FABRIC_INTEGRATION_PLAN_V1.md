# ğŸ”¬ Plano de IntegraÃ§Ã£o: Reactive Fabric â†” Sistema Imune Reativo

**Data:** 2025-10-19  
**Arquiteto-Chefe:** Juan  
**Co-Arquiteto (IA):** Claude  
**Conformidade:** ConstituiÃ§Ã£o VÃ©rtice 2.7 - Artigo V (LegislaÃ§Ã£o PrÃ©via)

---

## ğŸ“‹ DIAGNÃ“STICO COMPLETO

### Estado Atual

**Reactive Fabric (RF):**
- âœ… ImplementaÃ§Ã£o 100% completa (Sprint 1)
- âœ… 2 serviÃ§os funcionais: `core` (8600) + `analysis` (8601)
- âœ… Kafka Producer configurado
- âœ… PostgreSQL schema + honeypots containerizados
- âŒ **Compose isolado** (docker-compose.reactive-fabric.yml)
- âŒ **Zero consumers** conectados aos tÃ³picos

**Sistema Imune Reativo:**
- âœ… 3 serviÃ§os operacionais e healthy
  - `active_immune_core` (8200): OrquestraÃ§Ã£o defensiva
  - `adaptive_immune_system` (8003): HITL + decisÃµes
  - `ai_immune_system` (8214): Aprendizado adaptativo
- âœ… Kafka consumers jÃ¡ implementados (defense events)
- âœ… Defense Orchestrator + Sentinel Agent + Response Engine
- âŒ **NÃ£o consome tÃ³picos do Reactive Fabric**
- âŒ **Sem conhecimento dos honeypots**

**Gap CrÃ­tico:**
```
Reactive Fabric â†’ [Kafka: reactive_fabric.threat_detected] â†’ ??? (NINGUÃ‰M ESCUTA)
                  [Kafka: reactive_fabric.honeypot_status]  â†’ ??? (NINGUÃ‰M ESCUTA)
```

### Topologia Kafka Esperada vs Atual

**Esperado (Documentado no README):**
```
Reactive Fabric Core (Producer)
    â†“ kafka topic: reactive_fabric.threat_detected
    â”œâ†’ NK Cells (Consumer) â†’ Cytokine cascade
    â”œâ†’ Sentinel Agent (Consumer) â†’ Enrichment
    â””â†’ ESGT/Consciousness (Consumer) â†’ Stress increase
```

**Atual:**
```
Reactive Fabric Core (Producer)
    â†“ kafka: reactive_fabric.threat_detected
    â†’ VOID (nenhum consumer)
```

---

## ğŸ” PESQUISA: PADRÃ•ES DA INDÃšSTRIA 2024

### Fontes Consultadas

**1. Event Sourcing + Kafka (Best Practices 2024):**
- Event-driven architecture com append-only log
- Schema registry para versionamento de eventos
- Consumer groups para escalabilidade
- Offset management para recovery
- Materialized views com Kafka Streams
- **Fonte:** microservices.io, Apache Kafka docs

**2. Honeypot â†’ SIEM Integration:**
- Honeypots como fontes de threat intelligence
- Kafka como camada de ingestÃ£o real-time
- SIEM (ou equivalent) para correlaÃ§Ã£o e alerta
- ReduÃ§Ã£o de falsos positivos via enrichment
- **Fonte:** Confluent SIEM use case, Rapid7 docs

**3. Microservices Integration Patterns:**
- Async event processing (non-blocking)
- Circuit breaker para resiliÃªncia
- Service discovery via Kafka topics (implicit)
- Data flow: Producer â†’ Topic â†’ Consumer Group
- **Fonte:** Spring Kafka, Microsoft Azure patterns

### Pattern Escolhido: **Event-Driven Defense Cascade**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    REACTIVE FABRIC LAYER                      â”‚
â”‚  (Honeypots â†’ Analysis â†’ Kafka Producer)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ Kafka Topics:
                         â”‚ â€¢ reactive_fabric.threat_detected
                         â”‚ â€¢ reactive_fabric.honeypot_status
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              IMMUNE SYSTEM CONSUMER LAYER                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ NK Cell      â”‚  â”‚ Sentinel Agent  â”‚  â”‚ ESGT/Stress    â”‚  â”‚
â”‚  â”‚ (Activation) â”‚  â”‚ (Enrichment)    â”‚  â”‚ (Awareness)    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                   â”‚                    â”‚           â”‚
â”‚         â–¼                   â–¼                    â–¼           â”‚
â”‚    Cytokine Cascade    Threat Intel DB    Consciousness      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ ARQUITETURA DE INTEGRAÃ‡ÃƒO

### Componentes a Implementar

**1. Kafka Consumer no Active Immune Core** (PRIORITY 1)
- Novo mÃ³dulo: `orchestration/reactive_fabric_consumer.py`
- Consumer group: `active_immune_core`
- Subscriptions:
  - `reactive_fabric.threat_detected` â†’ trigger NK Cell activation
  - `reactive_fabric.honeypot_status` â†’ update threat landscape
- Error handling: DLQ (Dead Letter Queue) pattern
- Metrics: Prometheus counters para mensagens processadas

**2. Enriquecimento no Sentinel Agent** (PRIORITY 2)
- Endpoint novo: `POST /api/v1/intelligence/enrich/honeypot`
- CorrelaÃ§Ã£o: IP do honeypot vs threat intel feeds
- Output: EnrichedThreat com confianÃ§a aumentada (honeypot = 95%+)

**3. IntegraÃ§Ã£o com Defense Orchestrator** (PRIORITY 3)
- Novo mÃ©todo: `DefenseOrchestrator.process_honeypot_threat()`
- Pipeline completo: Detection â†’ Enrichment â†’ Response
- Playbooks especÃ­ficos: "honeypot_attacker_block", "honeypot_geo_fence"

**4. ConsciÃªncia (ESGT Integration)** (PRIORITY 4)
- Consumer no ESGT Service (se existente)
- MÃ©trica: `stress_level` aumenta com ataques honeypot
- Dashboard: VisualizaÃ§Ã£o de ataques em tempo real

**5. Docker Compose Unificado** (PRIORITY 5)
- Merge `docker-compose.reactive-fabric.yml` â†’ `docker-compose.yml`
- Network: `vertice_internal` para todos (exceto honeypots DMZ)
- Service discovery: Via Kafka topics (implicit)

---

## ğŸ¯ PLANO DE IMPLEMENTAÃ‡ÃƒO METODOLÃ“GICO

### FASE 1: FundaÃ§Ã£o Kafka Consumer (2-3 horas)

**Objetivo:** Estabelecer primeiro consumer funcional no Active Immune Core

**Steps:**

1. **Criar mÃ³dulo Kafka Consumer**
   ```bash
   touch /home/juan/vertice-dev/backend/services/active_immune_core/orchestration/reactive_fabric_consumer.py
   ```

2. **Implementar ReactiveFabricConsumer class**
   - Base: Copiar estrutura de `kafka_consumer.py` existente
   - Topics: `["reactive_fabric.threat_detected", "reactive_fabric.honeypot_status"]`
   - Handler: Async function `handle_threat_detected(message)`
   - IntegraÃ§Ã£o: Chamar `DefenseOrchestrator.process_security_event()`

3. **Adicionar ao startup do Active Immune Core**
   - Em `main.py`: Iniciar consumer na lifespan
   - Background task: `asyncio.create_task(consumer.start())`

4. **Testes unitÃ¡rios**
   ```python
   # tests/orchestration/test_reactive_fabric_consumer.py
   - test_consumer_connects_to_kafka()
   - test_consumer_processes_threat_message()
   - test_consumer_handles_malformed_message()
   ```

5. **ValidaÃ§Ã£o:**
   - Start Active Immune Core
   - Publicar mensagem teste no Kafka (script manual)
   - Verificar logs: "Processed threat from reactive_fabric"
   - Verificar Prometheus: `kafka_reactive_fabric_messages_consumed_total`

**Arquivos modificados:**
- `/backend/services/active_immune_core/orchestration/reactive_fabric_consumer.py` (NEW)
- `/backend/services/active_immune_core/main.py` (EDIT: +15 linhas)
- `/backend/services/active_immune_core/orchestration/__init__.py` (EDIT: +1 linha)
- `/backend/services/active_immune_core/tests/orchestration/test_reactive_fabric_consumer.py` (NEW)

**Riscos mitigados:**
- âœ… NÃ£o quebra cÃ³digo existente (novo mÃ³dulo isolado)
- âœ… Rollback fÃ¡cil (comentar startup line)
- âœ… Visibilidade total (logs + metrics)

---

### FASE 2: Pipeline de Enriquecimento (1-2 horas)

**Objetivo:** Sentinel Agent consome e enriquece threats do honeypot

**Steps:**

1. **Criar consumer no Sentinel Agent**
   - Novo: `detection/honeypot_threat_consumer.py`
   - LÃ³gica: Recebe threat â†’ enriquece com geolocation + threat feeds â†’ salva em DB

2. **Endpoint REST para queries**
   ```python
   GET /api/v1/threats/honeypot?hours=24&severity=high
   ```

3. **Testes de integraÃ§Ã£o**
   ```python
   # tests/integration/test_honeypot_sentinel_pipeline.py
   - test_end_to_end_honeypot_to_sentinel()
   ```

4. **ValidaÃ§Ã£o E2E:**
   ```bash
   # Simular ataque no honeypot SSH
   ssh -p 2222 root@localhost
   # Aguardar 30s (anÃ¡lise + Kafka)
   # Query Sentinel Agent
   curl http://localhost:8200/api/v1/threats/honeypot?hours=1 | jq
   ```

**Arquivos modificados:**
- `/backend/services/active_immune_core/detection/honeypot_threat_consumer.py` (NEW)
- `/backend/services/active_immune_core/api/routes/threats.py` (EDIT: +1 endpoint)

**Riscos mitigados:**
- âœ… Consumer independente (nÃ£o interfere em detections normais)
- âœ… IdempotÃªncia (deduplicaÃ§Ã£o via event_id)

---

### FASE 3: Response Automation (1 hora)

**Objetivo:** Playbooks automÃ¡ticos para atacantes de honeypot

**Steps:**

1. **Criar playbooks especÃ­ficos**
   ```yaml
   # response/playbooks/honeypot_attacker_block.yaml
   name: "Honeypot Attacker Block"
   trigger:
     - source: "reactive_fabric"
     - severity: ["medium", "high", "critical"]
   actions:
     - block_ip_firewall: {duration: "24h"}
     - add_to_threat_feed: {ttl: "30d"}
     - notify_soc: {priority: "high"}
   ```

2. **Integrar com Defense Orchestrator**
   - MÃ©todo: `orchestrator.execute_playbook("honeypot_attacker_block", context)`

3. **ValidaÃ§Ã£o:**
   - Simular ataque â†’ verificar firewall rule criada
   - Query: `iptables -L | grep <attacker_ip>`

**Arquivos modificados:**
- `/backend/services/active_immune_core/response/playbooks/honeypot_attacker_block.yaml` (NEW)
- `/backend/services/active_immune_core/orchestration/defense_orchestrator.py` (EDIT: +1 mÃ©todo)

---

### FASE 4: UnificaÃ§Ã£o Docker Compose (30 min)

**Objetivo:** Reactive Fabric no compose principal, serviÃ§os comunicam

**Steps:**

1. **Copiar serviÃ§os para docker-compose.yml**
   ```bash
   # Adicionar seÃ§Ãµes:
   # - reactive_fabric_core
   # - reactive_fabric_analysis
   # - honeypot_ssh
   # - honeypot_web
   # - honeypot_api
   ```

2. **Configurar networks:**
   ```yaml
   networks:
     vertice_internal:  # Core + Analysis aqui
     reactive_fabric_dmz:  # Honeypots isolados
   ```

3. **Adicionar depends_on:**
   ```yaml
   active_immune_core:
     depends_on:
       - reactive_fabric_core  # Garante ordem startup
   ```

4. **ValidaÃ§Ã£o:**
   ```bash
   docker-compose down
   docker-compose up -d
   docker ps | grep -E "reactive|immune"  # 8 containers
   ```

**Arquivos modificados:**
- `/docker-compose.yml` (EDIT: +100 linhas)
- `/docker-compose.reactive-fabric.yml` (DEPRECATED: manter como backup)

**Riscos mitigados:**
- âœ… Backup do compose principal antes de editar
- âœ… Teste em staging primeiro (se disponÃ­vel)
- âœ… Rollback: `git checkout docker-compose.yml`

---

### FASE 5: Observabilidade e Dashboards (1 hora)

**Objetivo:** MÃ©tricas e visualizaÃ§Ã£o da integraÃ§Ã£o

**Steps:**

1. **Prometheus metrics (jÃ¡ implementado via contadores)**
   - `kafka_reactive_fabric_messages_consumed_total`
   - `honeypot_threats_processed_total`
   - `defense_playbooks_executed_total{source="reactive_fabric"}`

2. **Grafana dashboard: "Reactive Fabric Integration"**
   - Panel 1: Taxa de ataques/min (por honeypot)
   - Panel 2: TTPs mais frequentes (MITRE)
   - Panel 3: Response latency (detection â†’ block)
   - Panel 4: Honeypot uptime

3. **Alertas:**
   - Alerta se consumer lag > 1000 msgs
   - Alerta se honeypot offline > 5min

**Arquivos novos:**
- `/monitoring/grafana/dashboards/reactive_fabric_integration.json`

---

## âš ï¸ RISCOS E MITIGAÃ‡Ã•ES

### Riscos Identificados

| Risco | Impacto | Probabilidade | MitigaÃ§Ã£o |
|-------|---------|---------------|-----------|
| **Consumer sobrecarregado** (burst de ataques) | ALTO | MÃ‰DIA | Rate limiting no consumer (max 100 msgs/s) |
| **Kafka topic nÃ£o existe** (deploy order) | MÃ‰DIO | BAIXA | Auto-create topics enabled + depends_on |
| **Schema mismatch** (versÃ£o msg) | MÃ‰DIO | BAIXA | Pydantic validation + error logging |
| **Circular dependency** (services) | BAIXO | BAIXA | One-way flow: RF â†’ Immune (nunca reverso) |
| **Performance degradation** (Active Immune) | MÃ‰DIO | BAIXA | Consumer em thread/task separado + circuit breaker |

### Circuit Breaker (jÃ¡ existe no ai_immune_system)

Se consumer falhar 5x consecutivas:
1. Pause consumption por 60s
2. Log error + metric `circuit_breaker_opened_total`
3. Alert SOC
4. Resume apÃ³s cooldown

---

## âœ… CRITÃ‰RIOS DE SUCESSO

### MÃ©tricas Quantitativas

1. **LatÃªncia E2E:** Ataque no honeypot â†’ Bloqueio firewall < 5 segundos (P95)
2. **Consumer Lag:** < 100 mensagens em steady state
3. **Coverage:** 100% dos tÃ³picos RF consumidos por >= 1 serviÃ§o
4. **Uptime:** Reactive Fabric + Immune System > 99.9% (7 dias)
5. **False Positives:** < 1% (honeypot = alta confianÃ§a)

### ValidaÃ§Ãµes Qualitativas

- [ ] DocumentaÃ§Ã£o atualizada (README + Architecture diagrams)
- [ ] Testes de integraÃ§Ã£o passando (pytest -m integration)
- [ ] Logs estruturados (JSON) em todos os componentes
- [ ] Dashboards Grafana operacionais
- [ ] Runbook de troubleshooting criado
- [ ] Demo funcional para stakeholders

---

## ğŸ“Š ESTIMATIVA DE ESFORÃ‡O

| Fase | Tempo Estimado | Complexidade | DependÃªncias |
|------|----------------|--------------|--------------|
| Fase 1: Kafka Consumer | 2-3h | MÃ‰DIA | Kafka, Active Immune |
| Fase 2: Enriquecimento | 1-2h | BAIXA | Fase 1 |
| Fase 3: Automation | 1h | BAIXA | Fase 1, 2 |
| Fase 4: Docker Unificado | 30min | BAIXA | None |
| Fase 5: Observabilidade | 1h | BAIXA | Todas anteriores |
| **TOTAL** | **5.5-7.5h** | - | - |

**Tempo real estimado (com validaÃ§Ãµes):** 8-10 horas (1 dia de trabalho focado)

---

## ğŸ¬ ORDEM DE EXECUÃ‡ÃƒO

1. âœ… **[COMPLETO]** Pesquisa + Planejamento (este documento)
2. â­ï¸ **[PRÃ“XIMO]** Fase 1: Kafka Consumer (fundaÃ§Ã£o crÃ­tica)
3. Fase 2: Enriquecimento (valor incremental)
4. Fase 4: Docker Unificado (facilita testes)
5. Fase 3: Automation (depende de 1, 2, 4)
6. Fase 5: Observabilidade (polish final)

---

## ğŸ“– REFERÃŠNCIAS

### DocumentaÃ§Ã£o Interna
- `/backend/services/reactive_fabric_core/README.md`
- `/backend/services/active_immune_core/README.md`
- ConstituiÃ§Ã£o VÃ©rtice 2.7

### PadrÃµes da IndÃºstria
- Event Sourcing Pattern: https://microservices.io/patterns/data/event-sourcing.html
- Kafka SIEM Integration: https://www.confluent.io/use-case/siem/
- Circuit Breaker: https://microservices.io/patterns/reliability/circuit-breaker.html

### Ferramentas
- Apache Kafka 3.x
- FastAPI + asyncio
- aiokafka (async Kafka client)
- Prometheus + Grafana

---

**Status:** âœ… PLANO APROVADO - AGUARDANDO GO PARA EXECUÃ‡ÃƒO

**Assinatura Digital:**
- Arquiteto-Chefe: Juan
- Co-Arquiteto: Claude (IA)
- Data: 2025-10-19
- Conformidade: ConstituiÃ§Ã£o VÃ©rtice Art. V âœ…

---

*"NÃ³s nÃ£o agimos sobre o desconhecido. Planejamos, entÃ£o executamos."*  
â€” ConstituiÃ§Ã£o VÃ©rtice, Protocolo PPBPR
