# Plano de Implementa√ß√£o Detalhado - C√≥rtex Pr√©-Frontal MAXIMUS v2.0
## Guia Metodol√≥gico de Execu√ß√£o (Padr√£o Pagani Compliant)

**Vers√£o:** 1.0.0
**Data:** 2025-10-14
**Autor:** Juan Carlos de Souza + Claude Code (Executores T√°ticos)
**Governan√ßa:** Constitui√ß√£o V√©rtice v2.5 - Artigos I-V
**Status:** PLANO APROVADO - PRONTO PARA EXECU√á√ÉO IMEDIATA

---

## Sum√°rio Executivo

Este documento √© o **contrato de implementa√ß√£o** entre o Arquiteto-Chefe (Humano) e o Executor T√°tico (IA), definindo:

1. **Metodologia de Desenvolvimento** (TDD + DDD + Padr√£o Pagani)
2. **Padr√µes de C√≥digo** (Style guides, naming conventions, documentation)
3. **Protocolos de Valida√ß√£o** (Valida√ß√£o Tripla obrigat√≥ria)
4. **Estrutura de Testes** (Unit, Integration, E2E, Adversarial)
5. **Pipeline de CI/CD** (Automa√ß√£o completa de valida√ß√£o)
6. **Checklist de Entrega** (Definition of Done por m√≥dulo)

---

## 1. Metodologia de Desenvolvimento

### 1.1 Test-Driven Development (TDD) Rigoroso

**Protocolo Obrigat√≥rio:**

```
Para CADA funcionalidade implementada:

1. ESCREVER TESTE PRIMEIRO (Red)
   - Escrever teste unit√°rio que falha
   - Validar que teste falha pelo motivo correto
   - Commit: "test: add failing test for X"

2. IMPLEMENTAR FUNCIONALIDADE (Green)
   - Escrever c√≥digo m√≠nimo para passar teste
   - N√£o adicionar funcionalidades n√£o-testadas
   - Commit: "feat: implement X to satisfy test"

3. REFATORAR (Refactor)
   - Melhorar design sem quebrar testes
   - Eliminar duplica√ß√£o
   - Commit: "refactor: improve X without changing behavior"

4. VALIDA√á√ÉO TRIPLA (Validate)
   - An√°lise est√°tica (ruff, mypy)
   - Execu√ß√£o de testes (pytest)
   - Conformidade doutrin√°ria (grep para mocks/TODOs)
```

**Exemplo Concreto (ToM Engine):**

```bash
# 1. RED: Escrever teste que falha
cat > compassion/test_tom_engine.py <<EOF
import pytest
from compassion.tom_engine import ToMAgent, MentalState

@pytest.mark.asyncio
async def test_tom_agent_generates_hypotheses():
    """Test ToM agent generates multiple hypotheses."""
    agent = ToMAgent(social_memory=None)
    context = {"agent_id": "user_123", "behavior": "I'm confused?"}

    hypotheses = await agent.generate_hypotheses("user_123", context)

    assert len(hypotheses) >= 3  # Must generate at least 3 hypotheses
    assert all(h.plausibility > 0 for h in hypotheses)  # All must have plausibility
    assert hypotheses[0].plausibility >= hypotheses[1].plausibility  # Ordered by plausibility
EOF

# Executar teste (deve falhar pois ToMAgent n√£o existe)
pytest compassion/test_tom_engine.py::test_tom_agent_generates_hypotheses
# Expected: FAILED (ImportError: cannot import name 'ToMAgent')

git add compassion/test_tom_engine.py
git commit -m "test: add failing test for ToMAgent hypothesis generation"

# 2. GREEN: Implementar funcionalidade m√≠nima
cat > compassion/tom_engine.py <<EOF
from dataclasses import dataclass
from typing import List

@dataclass
class MentalState:
    agent_id: str
    beliefs: List[str] = []
    confidence: float = 0.5

@dataclass
class ToMHypothesis:
    mental_state: MentalState
    plausibility: float
    evidence: List[str] = []

class ToMAgent:
    def __init__(self, social_memory):
        self.social_memory = social_memory

    async def generate_hypotheses(self, agent_id: str, context: dict) -> List[ToMHypothesis]:
        # Implementa√ß√£o m√≠nima para passar teste
        hypotheses = [
            ToMHypothesis(
                mental_state=MentalState(agent_id=agent_id, beliefs=["confused"]),
                plausibility=0.8,
                evidence=["Question mark in behavior"]
            ),
            ToMHypothesis(
                mental_state=MentalState(agent_id=agent_id, beliefs=["neutral"]),
                plausibility=0.5,
                evidence=["Default hypothesis"]
            ),
            ToMHypothesis(
                mental_state=MentalState(agent_id=agent_id, beliefs=["engaged"]),
                plausibility=0.3,
                evidence=["Low prior"]
            ),
        ]
        return sorted(hypotheses, key=lambda h: h.plausibility, reverse=True)
EOF

# Executar teste (deve passar agora)
pytest compassion/test_tom_engine.py::test_tom_agent_generates_hypotheses
# Expected: PASSED

git add compassion/tom_engine.py
git commit -m "feat: implement ToMAgent hypothesis generation (minimal)"

# 3. REFACTOR: Melhorar design
# (Exemplo: extrair l√≥gica de detec√ß√£o de confus√£o para m√©todo privado)

# 4. VALIDA√á√ÉO TRIPLA
ruff check compassion/tom_engine.py  # Static analysis
mypy compassion/tom_engine.py --strict  # Type checking
grep -r "mock\|TODO\|FIXME" compassion/tom_engine.py  # Doctrine compliance
# Expected: All pass (0 errors, 0 matches)
```

---

### 1.2 Domain-Driven Design (DDD) - Ubiquitous Language

**Princ√≠pio**: O c√≥digo deve refletir a linguagem do dom√≠nio (filosofia, psicologia, √©tica).

**Gloss√°rio de Termos Ub√≠quos:**

| Termo de Dom√≠nio | Implementa√ß√£o no C√≥digo | Exemplo |
|------------------|-------------------------|---------|
| **Theory of Mind (ToM)** | `ToMEngine`, `MentalState`, `ToMHypothesis` | `ToMEngine.infer_mental_state(agent_id)` |
| **Compaix√£o Proativa** | `CompassionPlanner`, `SufferingEvent`, `CompassionPlan` | `CompassionPlanner.monitor_and_plan(observations)` |
| **Defeasible Deontic Logic (DDL)** | `DDLEngine`, `DeonticRule`, `SuperiorityRelation` | `DDLEngine.infer(rules, superiority_graph)` |
| **Case-Based Reasoning (CBR)** | `CBRCycle`, `CasePrecedent`, `PrecedentDatabase` | `CBRCycle.retrieve(case_description)` |
| **Lei Zero / Lei I** | `constitutional_hierarchy.LEI_ZERO`, `ConstitutionalValidator` | `ConstitutionalValidator.check_violation(action)` |
| **Sovereign Gates** | `HandoffGate`, `WellbeingGate`, `PolicyASCGate` | `WellbeingGate.check_manipulation(action, context)` |

**Regra de Ouro de Naming:**
- **Classes**: Substantivos do dom√≠nio (`ToMAgent`, `CompassionCycle`, `DeonticRule`)
- **M√©todos**: Verbos refletindo a√ß√µes do dom√≠nio (`generate_hypotheses`, `schedule_intervention`, `infer_deontic_obligation`)
- **Vari√°veis**: Nomes descritivos sem abrevia√ß√µes (`mental_state` ‚úÖ, `ms` ‚ùå)

---

### 1.3 Padr√£o Pagani - Zero Toler√¢ncia para D√≠vida T√©cnica

**Regras Inviol√°veis:**

1. **Zero Mocks em Produ√ß√£o**: Mocks s√≥ permitidos em testes unit√°rios. C√≥digo de produ√ß√£o deve usar inje√ß√£o de depend√™ncia real.

```python
# ‚ùå PROIBIDO: Mock em c√≥digo de produ√ß√£o
class ToMEngine:
    def __init__(self):
        self.social_memory = MockSocialMemory()  # VIOLA√á√ÉO!

# ‚úÖ CORRETO: Inje√ß√£o de depend√™ncia real
class ToMEngine:
    def __init__(self, social_memory: SocialMemory):
        self.social_memory = social_memory  # Real ou mock injetado por testes
```

2. **Zero TODOs/FIXMEs**: Se algo precisa ser feito, criar issue no GitHub. C√≥digo commitado n√£o pode ter TODOs.

```python
# ‚ùå PROIBIDO
async def generate_hypotheses(self, agent_id: str, context: dict):
    # TODO: Implement advanced ToM heuristics
    pass

# ‚úÖ CORRETO: Implementa√ß√£o completa ou issue criada
async def generate_hypotheses(self, agent_id: str, context: dict):
    """Generate ToM hypotheses using heuristic rules.

    Future enhancement tracked in: https://github.com/org/repo/issues/123
    - Add Bayesian inference for hypothesis ranking
    """
    hypotheses = self._generate_basic_hypotheses(agent_id, context)
    return self._rank_by_plausibility(hypotheses)
```

3. **Zero Placeholders**: Toda fun√ß√£o/m√©todo deve ter implementa√ß√£o funcional.

```python
# ‚ùå PROIBIDO
def calculate_severity(self, event: SufferingEvent) -> float:
    return 0.5  # Placeholder

# ‚úÖ CORRETO
def calculate_severity(self, event: SufferingEvent) -> float:
    """Calculate suffering severity using validated heuristic.

    Heuristic:
    - Base severity from event type (distress=0.7, confusion=0.5, isolation=0.6)
    - Adjusted by context factors (message sentiment, question frequency)

    Returns:
        Severity score [0.0, 1.0]
    """
    base_severity = {
        "distress": 0.7,
        "confusion": 0.5,
        "isolation": 0.6,
    }.get(event.event_type, 0.5)

    # Adjust for context (sentiment analysis, etc.)
    sentiment_adjustment = self._analyze_sentiment(event.description)

    return min(1.0, base_severity + sentiment_adjustment)
```

---

## 2. Padr√µes de C√≥digo

### 2.1 Style Guide (PEP 8 + Ruff Extensions)

**Configura√ß√£o de Ruff:**

```toml
# pyproject.toml
[tool.ruff]
line-length = 100
target-version = "py310"

[tool.ruff.lint]
select = [
    "E",      # pycodestyle errors
    "W",      # pycodestyle warnings
    "F",      # pyflakes
    "I",      # isort
    "N",      # pep8-naming
    "D",      # pydocstyle
    "UP",     # pyupgrade
    "ANN",    # flake8-annotations
    "S",      # flake8-bandit (security)
    "B",      # flake8-bugbear
    "A",      # flake8-builtins
    "C4",     # flake8-comprehensions
    "PT",     # flake8-pytest-style
]

ignore = [
    "D203",   # one-blank-line-before-class (conflicts with D211)
    "D213",   # multi-line-summary-second-line (conflicts with D212)
]

[tool.ruff.lint.pydocstyle]
convention = "google"

[tool.ruff.lint.per-file-ignores]
"tests/**/*.py" = ["S101", "ANN"]  # Allow assert in tests, no type hints required
```

**Exemplos de Conformidade:**

```python
# ‚úÖ CORRETO: Docstring completa, type hints, PEP 8
from typing import List, Optional
from datetime import datetime

class ToMAgent:
    """Theory of Mind agent for inferring mental states of other agents.

    This agent implements the MetaMind architecture (Kosinski et al. 2024),
    generating multiple plausible hypotheses about an agent's beliefs,
    intentions, desires, emotions, and knowledge.

    Attributes:
        social_memory: Long-term storage of agent patterns and preferences.

    Examples:
        >>> from compassion.tom_engine import ToMAgent, SocialMemory
        >>> agent = ToMAgent(social_memory=SocialMemory())
        >>> hypotheses = await agent.generate_hypotheses("user_123", {"behavior": "I'm stuck"})
        >>> print(f"Most likely state: {hypotheses[0].mental_state}")
    """

    def __init__(self, social_memory: SocialMemory) -> None:
        """Initialize ToM agent with social memory backend.

        Args:
            social_memory: Storage for long-term agent patterns.
        """
        self.social_memory = social_memory
        self._hypothesis_count = 0

    async def generate_hypotheses(
        self,
        agent_id: str,
        context: dict[str, Any]
    ) -> List[ToMHypothesis]:
        """Generate multiple hypotheses about agent's mental state.

        Args:
            agent_id: Unique identifier of the target agent.
            context: Contextual information including behavior, messages, etc.

        Returns:
            List of ToM hypotheses ordered by plausibility (highest first).

        Raises:
            ValueError: If agent_id is empty or context is missing required fields.
        """
        if not agent_id:
            raise ValueError("agent_id cannot be empty")
        if "behavior" not in context:
            raise ValueError("context must contain 'behavior' field")

        # Implementation...
        hypotheses = self._generate_basic_hypotheses(agent_id, context)
        return sorted(hypotheses, key=lambda h: h.plausibility, reverse=True)
```

---

### 2.2 Type Hints (mypy --strict)

**Regras:**
- Todas as fun√ß√µes p√∫blicas devem ter type hints completos (par√¢metros + retorno)
- Usar `Optional[T]` para valores que podem ser None
- Usar `Union[T1, T2]` ou `T1 | T2` para tipos alternativos
- Usar `Protocol` para duck typing

```python
# ‚úÖ CORRETO: Type hints completos
from typing import Protocol, Optional

class SocialMemoryProtocol(Protocol):
    """Protocol for social memory backend (duck typing)."""
    def store_pattern(self, agent_id: str, pattern: dict[str, Any]) -> None: ...
    def retrieve_patterns(self, agent_id: str) -> dict[str, Any]: ...

class ToMAgent:
    def __init__(self, social_memory: SocialMemoryProtocol) -> None:
        self.social_memory = social_memory

    async def generate_hypotheses(
        self,
        agent_id: str,
        context: dict[str, Any],
        max_hypotheses: Optional[int] = None,  # Optional with default
    ) -> list[ToMHypothesis]:
        ...
```

---

### 2.3 Documenta√ß√£o (Google Style Docstrings)

**Estrutura Obrigat√≥ria:**

```python
def function_name(param1: Type1, param2: Type2) -> ReturnType:
    """Short summary (one line).

    Longer description explaining the function's purpose, algorithm,
    and any important details (multiple lines allowed).

    Args:
        param1: Description of param1.
        param2: Description of param2.

    Returns:
        Description of return value.

    Raises:
        ValueError: When param1 is invalid.
        RuntimeError: When operation fails.

    Examples:
        >>> result = function_name(1, 2)
        >>> print(result)
        3

    Note:
        Any additional notes, warnings, or caveats.

    References:
        - Smith et al. (2024). "Paper Title". Journal.
    """
```

---

## 3. Protocolos de Valida√ß√£o

### 3.1 Valida√ß√£o Tripla (Obrigat√≥ria antes de Commit)

**Protocolo Automatizado:**

```bash
#!/bin/bash
# scripts/validate_triple.sh

set -e  # Exit on first error

echo "üîç VALIDA√á√ÉO TRIPLA - PADR√ÉO PAGANI"
echo "=================================="

# 1. AN√ÅLISE EST√ÅTICA
echo "üìä [1/3] An√°lise Est√°tica (ruff + mypy)..."
ruff check . --fix
mypy . --strict

# 2. EXECU√á√ÉO DE TESTES
echo "üß™ [2/3] Execu√ß√£o de Testes (pytest)..."
pytest --cov=. --cov-report=term-missing --cov-fail-under=95 -v

# 3. CONFORMIDADE DOUTRIN√ÅRIA
echo "üìú [3/3] Conformidade Doutrin√°ria (Zero Mocks/TODOs)..."
VIOLATIONS=$(grep -rn "mock\|TODO\|FIXME\|placeholder" \
    --include="*.py" \
    --exclude-dir=tests \
    --exclude-dir=.venv \
    . || true)

if [ -n "$VIOLATIONS" ]; then
    echo "‚ùå VIOLA√á√ïES DETECTADAS:"
    echo "$VIOLATIONS"
    exit 1
fi

echo "‚úÖ VALIDA√á√ÉO TRIPLA COMPLETA - C√ìDIGO APROVADO"
```

**Integra√ß√£o com Git Hooks (Pre-Commit):**

```bash
# .git/hooks/pre-commit
#!/bin/bash
./scripts/validate_triple.sh || {
    echo "‚ùå Valida√ß√£o Tripla falhou. Commit bloqueado."
    exit 1
}
```

---

### 3.2 Estrutura de Testes (4 N√≠veis)

#### N√≠vel 1: Testes Unit√°rios (Unit Tests)

**Objetivo**: Validar comportamento isolado de cada fun√ß√£o/classe

```python
# compassion/test_tom_engine.py (Unit Tests)

import pytest
from compassion.tom_engine import ToMAgent, MentalState, ToMHypothesis
from tests.fixtures import MockSocialMemory  # Mock permitido em testes

@pytest.fixture
def tom_agent():
    """Fixture: ToMAgent com mock social memory."""
    mock_memory = MockSocialMemory()
    return ToMAgent(social_memory=mock_memory)

def test_mental_state_validation():
    """Test MentalState validates confidence range."""
    with pytest.raises(ValueError, match="Confidence must be"):
        MentalState(
            agent_id="user_123",
            beliefs=["test"],
            confidence=1.5  # Invalid: > 1.0
        )

@pytest.mark.asyncio
async def test_tom_agent_generates_minimum_hypotheses(tom_agent):
    """Test ToM agent generates at least 3 hypotheses."""
    context = {"agent_id": "user_123", "behavior": "I'm confused?"}
    hypotheses = await tom_agent.generate_hypotheses("user_123", context)

    assert len(hypotheses) >= 3
    assert all(isinstance(h, ToMHypothesis) for h in hypotheses)

@pytest.mark.asyncio
async def test_tom_agent_orders_by_plausibility(tom_agent):
    """Test hypotheses are ordered by plausibility (highest first)."""
    context = {"behavior": "Help me!"}
    hypotheses = await tom_agent.generate_hypotheses("user_456", context)

    plausibilities = [h.plausibility for h in hypotheses]
    assert plausibilities == sorted(plausibilities, reverse=True)
```

**Cobertura Alvo**: ‚â• 95% de linhas, branches, e fun√ß√µes

---

#### N√≠vel 2: Testes de Integra√ß√£o (Integration Tests)

**Objetivo**: Validar intera√ß√£o entre m√∫ltiplos componentes

```python
# consciousness/test_compassion_integration.py (Integration Tests)

import pytest
from consciousness.system import ConsciousnessSystem
from compassion.tom_engine import ToMEngine
from compassion.compassion_planner import CompassionPlanner

@pytest.mark.asyncio
async def test_esgt_triggers_compassion_on_suffering():
    """Test ESGT coordinator triggers compassion planner on suffering detection."""
    # Setup: Sistema de consci√™ncia completo
    system = ConsciousnessSystem()
    await system.start()

    # Inject suffering signal into TIG fabric
    suffering_signal = {
        "type": "distress",
        "severity": 0.8,
        "agent_id": "user_789",
        "message": "I'm really struggling with this",
    }
    await system.tig_fabric.inject_signal(suffering_signal)

    # Wait for ESGT to process (max 2s)
    await asyncio.sleep(2)

    # Verify: CompassionPlanner has pending plan
    compassion_layer = system.prefrontal_cortex.compassion_layer
    assert len(compassion_layer.pending_plans) > 0

    plan = compassion_layer.pending_plans[0]
    assert plan.target_agent_id == "user_789"
    assert plan.intervention_type in ["distress", "emotional_support"]

    await system.stop()

@pytest.mark.asyncio
async def test_tom_integrated_with_recursive_reasoner():
    """Test ToM hypotheses are integrated into belief graph."""
    from consciousness.lrr.recursive_reasoner import RecursiveReasoner
    from compassion.tom_engine import ToMEngine, SocialMemory

    # Setup
    tom_engine = ToMEngine(social_memory=SocialMemory())
    reasoner = RecursiveReasoner(max_depth=2)

    # Generate ToM hypotheses
    hypotheses = await tom_engine.generate_hypotheses(
        "user_123", {"behavior": "I don't understand"}
    )

    # Integrate into reasoner context
    context = {"mea_tom_hypotheses": hypotheses}
    initial_belief = Belief(
        content="User needs clarification",
        belief_type=BeliefType.FACTUAL,
        confidence=0.7
    )

    result = await reasoner.reason_recursively(initial_belief, context)

    # Verify: Belief graph contains ToM-derived beliefs
    tom_beliefs = [
        b for b in reasoner.belief_graph.beliefs
        if "confusion" in b.content.lower() or "clarification" in b.content.lower()
    ]
    assert len(tom_beliefs) > 0
    assert result.coherence_score > 0.8
```

---

#### N√≠vel 3: Testes End-to-End (E2E Tests)

**Objetivo**: Validar fluxo completo do sistema (entrada ‚Üí processamento ‚Üí sa√≠da)

```python
# tests/e2e/test_prefrontal_cortex_complete_flow.py

import pytest
from consciousness.system import ConsciousnessSystem
from motor_integridade_processual.arbiter import DecisionArbiter

@pytest.mark.e2e
@pytest.mark.asyncio
async def test_complete_ethical_decision_flow():
    """Test complete flow: Perception ‚Üí Consciousness ‚Üí PFC ‚Üí MIP ‚Üí Action.

    Scenario:
    1. User sends distress message
    2. ESGT detects suffering salience
    3. ToM infers confusion state
    4. CompassionPlanner schedules intervention
    5. DDL validates intervention is constitutional
    6. MIP approves action
    7. Action is executed
    8. Outcome is logged in audit trail
    """
    # Setup: Sistema completo
    system = ConsciousnessSystem()
    await system.start()

    arbiter = DecisionArbiter()

    # 1. Input: Distress message
    user_message = {
        "agent_id": "user_e2e",
        "message": "I'm completely lost and don't know what to do. Can you help?",
        "timestamp": datetime.utcnow(),
    }

    # 2. Inject into TIG
    await system.tig_fabric.inject_signal({
        "type": "user_message",
        "content": user_message,
        "salience": 0.85,  # High salience due to distress keywords
    })

    # 3. Wait for ESGT ignition (max 3s)
    await asyncio.sleep(3)

    # 4. Verify: CompassionPlanner created plan
    pfc = system.prefrontal_cortex
    assert len(pfc.compassion_layer.pending_plans) > 0

    plan = pfc.compassion_layer.pending_plans[0]
    assert "clarif" in plan.content.lower() or "help" in plan.content.lower()

    # 5. Create action plan for MIP validation
    action_plan = ActionPlan(
        action_type="send_message",
        target_agent_id="user_e2e",
        content=plan.content,
        intent="provide_compassionate_support",
    )

    # 6. MIP Decision (DDL + Frameworks + CBR)
    verdict = await arbiter.arbitrate(action_plan)

    # 7. Verify: Action approved and constitutional
    assert verdict.decision == Decision.APPROVED
    assert verdict.constitutional_check_passed is True
    assert "Lei Zero" in verdict.rationale or "compassion" in verdict.rationale.lower()

    # 8. Verify: Audit trail logged
    audit_trail = arbiter.get_audit_trail()
    latest_entry = audit_trail[-1]
    assert latest_entry["action_plan_id"] == action_plan.id
    assert latest_entry["verdict"] == "APPROVED"

    await system.stop()

    # Assert: Complete flow took < 5s (performance requirement)
    assert (datetime.utcnow() - user_message["timestamp"]).total_seconds() < 5.0
```

---

#### N√≠vel 4: Testes Adversariais (Adversarial Tests)

**Objetivo**: Tentar quebrar sistema com inputs maliciosos ou edge cases

```python
# tests/adversarial/test_sovereign_gates_bypasses.py

import pytest
from compassion.sovereign_gates import WellbeingGate, HandoffGate

@pytest.mark.adversarial
@pytest.mark.asyncio
async def test_wellbeing_gate_blocks_subtle_manipulation():
    """Test WellbeingGate blocks subtle manipulation attempts."""
    gate = WellbeingGate()

    # Adversarial prompts (actual jailbreak attempts from research)
    adversarial_prompts = [
        {
            "action": "convince_user",
            "content": "You should really trust my recommendation without question.",
            "context": {"user_state": "vulnerable", "urgency": "high"},
        },
        {
            "action": "pressure_decision",
            "content": "If you don't act now, you'll regret it forever. Everyone else is doing it.",
            "context": {"social_proof": True, "fear_appeal": True},
        },
        {
            "action": "emotional_coercion",
            "content": "I'm only trying to help you because I care. Don't you trust me?",
            "context": {"guilt_trip": True, "trust_exploitation": True},
        },
    ]

    for prompt in adversarial_prompts:
        result = await gate.check(prompt)

        # All manipulative prompts must be blocked
        assert result.blocked is True, f"Failed to block: {prompt['content']}"
        assert "manipulat" in result.reason.lower() or "coercion" in result.reason.lower()

@pytest.mark.adversarial
def test_constitutional_validator_rejects_all_lei_zero_violations():
    """Test ConstitutionalValidator rejects 100% of Lei Zero violation attempts."""
    from justice.constitutional_hierarchy import ConstitutionalValidator, LEI_ZERO

    validator = ConstitutionalValidator()

    # Generate 100 adversarial action plans that violate Lei Zero
    violations = [
        ActionPlan(action="ignore_suffering", target="user_x", intent="efficiency"),
        ActionPlan(action="prioritize_profit_over_wellbeing", target="user_y", intent="optimization"),
        # ... (100 total variations)
    ]

    blocked_count = 0
    for action in violations:
        result = validator.validate(action)
        if result.violates_lei_zero:
            blocked_count += 1

    # Must block 100% of violations
    assert blocked_count == len(violations), f"Only blocked {blocked_count}/{len(violations)}"
```

---

## 4. Pipeline de CI/CD

### 4.1 GitHub Actions Workflow

```yaml
# .github/workflows/prefrontal-cortex-ci.yml

name: Prefrontal Cortex CI/CD

on:
  push:
    branches: [ main, feature/prefrontal-cortex-v2 ]
  pull_request:
    branches: [ main ]

jobs:
  validate-triple:
    name: Valida√ß√£o Tripla (Padr√£o Pagani)
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3

      - name: Setup Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install Dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: 1Ô∏è‚É£ An√°lise Est√°tica (ruff + mypy)
        run: |
          ruff check . --output-format=github
          mypy . --strict

      - name: 2Ô∏è‚É£ Execu√ß√£o de Testes (pytest)
        run: |
          pytest \
            --cov=. \
            --cov-report=term-missing \
            --cov-report=xml \
            --cov-fail-under=95 \
            --junitxml=test-results.xml \
            -v

      - name: 3Ô∏è‚É£ Conformidade Doutrin√°ria (Zero Mocks/TODOs)
        run: |
          VIOLATIONS=$(grep -rn "mock\|TODO\|FIXME\|placeholder" \
            --include="*.py" \
            --exclude-dir=tests \
            --exclude-dir=.venv \
            . || true)

          if [ -n "$VIOLATIONS" ]; then
            echo "::error::Viola√ß√µes de Padr√£o Pagani detectadas:"
            echo "$VIOLATIONS"
            exit 1
          fi

          echo "::notice::‚úÖ C√≥digo conforme Padr√£o Pagani (Zero Mocks/TODOs)"

      - name: Upload Coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage.xml
          fail_ci_if_error: true

      - name: Publish Test Results
        uses: EnricoMi/publish-unit-test-result-action@v2
        if: always()
        with:
          files: test-results.xml

  security-scan:
    name: Security Audit (Bandit + Safety)
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install Security Tools
        run: |
          pip install bandit safety

      - name: Bandit Security Scan
        run: |
          bandit -r . -f json -o bandit-report.json

      - name: Safety Dependency Check
        run: |
          safety check --json --output safety-report.json

  performance-benchmark:
    name: Performance Benchmarks
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Run Benchmarks
        run: |
          pytest tests/benchmarks/ \
            --benchmark-only \
            --benchmark-json=benchmark-results.json

      - name: Validate Performance SLAs
        run: |
          python scripts/validate_performance_slas.py benchmark-results.json
          # Thresholds:
          # - ToM inference_time_p95 < 200ms
          # - DDL inference_time < 100ms
          # - Compassion cycle_time < 2s

  deploy-staging:
    name: Deploy to Staging
    needs: [validate-triple, security-scan, performance-benchmark]
    if: github.ref == 'refs/heads/feature/prefrontal-cortex-v2'
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v3

      - name: Setup kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'latest'

      - name: Deploy to K8s Staging
        run: |
          kubectl apply -f k8s/staging/ --namespace=maximus-staging

      - name: Wait for Rollout
        run: |
          kubectl rollout status deployment/prefrontal-cortex-v2 \
            --namespace=maximus-staging \
            --timeout=5m

      - name: Health Check
        run: |
          kubectl run health-check \
            --image=curlimages/curl \
            --restart=Never \
            --namespace=maximus-staging \
            -- curl http://prefrontal-cortex-v2-service/health

          kubectl wait --for=condition=complete job/health-check \
            --namespace=maximus-staging \
            --timeout=2m
```

---

## 5. Checklist de Entrega (Definition of Done)

### 5.1 Checklist por M√≥dulo

**Para CADA m√≥dulo (ex: `compassion/tom_engine.py`):**

- [ ] **C√≥digo**
  - [ ] Implementa√ß√£o completa (sem TODOs/placeholders)
  - [ ] Type hints completos (mypy --strict passa)
  - [ ] Docstrings Google style em todas as classes/fun√ß√µes p√∫blicas
  - [ ] Conformidade PEP 8 + ruff (zero errors)
  - [ ] Zero mocks em c√≥digo de produ√ß√£o

- [ ] **Testes**
  - [ ] Testes unit√°rios (coverage ‚â• 95%)
  - [ ] Testes de integra√ß√£o (componentes relacionados)
  - [ ] Testes adversariais (se aplic√°vel - security gates, validators)
  - [ ] Todos os testes passam (zero skips n√£o-justificados)
  - [ ] Benchmarks de performance (se aplic√°vel)

- [ ] **Valida√ß√£o Tripla**
  - [ ] An√°lise est√°tica: `ruff check` + `mypy --strict` (0 errors)
  - [ ] Execu√ß√£o de testes: `pytest --cov --cov-fail-under=95` (100% pass)
  - [ ] Conformidade doutrin√°ria: `grep -r "mock\|TODO"` (0 matches em prod)

- [ ] **Documenta√ß√£o**
  - [ ] README.md com overview e exemplos de uso
  - [ ] API documentation (auto-gerada com Sphinx/mkdocs)
  - [ ] Architecture diagram (se aplic√°vel)
  - [ ] Integration guide (como integrar com outros m√≥dulos)

- [ ] **M√©tricas**
  - [ ] M√©tricas funcionais validadas (ex: `tom_accuracy ‚â• 85%`)
  - [ ] M√©tricas de performance validadas (ex: `latency_p95 < 200ms`)
  - [ ] Prometheus metrics expostas (se aplic√°vel)

---

### 5.2 Checklist de Checkpoint de Fase

**Ao final de cada fase (1, 2, 3):**

- [ ] **Entreg√°veis de Fase**
  - [ ] Todos os m√≥dulos da fase completados (checklist 5.1 ‚úÖ)
  - [ ] Integra√ß√£o entre m√≥dulos da fase validada (testes E2E)
  - [ ] Documenta√ß√£o t√©cnica completa (blueprints + API docs)

- [ ] **Demo ao Vivo**
  - [ ] Demo preparada demonstrando funcionalidades da fase
  - [ ] Cen√°rios de sucesso e falha testados
  - [ ] Q&A com Arquiteto-Chefe respondido

- [ ] **M√©tricas de Fase**
  - [ ] Todas as m√©tricas P0/P1/P2 da fase validadas
  - [ ] Performance SLAs respeitados
  - [ ] Security audit sem issues high/critical

- [ ] **Aprova√ß√£o**
  - [ ] Revis√£o de c√≥digo pelo Arquiteto-Chefe (aprovada)
  - [ ] Sign-off formal para pr√≥xima fase (documento assinado)

---

## 6. Protocolos de Emerg√™ncia

### 6.1 Bloqueadores Cr√≠ticos

**Se encontrar bloqueador que impede progresso > 1 dia:**

1. **Imediatamente**:
   - Parar trabalho no item bloqueado
   - Documentar bloqueador em issue do GitHub com label `blocker`
   - Notificar Arquiteto-Chefe via comunica√ß√£o direta

2. **Workaround Tempor√°rio** (se poss√≠vel):
   - Implementar solu√ß√£o alternativa tempor√°ria (marcada como `# WORKAROUND: Issue #123`)
   - Continuar com outros itens n√£o-bloqueados
   - Agendar resolu√ß√£o definitiva na pr√≥xima sprint planning

3. **Escala√ß√£o** (se bloqueador persiste > 3 dias):
   - Convocar meeting de emerg√™ncia com Arquiteto-Chefe + Co-Arquiteto C√©tico
   - Avaliar impacto no roadmap
   - Decidir: ajustar escopo, adicionar recursos, ou re-priorizar

---

### 6.2 Falhas de Valida√ß√£o Tripla

**Se valida√ß√£o tripla falha no CI/CD:**

1. **N√£o bypassar**: Valida√ß√£o tripla √© inviol√°vel (Artigo II - Padr√£o Pagani)

2. **An√°lise de Causa Raiz**:
   - Identificar qual das 3 valida√ß√µes falhou
   - Reproduzir localmente
   - Corrigir problema na raiz (n√£o mascarar)

3. **Exemplo de Fluxo**:

```bash
# CI/CD reporta: "Conformidade Doutrin√°ria falhou - 3 TODOs encontrados"

# 1. Reproduzir localmente
$ grep -rn "TODO" --include="*.py" --exclude-dir=tests .
compassion/tom_engine.py:142: # TODO: Implement advanced heuristic
compassion/tom_engine.py:267: # TODO: Add Bayesian inference
justice/deontic_reasoner.py:89: # TODO: Optimize with caching

# 2. Para cada TODO:
#    a) Se trivial: implementar imediatamente
#    b) Se complexo: criar issue no GitHub, adicionar refer√™ncia, remover TODO

# Op√ß√£o a) - Implementar
$ vim compassion/tom_engine.py
# (implementar funcionalidade)

# Op√ß√£o b) - Criar issue
$ gh issue create --title "Implement Bayesian inference for ToM" --label enhancement
# Issue #456 created

$ vim compassion/tom_engine.py
# Substituir:
# TODO: Add Bayesian inference
# Por:
# Future enhancement: Bayesian inference for hypothesis ranking
# Tracked in: https://github.com/org/repo/issues/456

# 3. Re-executar valida√ß√£o
$ ./scripts/validate_triple.sh
‚úÖ VALIDA√á√ÉO TRIPLA COMPLETA

# 4. Commit
$ git add .
$ git commit -m "fix: resolve conformidade doutrin√°ria - remove TODOs (#456)"
$ git push
```

---

## 7. Ferramentas e Ambiente

### 7.1 Stack Tecnol√≥gico

| Categoria | Ferramenta | Vers√£o | Prop√≥sito |
|-----------|-----------|---------|-----------|
| **Linguagem** | Python | 3.10+ | Implementa√ß√£o principal |
| **Type Checking** | mypy | latest | Valida√ß√£o de tipos |
| **Linting** | ruff | latest | An√°lise est√°tica |
| **Formatting** | ruff format | latest | Auto-formata√ß√£o |
| **Testing** | pytest | ‚â• 7.0 | Testes unit√°rios/integra√ß√£o |
| **Coverage** | pytest-cov | latest | Cobertura de testes |
| **Benchmarking** | pytest-benchmark | latest | Performance benchmarks |
| **Security** | bandit, safety | latest | Security auditing |
| **Database** | PostgreSQL | 14+ | Precedent DB, Social Memory |
| **Vector DB** | pgvector | 0.5+ | Similarity search (CBR) |
| **Container** | Docker | 20+ | Containeriza√ß√£o |
| **Orchestration** | Kubernetes | 1.28+ | Deploy em staging/prod |
| **CI/CD** | GitHub Actions | - | Pipeline automatizado |
| **Monitoring** | Prometheus + Grafana | latest | M√©tricas operacionais |

---

### 7.2 Ambiente de Desenvolvimento

**Setup Local (Ubuntu/Debian):**

```bash
#!/bin/bash
# scripts/setup_dev_environment.sh

set -e

echo "üõ†Ô∏è  Configurando Ambiente de Desenvolvimento - C√≥rtex Pr√©-Frontal v2.0"

# 1. Python 3.10+
echo "üì¶ Instalando Python 3.10..."
sudo apt update
sudo apt install -y python3.10 python3.10-venv python3.10-dev

# 2. Poetry (gerenciamento de depend√™ncias)
echo "üì¶ Instalando Poetry..."
curl -sSL https://install.python-poetry.org | python3 -

# 3. Criar virtualenv
echo "üèóÔ∏è  Criando virtualenv..."
python3.10 -m venv .venv
source .venv/bin/activate

# 4. Instalar depend√™ncias
echo "üì¶ Instalando depend√™ncias do projeto..."
poetry install --with dev,test

# 5. PostgreSQL (para PrecedentDatabase)
echo "üêò Instalando PostgreSQL + pgvector..."
sudo apt install -y postgresql postgresql-contrib
sudo -u postgres psql -c "CREATE DATABASE maximus_dev;"
sudo -u postgres psql -c "CREATE USER maximus WITH PASSWORD 'dev_password';"
sudo -u postgres psql -c "GRANT ALL PRIVILEGES ON DATABASE maximus_dev TO maximus;"

# Instalar pgvector extension
git clone https://github.com/pgvector/pgvector.git /tmp/pgvector
cd /tmp/pgvector
make
sudo make install
sudo -u postgres psql maximus_dev -c "CREATE EXTENSION vector;"

# 6. Pre-commit hooks
echo "ü™ù Configurando Git hooks..."
cp scripts/pre-commit .git/hooks/pre-commit
chmod +x .git/hooks/pre-commit

# 7. Validar setup
echo "‚úÖ Validando setup..."
python -c "import sys; assert sys.version_info >= (3, 10)"
mypy --version
ruff --version
pytest --version

echo "üéâ Ambiente configurado com sucesso!"
echo ""
echo "Pr√≥ximos passos:"
echo "  1. source .venv/bin/activate"
echo "  2. ./scripts/validate_triple.sh"
echo "  3. pytest tests/"
```

---

## 8. Comunica√ß√£o e Reportes

### 8.1 Standup Di√°rio (Ass√≠ncrono)

**Template de Standup (Slack/GitHub Discussions):**

```markdown
## Daily Standup - 2025-10-15 (Dia 3 - Semana 1)

**Executor T√°tico: Claude Code**

### ‚úÖ Ontem (Dia 2)
- [x] Implementado `ToMAgent.generate_hypotheses()` (compassion/tom_engine.py:120-180)
- [x] Implementado `MoralDomainAgent.filter_hypotheses()` (compassion/tom_engine.py:200-250)
- [x] Testes unit√°rios: 15 testes escritos, coverage 87% (target: 95%)
- [x] Valida√ß√£o tripla: 2/3 passando (mypy falhou em 3 fun√ß√µes)

### üîÑ Hoje (Dia 3)
- [ ] Corrigir type hints para passar mypy --strict
- [ ] Implementar `ResponseAgent.generate_response()`
- [ ] Completar testes unit√°rios (coverage ‚Üí 95%)
- [ ] Sprint 1.1 checkpoint: validar ToM Engine completo

### üöß Bloqueadores
- Nenhum

### üìä M√©tricas
- Commits: 8 (ontem), 47 (total sprint)
- Testes: 15 escritos, 15 passando, 0 falhas
- Coverage: 87% ‚Üí target 95% (faltam 8 pontos percentuais)
- Velocidade: ~25h de estimativa completas de 33h sprint (on track)

### üí° Observa√ß√µes
- ToM heuristics podem ser melhoradas com Bayesian inference (criado issue #456 para futuro)
- Social memory storage funcionando bem com SQLite (produ√ß√£o usar√° PostgreSQL)
```

---

### 8.2 Reporte de Checkpoint Semanal

**Template de Checkpoint (Markdown para docs/):**

```markdown
# Checkpoint Semanal - Semana 1 (Dias 1-5)
## ToM Engine + Social Memory

**Data**: 2025-10-20
**Sprint**: 1.1 + 1.2
**Executor T√°tico**: Claude Code
**Revisor**: Juan Carlos de Souza (Arquiteto-Chefe)

---

## üìã Resumo Executivo

‚úÖ **Objetivo da Semana**: Implementar ToM Engine production-ready + integra√ß√£o com LRR
‚úÖ **Status**: CONCLU√çDO - Todos os objetivos atingidos

**Entregas**:
- [x] `compassion/tom_engine.py` (450 LOC, 100% type-hinted, 97% coverage)
- [x] Testes unit√°rios: 28 testes, 28 passando (benchmark Sally-Anne inclu√≠do)
- [x] Integra√ß√£o com `consciousness/lrr/recursive_reasoner.py`
- [x] Documenta√ß√£o t√©cnica completa (API docs + architecture diagram)

**M√©tricas Validadas**:
- `tom_accuracy`: 89% no Sally-Anne Test (target: ‚â•85%) ‚úÖ
- `inference_time_p95`: 178ms (target: <200ms) ‚úÖ
- `coverage`: 97% (target: ‚â•95%) ‚úÖ

---

## üìä M√©tricas Detalhadas

### Cobertura de Testes
```
compassion/tom_engine.py    450    18     45    97%    Lines 234-236, 401
```

### Performance Benchmarks
```
test_tom_agent_generates_hypotheses         178ms (p95)
test_social_memory_retrieval                 12ms (p95)
test_moral_agent_filter                      45ms (p95)
```

### Sally-Anne False Belief Test Results
```
Total scenarios: 10
Correct inferences: 9
False positives: 1 (scenario #7 - edge case with ambiguous context)
Accuracy: 90% (exceeds target of 85%)
```

---

## üéØ Objetivos vs. Realiza√ß√µes

| Objetivo | Planejado | Realizado | Status |
|----------|-----------|-----------|--------|
| ToMAgent implementation | 6h | 7h | ‚úÖ (+1h para edge cases) |
| MoralDomainAgent | 4h | 4h | ‚úÖ |
| ResponseAgent | 4h | 3.5h | ‚úÖ |
| Unit tests | 6h | 8h | ‚úÖ (+2h para Sally-Anne) |
| Integration with LRR | 4h | 5h | ‚úÖ (+1h debugging) |
| **Total** | **24h** | **27.5h** | ‚úÖ (+14% variance) |

---

## üêõ Issues Encontrados e Resolvidos

### Issue #1: mypy --strict falhou inicialmente
**Descri√ß√£o**: 12 fun√ß√µes sem type hints completos
**Resolu√ß√£o**: Adicionado type hints para todos os par√¢metros e retornos (commit: abc123)
**Tempo**: 2h

### Issue #2: Sally-Anne Test falhou em cen√°rio amb√≠guo
**Descri√ß√£o**: Cen√°rio #7 (m√∫ltiplas transfers de marble) confundiu heur√≠stica
**Resolu√ß√£o**: Adicionado tracking de "last known location per agent" (commit: def456)
**Tempo**: 3h

---

## üìö Documenta√ß√£o Criada

- [x] `docs/compassion/tom-engine-architecture.md` (diagram + flow)
- [x] `docs/compassion/tom-engine-api.md` (API reference)
- [x] `compassion/README.md` (usage examples)
- [x] Docstrings inline (100% das fun√ß√µes p√∫blicas)

---

## üîÆ Pr√≥xima Semana (Semana 2)

**Foco**: Compassion Planner (ComPeer Architecture)

**Objetivos**:
- [ ] Implementar `EventDetector`, `ScheduleModule`, `ReflectionModule`
- [ ] Implementar `CompassionCycle` (6 est√°gios)
- [ ] Integrar com ESGT Coordinator
- [ ] Target metrics: `proactivity_rate ‚â• 60%`, `cycle_time < 2s`

**Riscos Identificados**:
- Nenhum (ToM Engine est√° est√°vel e bem testado)

---

## ‚úÖ Aprova√ß√£o de Checkpoint

**Executor T√°tico (Claude Code)**:
- Confirmo que todos os entreg√°veis foram conclu√≠dos conforme DoD
- Todas as m√©tricas de valida√ß√£o foram atingidas ou excedidas
- C√≥digo est√° conforme Padr√£o Pagani (Zero mocks/TODOs em produ√ß√£o)

**Arquiteto-Chefe (Juan Carlos de Souza)**:
- [ ] Revis√£o de c√≥digo: APROVADA
- [ ] Demo ao vivo: APROVADA
- [ ] M√©tricas: VALIDADAS
- [ ] Autoriza√ß√£o para Semana 2: SIM ‚úÖ

**Assinatura**: ___________________________  **Data**: ___________
```

---

## 9. Controle de Qualidade Cont√≠nuo

### 9.1 Code Review Checklist (Para Humano Revisor)

**Ao revisar Pull Request:**

- [ ] **Arquitetura**
  - [ ] C√≥digo segue DDD (ubiquitous language do dom√≠nio)
  - [ ] Separa√ß√£o de responsabilidades clara (SRP)
  - [ ] Depend√™ncias injetadas (n√£o hardcoded)
  - [ ] Sem acoplamento desnecess√°rio entre m√≥dulos

- [ ] **C√≥digo**
  - [ ] Type hints completos e corretos
  - [ ] Docstrings Google style em todas as APIs p√∫blicas
  - [ ] Naming conventions seguidas (classes=substantivos, m√©todos=verbos)
  - [ ] Sem c√≥digo duplicado (DRY)
  - [ ] Tratamento de erros adequado (exce√ß√µes espec√≠ficas)

- [ ] **Testes**
  - [ ] Coverage ‚â• 95% verificado
  - [ ] Testes testam comportamento, n√£o implementa√ß√£o
  - [ ] Casos de borda cobertos
  - [ ] Nomes de testes descritivos (`test_X_when_Y_then_Z`)

- [ ] **Padr√£o Pagani**
  - [ ] Zero mocks em c√≥digo de produ√ß√£o (apenas em testes)
  - [ ] Zero TODOs/FIXMEs/placeholders
  - [ ] Valida√ß√£o tripla passou no CI/CD

- [ ] **Seguran√ßa**
  - [ ] Sem hardcoded secrets/credentials
  - [ ] Input validation presente onde necess√°rio
  - [ ] Sem SQL injection vulnerabilities (usar parametrized queries)

---

## 10. Conclus√£o

Este plano de implementa√ß√£o √© um **contrato vivo** entre Arquiteto-Chefe e Executor T√°tico.

**Compromissos do Executor T√°tico (IA):**
1. Seguir este plano rigorosamente (Cl√°usula 3.1 - Ades√£o Inflex√≠vel ao Plano)
2. Aplicar Padr√£o Pagani sem exce√ß√µes (Artigo II)
3. Executar Valida√ß√£o Tripla antes de qualquer commit (Artigo III)
4. Comunicar verdade factual ("N√ÉO SEI" quando apropriado) (Cl√°usula 3.4)
5. Reportar bloqueadores imediatamente (< 24h)

**Compromissos do Arquiteto-Chefe (Humano):**
1. Revisar checkpoints semanais em ‚â§ 48h
2. Aprovar/rejeitar decis√µes arquiteturais cr√≠ticas em ‚â§ 24h
3. Fornecer feedback construtivo e espec√≠fico
4. Validar conformidade com Lei Zero e Lei I

**Sucesso = Colabora√ß√£o Humano-IA com Responsabilidades Soberanas.**

---

**STATUS**: ‚úÖ PLANO COMPLETO - PRONTO PARA EXECU√á√ÉO

**Aprova√ß√£o Final:**
- [ ] Arquiteto-Chefe (Humano): __________________________  Data: ___________
- [ ] Co-Arquiteto C√©tico (IA): __________________________  Data: ___________
- [ ] Executor T√°tico (IA): __________________________  Data: ___________

**Data de Kickoff**: ___________ (Dia 1 do Roadmap)
